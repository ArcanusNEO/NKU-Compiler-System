*** IR Dump Before Pre-ISel Intrinsic Lowering (pre-isel-intrinsic-lowering) ***
; ModuleID = 'fib.ll'
source_filename = "fib.c"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-pc-linux-gnu"

@.str = private unnamed_addr constant [7 x i8] c"%d%d%d\00", align 1
@.str.1 = private unnamed_addr constant [4 x i8] c"%d\0A\00", align 1

; Function Attrs: noinline nounwind optnone sspstrong uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  %6 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  store i32 0, i32* %2, align 4
  store i32 1, i32* %3, align 4
  store i32 1, i32* %4, align 4
  %7 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([7 x i8], [7 x i8]* @.str, i64 0, i64 0), i32* noundef %5, i32* noundef %2, i32* noundef %3)
  br label %8

8:                                                ; preds = %12, %0
  %9 = load i32, i32* %4, align 4
  %10 = load i32, i32* %5, align 4
  %11 = icmp slt i32 %9, %10
  br i1 %11, label %12, label %22

12:                                               ; preds = %8
  %13 = load i32, i32* %3, align 4
  store i32 %13, i32* %6, align 4
  %14 = load i32, i32* %2, align 4
  %15 = load i32, i32* %3, align 4
  %16 = add nsw i32 %14, %15
  store i32 %16, i32* %3, align 4
  %17 = load i32, i32* %3, align 4
  %18 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([4 x i8], [4 x i8]* @.str.1, i64 0, i64 0), i32 noundef %17)
  %19 = load i32, i32* %6, align 4
  store i32 %19, i32* %2, align 4
  %20 = load i32, i32* %4, align 4
  %21 = add nsw i32 %20, 1
  store i32 %21, i32* %4, align 4
  br label %8, !llvm.loop !6

22:                                               ; preds = %8
  %23 = load i32, i32* %1, align 4
  ret i32 %23
}

declare i32 @__isoc99_scanf(i8* noundef, ...) #1

declare i32 @printf(i8* noundef, ...) #1

attributes #0 = { noinline nounwind optnone sspstrong uwtable "frame-pointer"="all" "min-legal-vector-width"="0" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+x87" "tune-cpu"="generic" }
attributes #1 = { "frame-pointer"="all" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+x87" "tune-cpu"="generic" }

!llvm.module.flags = !{!0, !1, !2, !3, !4}
!llvm.ident = !{!5}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"PIC Level", i32 2}
!2 = !{i32 7, !"PIE Level", i32 2}
!3 = !{i32 7, !"uwtable", i32 1}
!4 = !{i32 7, !"frame-pointer", i32 2}
!5 = !{!"clang version 14.0.6"}
!6 = distinct !{!6, !7}
!7 = !{!"llvm.loop.mustprogress"}
*** IR Dump After Pre-ISel Intrinsic Lowering (pre-isel-intrinsic-lowering) ***
; ModuleID = 'fib.ll'
source_filename = "fib.c"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-pc-linux-gnu"

@.str = private unnamed_addr constant [7 x i8] c"%d%d%d\00", align 1
@.str.1 = private unnamed_addr constant [4 x i8] c"%d\0A\00", align 1

; Function Attrs: noinline nounwind optnone sspstrong uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  %6 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  store i32 0, i32* %2, align 4
  store i32 1, i32* %3, align 4
  store i32 1, i32* %4, align 4
  %7 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([7 x i8], [7 x i8]* @.str, i64 0, i64 0), i32* noundef %5, i32* noundef %2, i32* noundef %3)
  br label %8

8:                                                ; preds = %12, %0
  %9 = load i32, i32* %4, align 4
  %10 = load i32, i32* %5, align 4
  %11 = icmp slt i32 %9, %10
  br i1 %11, label %12, label %22

12:                                               ; preds = %8
  %13 = load i32, i32* %3, align 4
  store i32 %13, i32* %6, align 4
  %14 = load i32, i32* %2, align 4
  %15 = load i32, i32* %3, align 4
  %16 = add nsw i32 %14, %15
  store i32 %16, i32* %3, align 4
  %17 = load i32, i32* %3, align 4
  %18 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([4 x i8], [4 x i8]* @.str.1, i64 0, i64 0), i32 noundef %17)
  %19 = load i32, i32* %6, align 4
  store i32 %19, i32* %2, align 4
  %20 = load i32, i32* %4, align 4
  %21 = add nsw i32 %20, 1
  store i32 %21, i32* %4, align 4
  br label %8, !llvm.loop !6

22:                                               ; preds = %8
  %23 = load i32, i32* %1, align 4
  ret i32 %23
}

declare i32 @__isoc99_scanf(i8* noundef, ...) #1

declare i32 @printf(i8* noundef, ...) #1

attributes #0 = { noinline nounwind optnone sspstrong uwtable "frame-pointer"="all" "min-legal-vector-width"="0" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+x87" "tune-cpu"="generic" }
attributes #1 = { "frame-pointer"="all" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+x87" "tune-cpu"="generic" }

!llvm.module.flags = !{!0, !1, !2, !3, !4}
!llvm.ident = !{!5}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"PIC Level", i32 2}
!2 = !{i32 7, !"PIE Level", i32 2}
!3 = !{i32 7, !"uwtable", i32 1}
!4 = !{i32 7, !"frame-pointer", i32 2}
!5 = !{!"clang version 14.0.6"}
!6 = distinct !{!6, !7}
!7 = !{!"llvm.loop.mustprogress"}
*** IR Dump Before Expand Atomic instructions (atomic-expand) ***
; Function Attrs: noinline nounwind optnone sspstrong uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  %6 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  store i32 0, i32* %2, align 4
  store i32 1, i32* %3, align 4
  store i32 1, i32* %4, align 4
  %7 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([7 x i8], [7 x i8]* @.str, i64 0, i64 0), i32* noundef %5, i32* noundef %2, i32* noundef %3)
  br label %8

8:                                                ; preds = %12, %0
  %9 = load i32, i32* %4, align 4
  %10 = load i32, i32* %5, align 4
  %11 = icmp slt i32 %9, %10
  br i1 %11, label %12, label %22

12:                                               ; preds = %8
  %13 = load i32, i32* %3, align 4
  store i32 %13, i32* %6, align 4
  %14 = load i32, i32* %2, align 4
  %15 = load i32, i32* %3, align 4
  %16 = add nsw i32 %14, %15
  store i32 %16, i32* %3, align 4
  %17 = load i32, i32* %3, align 4
  %18 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([4 x i8], [4 x i8]* @.str.1, i64 0, i64 0), i32 noundef %17)
  %19 = load i32, i32* %6, align 4
  store i32 %19, i32* %2, align 4
  %20 = load i32, i32* %4, align 4
  %21 = add nsw i32 %20, 1
  store i32 %21, i32* %4, align 4
  br label %8, !llvm.loop !6

22:                                               ; preds = %8
  %23 = load i32, i32* %1, align 4
  ret i32 %23
}
*** IR Dump After Expand Atomic instructions (atomic-expand) ***
; Function Attrs: noinline nounwind optnone sspstrong uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  %6 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  store i32 0, i32* %2, align 4
  store i32 1, i32* %3, align 4
  store i32 1, i32* %4, align 4
  %7 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([7 x i8], [7 x i8]* @.str, i64 0, i64 0), i32* noundef %5, i32* noundef %2, i32* noundef %3)
  br label %8

8:                                                ; preds = %12, %0
  %9 = load i32, i32* %4, align 4
  %10 = load i32, i32* %5, align 4
  %11 = icmp slt i32 %9, %10
  br i1 %11, label %12, label %22

12:                                               ; preds = %8
  %13 = load i32, i32* %3, align 4
  store i32 %13, i32* %6, align 4
  %14 = load i32, i32* %2, align 4
  %15 = load i32, i32* %3, align 4
  %16 = add nsw i32 %14, %15
  store i32 %16, i32* %3, align 4
  %17 = load i32, i32* %3, align 4
  %18 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([4 x i8], [4 x i8]* @.str.1, i64 0, i64 0), i32 noundef %17)
  %19 = load i32, i32* %6, align 4
  store i32 %19, i32* %2, align 4
  %20 = load i32, i32* %4, align 4
  %21 = add nsw i32 %20, 1
  store i32 %21, i32* %4, align 4
  br label %8, !llvm.loop !6

22:                                               ; preds = %8
  %23 = load i32, i32* %1, align 4
  ret i32 %23
}
*** IR Dump Before Lower AMX intrinsics (lower-amx-intrinsics) ***
; Function Attrs: noinline nounwind optnone sspstrong uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  %6 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  store i32 0, i32* %2, align 4
  store i32 1, i32* %3, align 4
  store i32 1, i32* %4, align 4
  %7 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([7 x i8], [7 x i8]* @.str, i64 0, i64 0), i32* noundef %5, i32* noundef %2, i32* noundef %3)
  br label %8

8:                                                ; preds = %12, %0
  %9 = load i32, i32* %4, align 4
  %10 = load i32, i32* %5, align 4
  %11 = icmp slt i32 %9, %10
  br i1 %11, label %12, label %22

12:                                               ; preds = %8
  %13 = load i32, i32* %3, align 4
  store i32 %13, i32* %6, align 4
  %14 = load i32, i32* %2, align 4
  %15 = load i32, i32* %3, align 4
  %16 = add nsw i32 %14, %15
  store i32 %16, i32* %3, align 4
  %17 = load i32, i32* %3, align 4
  %18 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([4 x i8], [4 x i8]* @.str.1, i64 0, i64 0), i32 noundef %17)
  %19 = load i32, i32* %6, align 4
  store i32 %19, i32* %2, align 4
  %20 = load i32, i32* %4, align 4
  %21 = add nsw i32 %20, 1
  store i32 %21, i32* %4, align 4
  br label %8, !llvm.loop !6

22:                                               ; preds = %8
  %23 = load i32, i32* %1, align 4
  ret i32 %23
}
*** IR Dump After Lower AMX intrinsics (lower-amx-intrinsics) ***
; Function Attrs: noinline nounwind optnone sspstrong uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  %6 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  store i32 0, i32* %2, align 4
  store i32 1, i32* %3, align 4
  store i32 1, i32* %4, align 4
  %7 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([7 x i8], [7 x i8]* @.str, i64 0, i64 0), i32* noundef %5, i32* noundef %2, i32* noundef %3)
  br label %8

8:                                                ; preds = %12, %0
  %9 = load i32, i32* %4, align 4
  %10 = load i32, i32* %5, align 4
  %11 = icmp slt i32 %9, %10
  br i1 %11, label %12, label %22

12:                                               ; preds = %8
  %13 = load i32, i32* %3, align 4
  store i32 %13, i32* %6, align 4
  %14 = load i32, i32* %2, align 4
  %15 = load i32, i32* %3, align 4
  %16 = add nsw i32 %14, %15
  store i32 %16, i32* %3, align 4
  %17 = load i32, i32* %3, align 4
  %18 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([4 x i8], [4 x i8]* @.str.1, i64 0, i64 0), i32 noundef %17)
  %19 = load i32, i32* %6, align 4
  store i32 %19, i32* %2, align 4
  %20 = load i32, i32* %4, align 4
  %21 = add nsw i32 %20, 1
  store i32 %21, i32* %4, align 4
  br label %8, !llvm.loop !6

22:                                               ; preds = %8
  %23 = load i32, i32* %1, align 4
  ret i32 %23
}
*** IR Dump Before Lower AMX type for load/store (lower-amx-type) ***
; Function Attrs: noinline nounwind optnone sspstrong uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  %6 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  store i32 0, i32* %2, align 4
  store i32 1, i32* %3, align 4
  store i32 1, i32* %4, align 4
  %7 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([7 x i8], [7 x i8]* @.str, i64 0, i64 0), i32* noundef %5, i32* noundef %2, i32* noundef %3)
  br label %8

8:                                                ; preds = %12, %0
  %9 = load i32, i32* %4, align 4
  %10 = load i32, i32* %5, align 4
  %11 = icmp slt i32 %9, %10
  br i1 %11, label %12, label %22

12:                                               ; preds = %8
  %13 = load i32, i32* %3, align 4
  store i32 %13, i32* %6, align 4
  %14 = load i32, i32* %2, align 4
  %15 = load i32, i32* %3, align 4
  %16 = add nsw i32 %14, %15
  store i32 %16, i32* %3, align 4
  %17 = load i32, i32* %3, align 4
  %18 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([4 x i8], [4 x i8]* @.str.1, i64 0, i64 0), i32 noundef %17)
  %19 = load i32, i32* %6, align 4
  store i32 %19, i32* %2, align 4
  %20 = load i32, i32* %4, align 4
  %21 = add nsw i32 %20, 1
  store i32 %21, i32* %4, align 4
  br label %8, !llvm.loop !6

22:                                               ; preds = %8
  %23 = load i32, i32* %1, align 4
  ret i32 %23
}
*** IR Dump After Lower AMX type for load/store (lower-amx-type) ***
; Function Attrs: noinline nounwind optnone sspstrong uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  %6 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  store i32 0, i32* %2, align 4
  store i32 1, i32* %3, align 4
  store i32 1, i32* %4, align 4
  %7 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([7 x i8], [7 x i8]* @.str, i64 0, i64 0), i32* noundef %5, i32* noundef %2, i32* noundef %3)
  br label %8

8:                                                ; preds = %12, %0
  %9 = load i32, i32* %4, align 4
  %10 = load i32, i32* %5, align 4
  %11 = icmp slt i32 %9, %10
  br i1 %11, label %12, label %22

12:                                               ; preds = %8
  %13 = load i32, i32* %3, align 4
  store i32 %13, i32* %6, align 4
  %14 = load i32, i32* %2, align 4
  %15 = load i32, i32* %3, align 4
  %16 = add nsw i32 %14, %15
  store i32 %16, i32* %3, align 4
  %17 = load i32, i32* %3, align 4
  %18 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([4 x i8], [4 x i8]* @.str.1, i64 0, i64 0), i32 noundef %17)
  %19 = load i32, i32* %6, align 4
  store i32 %19, i32* %2, align 4
  %20 = load i32, i32* %4, align 4
  %21 = add nsw i32 %20, 1
  store i32 %21, i32* %4, align 4
  br label %8, !llvm.loop !6

22:                                               ; preds = %8
  %23 = load i32, i32* %1, align 4
  ret i32 %23
}
*** IR Dump Before Module Verifier (verify) ***
; Function Attrs: noinline nounwind optnone sspstrong uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  %6 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  store i32 0, i32* %2, align 4
  store i32 1, i32* %3, align 4
  store i32 1, i32* %4, align 4
  %7 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([7 x i8], [7 x i8]* @.str, i64 0, i64 0), i32* noundef %5, i32* noundef %2, i32* noundef %3)
  br label %8

8:                                                ; preds = %12, %0
  %9 = load i32, i32* %4, align 4
  %10 = load i32, i32* %5, align 4
  %11 = icmp slt i32 %9, %10
  br i1 %11, label %12, label %22

12:                                               ; preds = %8
  %13 = load i32, i32* %3, align 4
  store i32 %13, i32* %6, align 4
  %14 = load i32, i32* %2, align 4
  %15 = load i32, i32* %3, align 4
  %16 = add nsw i32 %14, %15
  store i32 %16, i32* %3, align 4
  %17 = load i32, i32* %3, align 4
  %18 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([4 x i8], [4 x i8]* @.str.1, i64 0, i64 0), i32 noundef %17)
  %19 = load i32, i32* %6, align 4
  store i32 %19, i32* %2, align 4
  %20 = load i32, i32* %4, align 4
  %21 = add nsw i32 %20, 1
  store i32 %21, i32* %4, align 4
  br label %8, !llvm.loop !6

22:                                               ; preds = %8
  %23 = load i32, i32* %1, align 4
  ret i32 %23
}
*** IR Dump After Module Verifier (verify) ***
; Function Attrs: noinline nounwind optnone sspstrong uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  %6 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  store i32 0, i32* %2, align 4
  store i32 1, i32* %3, align 4
  store i32 1, i32* %4, align 4
  %7 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([7 x i8], [7 x i8]* @.str, i64 0, i64 0), i32* noundef %5, i32* noundef %2, i32* noundef %3)
  br label %8

8:                                                ; preds = %12, %0
  %9 = load i32, i32* %4, align 4
  %10 = load i32, i32* %5, align 4
  %11 = icmp slt i32 %9, %10
  br i1 %11, label %12, label %22

12:                                               ; preds = %8
  %13 = load i32, i32* %3, align 4
  store i32 %13, i32* %6, align 4
  %14 = load i32, i32* %2, align 4
  %15 = load i32, i32* %3, align 4
  %16 = add nsw i32 %14, %15
  store i32 %16, i32* %3, align 4
  %17 = load i32, i32* %3, align 4
  %18 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([4 x i8], [4 x i8]* @.str.1, i64 0, i64 0), i32 noundef %17)
  %19 = load i32, i32* %6, align 4
  store i32 %19, i32* %2, align 4
  %20 = load i32, i32* %4, align 4
  %21 = add nsw i32 %20, 1
  store i32 %21, i32* %4, align 4
  br label %8, !llvm.loop !6

22:                                               ; preds = %8
  %23 = load i32, i32* %1, align 4
  ret i32 %23
}
*** IR Dump Before Canonicalize natural loops (loop-simplify) ***
; Function Attrs: noinline nounwind optnone sspstrong uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  %6 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  store i32 0, i32* %2, align 4
  store i32 1, i32* %3, align 4
  store i32 1, i32* %4, align 4
  %7 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([7 x i8], [7 x i8]* @.str, i64 0, i64 0), i32* noundef %5, i32* noundef %2, i32* noundef %3)
  br label %8

8:                                                ; preds = %12, %0
  %9 = load i32, i32* %4, align 4
  %10 = load i32, i32* %5, align 4
  %11 = icmp slt i32 %9, %10
  br i1 %11, label %12, label %22

12:                                               ; preds = %8
  %13 = load i32, i32* %3, align 4
  store i32 %13, i32* %6, align 4
  %14 = load i32, i32* %2, align 4
  %15 = load i32, i32* %3, align 4
  %16 = add nsw i32 %14, %15
  store i32 %16, i32* %3, align 4
  %17 = load i32, i32* %3, align 4
  %18 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([4 x i8], [4 x i8]* @.str.1, i64 0, i64 0), i32 noundef %17)
  %19 = load i32, i32* %6, align 4
  store i32 %19, i32* %2, align 4
  %20 = load i32, i32* %4, align 4
  %21 = add nsw i32 %20, 1
  store i32 %21, i32* %4, align 4
  br label %8, !llvm.loop !6

22:                                               ; preds = %8
  %23 = load i32, i32* %1, align 4
  ret i32 %23
}
*** IR Dump After Canonicalize natural loops (loop-simplify) ***
; Function Attrs: noinline nounwind optnone sspstrong uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  %6 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  store i32 0, i32* %2, align 4
  store i32 1, i32* %3, align 4
  store i32 1, i32* %4, align 4
  %7 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([7 x i8], [7 x i8]* @.str, i64 0, i64 0), i32* noundef %5, i32* noundef %2, i32* noundef %3)
  br label %8

8:                                                ; preds = %12, %0
  %9 = load i32, i32* %4, align 4
  %10 = load i32, i32* %5, align 4
  %11 = icmp slt i32 %9, %10
  br i1 %11, label %12, label %22

12:                                               ; preds = %8
  %13 = load i32, i32* %3, align 4
  store i32 %13, i32* %6, align 4
  %14 = load i32, i32* %2, align 4
  %15 = load i32, i32* %3, align 4
  %16 = add nsw i32 %14, %15
  store i32 %16, i32* %3, align 4
  %17 = load i32, i32* %3, align 4
  %18 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([4 x i8], [4 x i8]* @.str.1, i64 0, i64 0), i32 noundef %17)
  %19 = load i32, i32* %6, align 4
  store i32 %19, i32* %2, align 4
  %20 = load i32, i32* %4, align 4
  %21 = add nsw i32 %20, 1
  store i32 %21, i32* %4, align 4
  br label %8, !llvm.loop !6

22:                                               ; preds = %8
  %23 = load i32, i32* %1, align 4
  ret i32 %23
}
*** IR Dump Before Canonicalize Freeze Instructions in Loops (canon-freeze) ***
; Preheader:
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  %6 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  store i32 0, i32* %2, align 4
  store i32 1, i32* %3, align 4
  store i32 1, i32* %4, align 4
  %7 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([7 x i8], [7 x i8]* @.str, i64 0, i64 0), i32* noundef %5, i32* noundef %2, i32* noundef %3)
  br label %8

; Loop:
8:                                                ; preds = %12, %0
  %9 = load i32, i32* %4, align 4
  %10 = load i32, i32* %5, align 4
  %11 = icmp slt i32 %9, %10
  br i1 %11, label %12, label %22

12:                                               ; preds = %8
  %13 = load i32, i32* %3, align 4
  store i32 %13, i32* %6, align 4
  %14 = load i32, i32* %2, align 4
  %15 = load i32, i32* %3, align 4
  %16 = add nsw i32 %14, %15
  store i32 %16, i32* %3, align 4
  %17 = load i32, i32* %3, align 4
  %18 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([4 x i8], [4 x i8]* @.str.1, i64 0, i64 0), i32 noundef %17)
  %19 = load i32, i32* %6, align 4
  store i32 %19, i32* %2, align 4
  %20 = load i32, i32* %4, align 4
  %21 = add nsw i32 %20, 1
  store i32 %21, i32* %4, align 4
  br label %8, !llvm.loop !6

; Exit blocks
22:                                               ; preds = %8
  %23 = load i32, i32* %1, align 4
  ret i32 %23
*** IR Dump After Canonicalize Freeze Instructions in Loops (canon-freeze) ***
; Preheader:
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  %6 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  store i32 0, i32* %2, align 4
  store i32 1, i32* %3, align 4
  store i32 1, i32* %4, align 4
  %7 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([7 x i8], [7 x i8]* @.str, i64 0, i64 0), i32* noundef %5, i32* noundef %2, i32* noundef %3)
  br label %8

; Loop:
8:                                                ; preds = %12, %0
  %9 = load i32, i32* %4, align 4
  %10 = load i32, i32* %5, align 4
  %11 = icmp slt i32 %9, %10
  br i1 %11, label %12, label %22

12:                                               ; preds = %8
  %13 = load i32, i32* %3, align 4
  store i32 %13, i32* %6, align 4
  %14 = load i32, i32* %2, align 4
  %15 = load i32, i32* %3, align 4
  %16 = add nsw i32 %14, %15
  store i32 %16, i32* %3, align 4
  %17 = load i32, i32* %3, align 4
  %18 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([4 x i8], [4 x i8]* @.str.1, i64 0, i64 0), i32 noundef %17)
  %19 = load i32, i32* %6, align 4
  store i32 %19, i32* %2, align 4
  %20 = load i32, i32* %4, align 4
  %21 = add nsw i32 %20, 1
  store i32 %21, i32* %4, align 4
  br label %8, !llvm.loop !6

; Exit blocks
22:                                               ; preds = %8
  %23 = load i32, i32* %1, align 4
  ret i32 %23
*** IR Dump Before Loop Strength Reduction (loop-reduce) ***
; Preheader:
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  %6 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  store i32 0, i32* %2, align 4
  store i32 1, i32* %3, align 4
  store i32 1, i32* %4, align 4
  %7 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([7 x i8], [7 x i8]* @.str, i64 0, i64 0), i32* noundef %5, i32* noundef %2, i32* noundef %3)
  br label %8

; Loop:
8:                                                ; preds = %12, %0
  %9 = load i32, i32* %4, align 4
  %10 = load i32, i32* %5, align 4
  %11 = icmp slt i32 %9, %10
  br i1 %11, label %12, label %22

12:                                               ; preds = %8
  %13 = load i32, i32* %3, align 4
  store i32 %13, i32* %6, align 4
  %14 = load i32, i32* %2, align 4
  %15 = load i32, i32* %3, align 4
  %16 = add nsw i32 %14, %15
  store i32 %16, i32* %3, align 4
  %17 = load i32, i32* %3, align 4
  %18 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([4 x i8], [4 x i8]* @.str.1, i64 0, i64 0), i32 noundef %17)
  %19 = load i32, i32* %6, align 4
  store i32 %19, i32* %2, align 4
  %20 = load i32, i32* %4, align 4
  %21 = add nsw i32 %20, 1
  store i32 %21, i32* %4, align 4
  br label %8, !llvm.loop !6

; Exit blocks
22:                                               ; preds = %8
  %23 = load i32, i32* %1, align 4
  ret i32 %23
*** IR Dump After Loop Strength Reduction (loop-reduce) ***
; Preheader:
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  %6 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  store i32 0, i32* %2, align 4
  store i32 1, i32* %3, align 4
  store i32 1, i32* %4, align 4
  %7 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([7 x i8], [7 x i8]* @.str, i64 0, i64 0), i32* noundef %5, i32* noundef %2, i32* noundef %3)
  br label %8

; Loop:
8:                                                ; preds = %12, %0
  %9 = load i32, i32* %4, align 4
  %10 = load i32, i32* %5, align 4
  %11 = icmp slt i32 %9, %10
  br i1 %11, label %12, label %22

12:                                               ; preds = %8
  %13 = load i32, i32* %3, align 4
  store i32 %13, i32* %6, align 4
  %14 = load i32, i32* %2, align 4
  %15 = load i32, i32* %3, align 4
  %16 = add nsw i32 %14, %15
  store i32 %16, i32* %3, align 4
  %17 = load i32, i32* %3, align 4
  %18 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([4 x i8], [4 x i8]* @.str.1, i64 0, i64 0), i32 noundef %17)
  %19 = load i32, i32* %6, align 4
  store i32 %19, i32* %2, align 4
  %20 = load i32, i32* %4, align 4
  %21 = add nsw i32 %20, 1
  store i32 %21, i32* %4, align 4
  br label %8, !llvm.loop !6

; Exit blocks
22:                                               ; preds = %8
  %23 = load i32, i32* %1, align 4
  ret i32 %23
*** IR Dump Before Merge contiguous icmps into a memcmp (mergeicmps) ***
; Function Attrs: noinline nounwind optnone sspstrong uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  %6 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  store i32 0, i32* %2, align 4
  store i32 1, i32* %3, align 4
  store i32 1, i32* %4, align 4
  %7 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([7 x i8], [7 x i8]* @.str, i64 0, i64 0), i32* noundef %5, i32* noundef %2, i32* noundef %3)
  br label %8

8:                                                ; preds = %12, %0
  %9 = load i32, i32* %4, align 4
  %10 = load i32, i32* %5, align 4
  %11 = icmp slt i32 %9, %10
  br i1 %11, label %12, label %22

12:                                               ; preds = %8
  %13 = load i32, i32* %3, align 4
  store i32 %13, i32* %6, align 4
  %14 = load i32, i32* %2, align 4
  %15 = load i32, i32* %3, align 4
  %16 = add nsw i32 %14, %15
  store i32 %16, i32* %3, align 4
  %17 = load i32, i32* %3, align 4
  %18 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([4 x i8], [4 x i8]* @.str.1, i64 0, i64 0), i32 noundef %17)
  %19 = load i32, i32* %6, align 4
  store i32 %19, i32* %2, align 4
  %20 = load i32, i32* %4, align 4
  %21 = add nsw i32 %20, 1
  store i32 %21, i32* %4, align 4
  br label %8, !llvm.loop !6

22:                                               ; preds = %8
  %23 = load i32, i32* %1, align 4
  ret i32 %23
}
*** IR Dump After Merge contiguous icmps into a memcmp (mergeicmps) ***
; Function Attrs: noinline nounwind optnone sspstrong uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  %6 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  store i32 0, i32* %2, align 4
  store i32 1, i32* %3, align 4
  store i32 1, i32* %4, align 4
  %7 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([7 x i8], [7 x i8]* @.str, i64 0, i64 0), i32* noundef %5, i32* noundef %2, i32* noundef %3)
  br label %8

8:                                                ; preds = %12, %0
  %9 = load i32, i32* %4, align 4
  %10 = load i32, i32* %5, align 4
  %11 = icmp slt i32 %9, %10
  br i1 %11, label %12, label %22

12:                                               ; preds = %8
  %13 = load i32, i32* %3, align 4
  store i32 %13, i32* %6, align 4
  %14 = load i32, i32* %2, align 4
  %15 = load i32, i32* %3, align 4
  %16 = add nsw i32 %14, %15
  store i32 %16, i32* %3, align 4
  %17 = load i32, i32* %3, align 4
  %18 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([4 x i8], [4 x i8]* @.str.1, i64 0, i64 0), i32 noundef %17)
  %19 = load i32, i32* %6, align 4
  store i32 %19, i32* %2, align 4
  %20 = load i32, i32* %4, align 4
  %21 = add nsw i32 %20, 1
  store i32 %21, i32* %4, align 4
  br label %8, !llvm.loop !6

22:                                               ; preds = %8
  %23 = load i32, i32* %1, align 4
  ret i32 %23
}
*** IR Dump Before Expand memcmp() to load/stores (expandmemcmp) ***
; Function Attrs: noinline nounwind optnone sspstrong uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  %6 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  store i32 0, i32* %2, align 4
  store i32 1, i32* %3, align 4
  store i32 1, i32* %4, align 4
  %7 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([7 x i8], [7 x i8]* @.str, i64 0, i64 0), i32* noundef %5, i32* noundef %2, i32* noundef %3)
  br label %8

8:                                                ; preds = %12, %0
  %9 = load i32, i32* %4, align 4
  %10 = load i32, i32* %5, align 4
  %11 = icmp slt i32 %9, %10
  br i1 %11, label %12, label %22

12:                                               ; preds = %8
  %13 = load i32, i32* %3, align 4
  store i32 %13, i32* %6, align 4
  %14 = load i32, i32* %2, align 4
  %15 = load i32, i32* %3, align 4
  %16 = add nsw i32 %14, %15
  store i32 %16, i32* %3, align 4
  %17 = load i32, i32* %3, align 4
  %18 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([4 x i8], [4 x i8]* @.str.1, i64 0, i64 0), i32 noundef %17)
  %19 = load i32, i32* %6, align 4
  store i32 %19, i32* %2, align 4
  %20 = load i32, i32* %4, align 4
  %21 = add nsw i32 %20, 1
  store i32 %21, i32* %4, align 4
  br label %8, !llvm.loop !6

22:                                               ; preds = %8
  %23 = load i32, i32* %1, align 4
  ret i32 %23
}
*** IR Dump After Expand memcmp() to load/stores (expandmemcmp) ***
; Function Attrs: noinline nounwind optnone sspstrong uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  %6 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  store i32 0, i32* %2, align 4
  store i32 1, i32* %3, align 4
  store i32 1, i32* %4, align 4
  %7 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([7 x i8], [7 x i8]* @.str, i64 0, i64 0), i32* noundef %5, i32* noundef %2, i32* noundef %3)
  br label %8

8:                                                ; preds = %12, %0
  %9 = load i32, i32* %4, align 4
  %10 = load i32, i32* %5, align 4
  %11 = icmp slt i32 %9, %10
  br i1 %11, label %12, label %22

12:                                               ; preds = %8
  %13 = load i32, i32* %3, align 4
  store i32 %13, i32* %6, align 4
  %14 = load i32, i32* %2, align 4
  %15 = load i32, i32* %3, align 4
  %16 = add nsw i32 %14, %15
  store i32 %16, i32* %3, align 4
  %17 = load i32, i32* %3, align 4
  %18 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([4 x i8], [4 x i8]* @.str.1, i64 0, i64 0), i32 noundef %17)
  %19 = load i32, i32* %6, align 4
  store i32 %19, i32* %2, align 4
  %20 = load i32, i32* %4, align 4
  %21 = add nsw i32 %20, 1
  store i32 %21, i32* %4, align 4
  br label %8, !llvm.loop !6

22:                                               ; preds = %8
  %23 = load i32, i32* %1, align 4
  ret i32 %23
}
*** IR Dump Before Lower Garbage Collection Instructions (gc-lowering) ***
; Function Attrs: noinline nounwind optnone sspstrong uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  %6 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  store i32 0, i32* %2, align 4
  store i32 1, i32* %3, align 4
  store i32 1, i32* %4, align 4
  %7 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([7 x i8], [7 x i8]* @.str, i64 0, i64 0), i32* noundef %5, i32* noundef %2, i32* noundef %3)
  br label %8

8:                                                ; preds = %12, %0
  %9 = load i32, i32* %4, align 4
  %10 = load i32, i32* %5, align 4
  %11 = icmp slt i32 %9, %10
  br i1 %11, label %12, label %22

12:                                               ; preds = %8
  %13 = load i32, i32* %3, align 4
  store i32 %13, i32* %6, align 4
  %14 = load i32, i32* %2, align 4
  %15 = load i32, i32* %3, align 4
  %16 = add nsw i32 %14, %15
  store i32 %16, i32* %3, align 4
  %17 = load i32, i32* %3, align 4
  %18 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([4 x i8], [4 x i8]* @.str.1, i64 0, i64 0), i32 noundef %17)
  %19 = load i32, i32* %6, align 4
  store i32 %19, i32* %2, align 4
  %20 = load i32, i32* %4, align 4
  %21 = add nsw i32 %20, 1
  store i32 %21, i32* %4, align 4
  br label %8, !llvm.loop !6

22:                                               ; preds = %8
  %23 = load i32, i32* %1, align 4
  ret i32 %23
}
*** IR Dump After Lower Garbage Collection Instructions (gc-lowering) ***
; Function Attrs: noinline nounwind optnone sspstrong uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  %6 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  store i32 0, i32* %2, align 4
  store i32 1, i32* %3, align 4
  store i32 1, i32* %4, align 4
  %7 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([7 x i8], [7 x i8]* @.str, i64 0, i64 0), i32* noundef %5, i32* noundef %2, i32* noundef %3)
  br label %8

8:                                                ; preds = %12, %0
  %9 = load i32, i32* %4, align 4
  %10 = load i32, i32* %5, align 4
  %11 = icmp slt i32 %9, %10
  br i1 %11, label %12, label %22

12:                                               ; preds = %8
  %13 = load i32, i32* %3, align 4
  store i32 %13, i32* %6, align 4
  %14 = load i32, i32* %2, align 4
  %15 = load i32, i32* %3, align 4
  %16 = add nsw i32 %14, %15
  store i32 %16, i32* %3, align 4
  %17 = load i32, i32* %3, align 4
  %18 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([4 x i8], [4 x i8]* @.str.1, i64 0, i64 0), i32 noundef %17)
  %19 = load i32, i32* %6, align 4
  store i32 %19, i32* %2, align 4
  %20 = load i32, i32* %4, align 4
  %21 = add nsw i32 %20, 1
  store i32 %21, i32* %4, align 4
  br label %8, !llvm.loop !6

22:                                               ; preds = %8
  %23 = load i32, i32* %1, align 4
  ret i32 %23
}
*** IR Dump Before Shadow Stack GC Lowering (shadow-stack-gc-lowering) ***
; Function Attrs: noinline nounwind optnone sspstrong uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  %6 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  store i32 0, i32* %2, align 4
  store i32 1, i32* %3, align 4
  store i32 1, i32* %4, align 4
  %7 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([7 x i8], [7 x i8]* @.str, i64 0, i64 0), i32* noundef %5, i32* noundef %2, i32* noundef %3)
  br label %8

8:                                                ; preds = %12, %0
  %9 = load i32, i32* %4, align 4
  %10 = load i32, i32* %5, align 4
  %11 = icmp slt i32 %9, %10
  br i1 %11, label %12, label %22

12:                                               ; preds = %8
  %13 = load i32, i32* %3, align 4
  store i32 %13, i32* %6, align 4
  %14 = load i32, i32* %2, align 4
  %15 = load i32, i32* %3, align 4
  %16 = add nsw i32 %14, %15
  store i32 %16, i32* %3, align 4
  %17 = load i32, i32* %3, align 4
  %18 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([4 x i8], [4 x i8]* @.str.1, i64 0, i64 0), i32 noundef %17)
  %19 = load i32, i32* %6, align 4
  store i32 %19, i32* %2, align 4
  %20 = load i32, i32* %4, align 4
  %21 = add nsw i32 %20, 1
  store i32 %21, i32* %4, align 4
  br label %8, !llvm.loop !6

22:                                               ; preds = %8
  %23 = load i32, i32* %1, align 4
  ret i32 %23
}
*** IR Dump After Shadow Stack GC Lowering (shadow-stack-gc-lowering) ***
; Function Attrs: noinline nounwind optnone sspstrong uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  %6 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  store i32 0, i32* %2, align 4
  store i32 1, i32* %3, align 4
  store i32 1, i32* %4, align 4
  %7 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([7 x i8], [7 x i8]* @.str, i64 0, i64 0), i32* noundef %5, i32* noundef %2, i32* noundef %3)
  br label %8

8:                                                ; preds = %12, %0
  %9 = load i32, i32* %4, align 4
  %10 = load i32, i32* %5, align 4
  %11 = icmp slt i32 %9, %10
  br i1 %11, label %12, label %22

12:                                               ; preds = %8
  %13 = load i32, i32* %3, align 4
  store i32 %13, i32* %6, align 4
  %14 = load i32, i32* %2, align 4
  %15 = load i32, i32* %3, align 4
  %16 = add nsw i32 %14, %15
  store i32 %16, i32* %3, align 4
  %17 = load i32, i32* %3, align 4
  %18 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([4 x i8], [4 x i8]* @.str.1, i64 0, i64 0), i32 noundef %17)
  %19 = load i32, i32* %6, align 4
  store i32 %19, i32* %2, align 4
  %20 = load i32, i32* %4, align 4
  %21 = add nsw i32 %20, 1
  store i32 %21, i32* %4, align 4
  br label %8, !llvm.loop !6

22:                                               ; preds = %8
  %23 = load i32, i32* %1, align 4
  ret i32 %23
}
*** IR Dump Before Lower constant intrinsics (lower-constant-intrinsics) ***
; Function Attrs: noinline nounwind optnone sspstrong uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  %6 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  store i32 0, i32* %2, align 4
  store i32 1, i32* %3, align 4
  store i32 1, i32* %4, align 4
  %7 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([7 x i8], [7 x i8]* @.str, i64 0, i64 0), i32* noundef %5, i32* noundef %2, i32* noundef %3)
  br label %8

8:                                                ; preds = %12, %0
  %9 = load i32, i32* %4, align 4
  %10 = load i32, i32* %5, align 4
  %11 = icmp slt i32 %9, %10
  br i1 %11, label %12, label %22

12:                                               ; preds = %8
  %13 = load i32, i32* %3, align 4
  store i32 %13, i32* %6, align 4
  %14 = load i32, i32* %2, align 4
  %15 = load i32, i32* %3, align 4
  %16 = add nsw i32 %14, %15
  store i32 %16, i32* %3, align 4
  %17 = load i32, i32* %3, align 4
  %18 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([4 x i8], [4 x i8]* @.str.1, i64 0, i64 0), i32 noundef %17)
  %19 = load i32, i32* %6, align 4
  store i32 %19, i32* %2, align 4
  %20 = load i32, i32* %4, align 4
  %21 = add nsw i32 %20, 1
  store i32 %21, i32* %4, align 4
  br label %8, !llvm.loop !6

22:                                               ; preds = %8
  %23 = load i32, i32* %1, align 4
  ret i32 %23
}
*** IR Dump After Lower constant intrinsics (lower-constant-intrinsics) ***
; Function Attrs: noinline nounwind optnone sspstrong uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  %6 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  store i32 0, i32* %2, align 4
  store i32 1, i32* %3, align 4
  store i32 1, i32* %4, align 4
  %7 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([7 x i8], [7 x i8]* @.str, i64 0, i64 0), i32* noundef %5, i32* noundef %2, i32* noundef %3)
  br label %8

8:                                                ; preds = %12, %0
  %9 = load i32, i32* %4, align 4
  %10 = load i32, i32* %5, align 4
  %11 = icmp slt i32 %9, %10
  br i1 %11, label %12, label %22

12:                                               ; preds = %8
  %13 = load i32, i32* %3, align 4
  store i32 %13, i32* %6, align 4
  %14 = load i32, i32* %2, align 4
  %15 = load i32, i32* %3, align 4
  %16 = add nsw i32 %14, %15
  store i32 %16, i32* %3, align 4
  %17 = load i32, i32* %3, align 4
  %18 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([4 x i8], [4 x i8]* @.str.1, i64 0, i64 0), i32 noundef %17)
  %19 = load i32, i32* %6, align 4
  store i32 %19, i32* %2, align 4
  %20 = load i32, i32* %4, align 4
  %21 = add nsw i32 %20, 1
  store i32 %21, i32* %4, align 4
  br label %8, !llvm.loop !6

22:                                               ; preds = %8
  %23 = load i32, i32* %1, align 4
  ret i32 %23
}
*** IR Dump Before Remove unreachable blocks from the CFG (unreachableblockelim) ***
; Function Attrs: noinline nounwind optnone sspstrong uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  %6 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  store i32 0, i32* %2, align 4
  store i32 1, i32* %3, align 4
  store i32 1, i32* %4, align 4
  %7 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([7 x i8], [7 x i8]* @.str, i64 0, i64 0), i32* noundef %5, i32* noundef %2, i32* noundef %3)
  br label %8

8:                                                ; preds = %12, %0
  %9 = load i32, i32* %4, align 4
  %10 = load i32, i32* %5, align 4
  %11 = icmp slt i32 %9, %10
  br i1 %11, label %12, label %22

12:                                               ; preds = %8
  %13 = load i32, i32* %3, align 4
  store i32 %13, i32* %6, align 4
  %14 = load i32, i32* %2, align 4
  %15 = load i32, i32* %3, align 4
  %16 = add nsw i32 %14, %15
  store i32 %16, i32* %3, align 4
  %17 = load i32, i32* %3, align 4
  %18 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([4 x i8], [4 x i8]* @.str.1, i64 0, i64 0), i32 noundef %17)
  %19 = load i32, i32* %6, align 4
  store i32 %19, i32* %2, align 4
  %20 = load i32, i32* %4, align 4
  %21 = add nsw i32 %20, 1
  store i32 %21, i32* %4, align 4
  br label %8, !llvm.loop !6

22:                                               ; preds = %8
  %23 = load i32, i32* %1, align 4
  ret i32 %23
}
*** IR Dump After Remove unreachable blocks from the CFG (unreachableblockelim) ***
; Function Attrs: noinline nounwind optnone sspstrong uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  %6 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  store i32 0, i32* %2, align 4
  store i32 1, i32* %3, align 4
  store i32 1, i32* %4, align 4
  %7 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([7 x i8], [7 x i8]* @.str, i64 0, i64 0), i32* noundef %5, i32* noundef %2, i32* noundef %3)
  br label %8

8:                                                ; preds = %12, %0
  %9 = load i32, i32* %4, align 4
  %10 = load i32, i32* %5, align 4
  %11 = icmp slt i32 %9, %10
  br i1 %11, label %12, label %22

12:                                               ; preds = %8
  %13 = load i32, i32* %3, align 4
  store i32 %13, i32* %6, align 4
  %14 = load i32, i32* %2, align 4
  %15 = load i32, i32* %3, align 4
  %16 = add nsw i32 %14, %15
  store i32 %16, i32* %3, align 4
  %17 = load i32, i32* %3, align 4
  %18 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([4 x i8], [4 x i8]* @.str.1, i64 0, i64 0), i32 noundef %17)
  %19 = load i32, i32* %6, align 4
  store i32 %19, i32* %2, align 4
  %20 = load i32, i32* %4, align 4
  %21 = add nsw i32 %20, 1
  store i32 %21, i32* %4, align 4
  br label %8, !llvm.loop !6

22:                                               ; preds = %8
  %23 = load i32, i32* %1, align 4
  ret i32 %23
}
*** IR Dump Before Constant Hoisting (consthoist) ***
; Function Attrs: noinline nounwind optnone sspstrong uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  %6 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  store i32 0, i32* %2, align 4
  store i32 1, i32* %3, align 4
  store i32 1, i32* %4, align 4
  %7 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([7 x i8], [7 x i8]* @.str, i64 0, i64 0), i32* noundef %5, i32* noundef %2, i32* noundef %3)
  br label %8

8:                                                ; preds = %12, %0
  %9 = load i32, i32* %4, align 4
  %10 = load i32, i32* %5, align 4
  %11 = icmp slt i32 %9, %10
  br i1 %11, label %12, label %22

12:                                               ; preds = %8
  %13 = load i32, i32* %3, align 4
  store i32 %13, i32* %6, align 4
  %14 = load i32, i32* %2, align 4
  %15 = load i32, i32* %3, align 4
  %16 = add nsw i32 %14, %15
  store i32 %16, i32* %3, align 4
  %17 = load i32, i32* %3, align 4
  %18 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([4 x i8], [4 x i8]* @.str.1, i64 0, i64 0), i32 noundef %17)
  %19 = load i32, i32* %6, align 4
  store i32 %19, i32* %2, align 4
  %20 = load i32, i32* %4, align 4
  %21 = add nsw i32 %20, 1
  store i32 %21, i32* %4, align 4
  br label %8, !llvm.loop !6

22:                                               ; preds = %8
  %23 = load i32, i32* %1, align 4
  ret i32 %23
}
*** IR Dump After Constant Hoisting (consthoist) ***
; Function Attrs: noinline nounwind optnone sspstrong uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  %6 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  store i32 0, i32* %2, align 4
  store i32 1, i32* %3, align 4
  store i32 1, i32* %4, align 4
  %7 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([7 x i8], [7 x i8]* @.str, i64 0, i64 0), i32* noundef %5, i32* noundef %2, i32* noundef %3)
  br label %8

8:                                                ; preds = %12, %0
  %9 = load i32, i32* %4, align 4
  %10 = load i32, i32* %5, align 4
  %11 = icmp slt i32 %9, %10
  br i1 %11, label %12, label %22

12:                                               ; preds = %8
  %13 = load i32, i32* %3, align 4
  store i32 %13, i32* %6, align 4
  %14 = load i32, i32* %2, align 4
  %15 = load i32, i32* %3, align 4
  %16 = add nsw i32 %14, %15
  store i32 %16, i32* %3, align 4
  %17 = load i32, i32* %3, align 4
  %18 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([4 x i8], [4 x i8]* @.str.1, i64 0, i64 0), i32 noundef %17)
  %19 = load i32, i32* %6, align 4
  store i32 %19, i32* %2, align 4
  %20 = load i32, i32* %4, align 4
  %21 = add nsw i32 %20, 1
  store i32 %21, i32* %4, align 4
  br label %8, !llvm.loop !6

22:                                               ; preds = %8
  %23 = load i32, i32* %1, align 4
  ret i32 %23
}
*** IR Dump Before Replace intrinsics with calls to vector library (replace-with-veclib) ***
; Function Attrs: noinline nounwind optnone sspstrong uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  %6 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  store i32 0, i32* %2, align 4
  store i32 1, i32* %3, align 4
  store i32 1, i32* %4, align 4
  %7 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([7 x i8], [7 x i8]* @.str, i64 0, i64 0), i32* noundef %5, i32* noundef %2, i32* noundef %3)
  br label %8

8:                                                ; preds = %12, %0
  %9 = load i32, i32* %4, align 4
  %10 = load i32, i32* %5, align 4
  %11 = icmp slt i32 %9, %10
  br i1 %11, label %12, label %22

12:                                               ; preds = %8
  %13 = load i32, i32* %3, align 4
  store i32 %13, i32* %6, align 4
  %14 = load i32, i32* %2, align 4
  %15 = load i32, i32* %3, align 4
  %16 = add nsw i32 %14, %15
  store i32 %16, i32* %3, align 4
  %17 = load i32, i32* %3, align 4
  %18 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([4 x i8], [4 x i8]* @.str.1, i64 0, i64 0), i32 noundef %17)
  %19 = load i32, i32* %6, align 4
  store i32 %19, i32* %2, align 4
  %20 = load i32, i32* %4, align 4
  %21 = add nsw i32 %20, 1
  store i32 %21, i32* %4, align 4
  br label %8, !llvm.loop !6

22:                                               ; preds = %8
  %23 = load i32, i32* %1, align 4
  ret i32 %23
}
*** IR Dump After Replace intrinsics with calls to vector library (replace-with-veclib) ***
; Function Attrs: noinline nounwind optnone sspstrong uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  %6 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  store i32 0, i32* %2, align 4
  store i32 1, i32* %3, align 4
  store i32 1, i32* %4, align 4
  %7 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([7 x i8], [7 x i8]* @.str, i64 0, i64 0), i32* noundef %5, i32* noundef %2, i32* noundef %3)
  br label %8

8:                                                ; preds = %12, %0
  %9 = load i32, i32* %4, align 4
  %10 = load i32, i32* %5, align 4
  %11 = icmp slt i32 %9, %10
  br i1 %11, label %12, label %22

12:                                               ; preds = %8
  %13 = load i32, i32* %3, align 4
  store i32 %13, i32* %6, align 4
  %14 = load i32, i32* %2, align 4
  %15 = load i32, i32* %3, align 4
  %16 = add nsw i32 %14, %15
  store i32 %16, i32* %3, align 4
  %17 = load i32, i32* %3, align 4
  %18 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([4 x i8], [4 x i8]* @.str.1, i64 0, i64 0), i32 noundef %17)
  %19 = load i32, i32* %6, align 4
  store i32 %19, i32* %2, align 4
  %20 = load i32, i32* %4, align 4
  %21 = add nsw i32 %20, 1
  store i32 %21, i32* %4, align 4
  br label %8, !llvm.loop !6

22:                                               ; preds = %8
  %23 = load i32, i32* %1, align 4
  ret i32 %23
}
*** IR Dump Before Partially inline calls to library functions (partially-inline-libcalls) ***
; Function Attrs: noinline nounwind optnone sspstrong uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  %6 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  store i32 0, i32* %2, align 4
  store i32 1, i32* %3, align 4
  store i32 1, i32* %4, align 4
  %7 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([7 x i8], [7 x i8]* @.str, i64 0, i64 0), i32* noundef %5, i32* noundef %2, i32* noundef %3)
  br label %8

8:                                                ; preds = %12, %0
  %9 = load i32, i32* %4, align 4
  %10 = load i32, i32* %5, align 4
  %11 = icmp slt i32 %9, %10
  br i1 %11, label %12, label %22

12:                                               ; preds = %8
  %13 = load i32, i32* %3, align 4
  store i32 %13, i32* %6, align 4
  %14 = load i32, i32* %2, align 4
  %15 = load i32, i32* %3, align 4
  %16 = add nsw i32 %14, %15
  store i32 %16, i32* %3, align 4
  %17 = load i32, i32* %3, align 4
  %18 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([4 x i8], [4 x i8]* @.str.1, i64 0, i64 0), i32 noundef %17)
  %19 = load i32, i32* %6, align 4
  store i32 %19, i32* %2, align 4
  %20 = load i32, i32* %4, align 4
  %21 = add nsw i32 %20, 1
  store i32 %21, i32* %4, align 4
  br label %8, !llvm.loop !6

22:                                               ; preds = %8
  %23 = load i32, i32* %1, align 4
  ret i32 %23
}
*** IR Dump After Partially inline calls to library functions (partially-inline-libcalls) ***
; Function Attrs: noinline nounwind optnone sspstrong uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  %6 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  store i32 0, i32* %2, align 4
  store i32 1, i32* %3, align 4
  store i32 1, i32* %4, align 4
  %7 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([7 x i8], [7 x i8]* @.str, i64 0, i64 0), i32* noundef %5, i32* noundef %2, i32* noundef %3)
  br label %8

8:                                                ; preds = %12, %0
  %9 = load i32, i32* %4, align 4
  %10 = load i32, i32* %5, align 4
  %11 = icmp slt i32 %9, %10
  br i1 %11, label %12, label %22

12:                                               ; preds = %8
  %13 = load i32, i32* %3, align 4
  store i32 %13, i32* %6, align 4
  %14 = load i32, i32* %2, align 4
  %15 = load i32, i32* %3, align 4
  %16 = add nsw i32 %14, %15
  store i32 %16, i32* %3, align 4
  %17 = load i32, i32* %3, align 4
  %18 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([4 x i8], [4 x i8]* @.str.1, i64 0, i64 0), i32 noundef %17)
  %19 = load i32, i32* %6, align 4
  store i32 %19, i32* %2, align 4
  %20 = load i32, i32* %4, align 4
  %21 = add nsw i32 %20, 1
  store i32 %21, i32* %4, align 4
  br label %8, !llvm.loop !6

22:                                               ; preds = %8
  %23 = load i32, i32* %1, align 4
  ret i32 %23
}
*** IR Dump Before Expand vector predication intrinsics (expandvp) ***
; Function Attrs: noinline nounwind optnone sspstrong uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  %6 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  store i32 0, i32* %2, align 4
  store i32 1, i32* %3, align 4
  store i32 1, i32* %4, align 4
  %7 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([7 x i8], [7 x i8]* @.str, i64 0, i64 0), i32* noundef %5, i32* noundef %2, i32* noundef %3)
  br label %8

8:                                                ; preds = %12, %0
  %9 = load i32, i32* %4, align 4
  %10 = load i32, i32* %5, align 4
  %11 = icmp slt i32 %9, %10
  br i1 %11, label %12, label %22

12:                                               ; preds = %8
  %13 = load i32, i32* %3, align 4
  store i32 %13, i32* %6, align 4
  %14 = load i32, i32* %2, align 4
  %15 = load i32, i32* %3, align 4
  %16 = add nsw i32 %14, %15
  store i32 %16, i32* %3, align 4
  %17 = load i32, i32* %3, align 4
  %18 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([4 x i8], [4 x i8]* @.str.1, i64 0, i64 0), i32 noundef %17)
  %19 = load i32, i32* %6, align 4
  store i32 %19, i32* %2, align 4
  %20 = load i32, i32* %4, align 4
  %21 = add nsw i32 %20, 1
  store i32 %21, i32* %4, align 4
  br label %8, !llvm.loop !6

22:                                               ; preds = %8
  %23 = load i32, i32* %1, align 4
  ret i32 %23
}
*** IR Dump After Expand vector predication intrinsics (expandvp) ***
; Function Attrs: noinline nounwind optnone sspstrong uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  %6 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  store i32 0, i32* %2, align 4
  store i32 1, i32* %3, align 4
  store i32 1, i32* %4, align 4
  %7 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([7 x i8], [7 x i8]* @.str, i64 0, i64 0), i32* noundef %5, i32* noundef %2, i32* noundef %3)
  br label %8

8:                                                ; preds = %12, %0
  %9 = load i32, i32* %4, align 4
  %10 = load i32, i32* %5, align 4
  %11 = icmp slt i32 %9, %10
  br i1 %11, label %12, label %22

12:                                               ; preds = %8
  %13 = load i32, i32* %3, align 4
  store i32 %13, i32* %6, align 4
  %14 = load i32, i32* %2, align 4
  %15 = load i32, i32* %3, align 4
  %16 = add nsw i32 %14, %15
  store i32 %16, i32* %3, align 4
  %17 = load i32, i32* %3, align 4
  %18 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([4 x i8], [4 x i8]* @.str.1, i64 0, i64 0), i32 noundef %17)
  %19 = load i32, i32* %6, align 4
  store i32 %19, i32* %2, align 4
  %20 = load i32, i32* %4, align 4
  %21 = add nsw i32 %20, 1
  store i32 %21, i32* %4, align 4
  br label %8, !llvm.loop !6

22:                                               ; preds = %8
  %23 = load i32, i32* %1, align 4
  ret i32 %23
}
*** IR Dump Before Scalarize Masked Memory Intrinsics (scalarize-masked-mem-intrin) ***
; Function Attrs: noinline nounwind optnone sspstrong uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  %6 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  store i32 0, i32* %2, align 4
  store i32 1, i32* %3, align 4
  store i32 1, i32* %4, align 4
  %7 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([7 x i8], [7 x i8]* @.str, i64 0, i64 0), i32* noundef %5, i32* noundef %2, i32* noundef %3)
  br label %8

8:                                                ; preds = %12, %0
  %9 = load i32, i32* %4, align 4
  %10 = load i32, i32* %5, align 4
  %11 = icmp slt i32 %9, %10
  br i1 %11, label %12, label %22

12:                                               ; preds = %8
  %13 = load i32, i32* %3, align 4
  store i32 %13, i32* %6, align 4
  %14 = load i32, i32* %2, align 4
  %15 = load i32, i32* %3, align 4
  %16 = add nsw i32 %14, %15
  store i32 %16, i32* %3, align 4
  %17 = load i32, i32* %3, align 4
  %18 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([4 x i8], [4 x i8]* @.str.1, i64 0, i64 0), i32 noundef %17)
  %19 = load i32, i32* %6, align 4
  store i32 %19, i32* %2, align 4
  %20 = load i32, i32* %4, align 4
  %21 = add nsw i32 %20, 1
  store i32 %21, i32* %4, align 4
  br label %8, !llvm.loop !6

22:                                               ; preds = %8
  %23 = load i32, i32* %1, align 4
  ret i32 %23
}
*** IR Dump After Scalarize Masked Memory Intrinsics (scalarize-masked-mem-intrin) ***
; Function Attrs: noinline nounwind optnone sspstrong uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  %6 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  store i32 0, i32* %2, align 4
  store i32 1, i32* %3, align 4
  store i32 1, i32* %4, align 4
  %7 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([7 x i8], [7 x i8]* @.str, i64 0, i64 0), i32* noundef %5, i32* noundef %2, i32* noundef %3)
  br label %8

8:                                                ; preds = %12, %0
  %9 = load i32, i32* %4, align 4
  %10 = load i32, i32* %5, align 4
  %11 = icmp slt i32 %9, %10
  br i1 %11, label %12, label %22

12:                                               ; preds = %8
  %13 = load i32, i32* %3, align 4
  store i32 %13, i32* %6, align 4
  %14 = load i32, i32* %2, align 4
  %15 = load i32, i32* %3, align 4
  %16 = add nsw i32 %14, %15
  store i32 %16, i32* %3, align 4
  %17 = load i32, i32* %3, align 4
  %18 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([4 x i8], [4 x i8]* @.str.1, i64 0, i64 0), i32 noundef %17)
  %19 = load i32, i32* %6, align 4
  store i32 %19, i32* %2, align 4
  %20 = load i32, i32* %4, align 4
  %21 = add nsw i32 %20, 1
  store i32 %21, i32* %4, align 4
  br label %8, !llvm.loop !6

22:                                               ; preds = %8
  %23 = load i32, i32* %1, align 4
  ret i32 %23
}
*** IR Dump Before Expand reduction intrinsics (expand-reductions) ***
; Function Attrs: noinline nounwind optnone sspstrong uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  %6 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  store i32 0, i32* %2, align 4
  store i32 1, i32* %3, align 4
  store i32 1, i32* %4, align 4
  %7 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([7 x i8], [7 x i8]* @.str, i64 0, i64 0), i32* noundef %5, i32* noundef %2, i32* noundef %3)
  br label %8

8:                                                ; preds = %12, %0
  %9 = load i32, i32* %4, align 4
  %10 = load i32, i32* %5, align 4
  %11 = icmp slt i32 %9, %10
  br i1 %11, label %12, label %22

12:                                               ; preds = %8
  %13 = load i32, i32* %3, align 4
  store i32 %13, i32* %6, align 4
  %14 = load i32, i32* %2, align 4
  %15 = load i32, i32* %3, align 4
  %16 = add nsw i32 %14, %15
  store i32 %16, i32* %3, align 4
  %17 = load i32, i32* %3, align 4
  %18 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([4 x i8], [4 x i8]* @.str.1, i64 0, i64 0), i32 noundef %17)
  %19 = load i32, i32* %6, align 4
  store i32 %19, i32* %2, align 4
  %20 = load i32, i32* %4, align 4
  %21 = add nsw i32 %20, 1
  store i32 %21, i32* %4, align 4
  br label %8, !llvm.loop !6

22:                                               ; preds = %8
  %23 = load i32, i32* %1, align 4
  ret i32 %23
}
*** IR Dump After Expand reduction intrinsics (expand-reductions) ***
; Function Attrs: noinline nounwind optnone sspstrong uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  %6 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  store i32 0, i32* %2, align 4
  store i32 1, i32* %3, align 4
  store i32 1, i32* %4, align 4
  %7 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([7 x i8], [7 x i8]* @.str, i64 0, i64 0), i32* noundef %5, i32* noundef %2, i32* noundef %3)
  br label %8

8:                                                ; preds = %12, %0
  %9 = load i32, i32* %4, align 4
  %10 = load i32, i32* %5, align 4
  %11 = icmp slt i32 %9, %10
  br i1 %11, label %12, label %22

12:                                               ; preds = %8
  %13 = load i32, i32* %3, align 4
  store i32 %13, i32* %6, align 4
  %14 = load i32, i32* %2, align 4
  %15 = load i32, i32* %3, align 4
  %16 = add nsw i32 %14, %15
  store i32 %16, i32* %3, align 4
  %17 = load i32, i32* %3, align 4
  %18 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([4 x i8], [4 x i8]* @.str.1, i64 0, i64 0), i32 noundef %17)
  %19 = load i32, i32* %6, align 4
  store i32 %19, i32* %2, align 4
  %20 = load i32, i32* %4, align 4
  %21 = add nsw i32 %20, 1
  store i32 %21, i32* %4, align 4
  br label %8, !llvm.loop !6

22:                                               ; preds = %8
  %23 = load i32, i32* %1, align 4
  ret i32 %23
}
*** IR Dump Before Interleaved Access Pass (interleaved-access) ***
; Function Attrs: noinline nounwind optnone sspstrong uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  %6 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  store i32 0, i32* %2, align 4
  store i32 1, i32* %3, align 4
  store i32 1, i32* %4, align 4
  %7 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([7 x i8], [7 x i8]* @.str, i64 0, i64 0), i32* noundef %5, i32* noundef %2, i32* noundef %3)
  br label %8

8:                                                ; preds = %12, %0
  %9 = load i32, i32* %4, align 4
  %10 = load i32, i32* %5, align 4
  %11 = icmp slt i32 %9, %10
  br i1 %11, label %12, label %22

12:                                               ; preds = %8
  %13 = load i32, i32* %3, align 4
  store i32 %13, i32* %6, align 4
  %14 = load i32, i32* %2, align 4
  %15 = load i32, i32* %3, align 4
  %16 = add nsw i32 %14, %15
  store i32 %16, i32* %3, align 4
  %17 = load i32, i32* %3, align 4
  %18 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([4 x i8], [4 x i8]* @.str.1, i64 0, i64 0), i32 noundef %17)
  %19 = load i32, i32* %6, align 4
  store i32 %19, i32* %2, align 4
  %20 = load i32, i32* %4, align 4
  %21 = add nsw i32 %20, 1
  store i32 %21, i32* %4, align 4
  br label %8, !llvm.loop !6

22:                                               ; preds = %8
  %23 = load i32, i32* %1, align 4
  ret i32 %23
}
*** IR Dump After Interleaved Access Pass (interleaved-access) ***
; Function Attrs: noinline nounwind optnone sspstrong uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  %6 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  store i32 0, i32* %2, align 4
  store i32 1, i32* %3, align 4
  store i32 1, i32* %4, align 4
  %7 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([7 x i8], [7 x i8]* @.str, i64 0, i64 0), i32* noundef %5, i32* noundef %2, i32* noundef %3)
  br label %8

8:                                                ; preds = %12, %0
  %9 = load i32, i32* %4, align 4
  %10 = load i32, i32* %5, align 4
  %11 = icmp slt i32 %9, %10
  br i1 %11, label %12, label %22

12:                                               ; preds = %8
  %13 = load i32, i32* %3, align 4
  store i32 %13, i32* %6, align 4
  %14 = load i32, i32* %2, align 4
  %15 = load i32, i32* %3, align 4
  %16 = add nsw i32 %14, %15
  store i32 %16, i32* %3, align 4
  %17 = load i32, i32* %3, align 4
  %18 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([4 x i8], [4 x i8]* @.str.1, i64 0, i64 0), i32 noundef %17)
  %19 = load i32, i32* %6, align 4
  store i32 %19, i32* %2, align 4
  %20 = load i32, i32* %4, align 4
  %21 = add nsw i32 %20, 1
  store i32 %21, i32* %4, align 4
  br label %8, !llvm.loop !6

22:                                               ; preds = %8
  %23 = load i32, i32* %1, align 4
  ret i32 %23
}
*** IR Dump Before X86 Partial Reduction (x86-partial-reduction) ***
; Function Attrs: noinline nounwind optnone sspstrong uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  %6 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  store i32 0, i32* %2, align 4
  store i32 1, i32* %3, align 4
  store i32 1, i32* %4, align 4
  %7 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([7 x i8], [7 x i8]* @.str, i64 0, i64 0), i32* noundef %5, i32* noundef %2, i32* noundef %3)
  br label %8

8:                                                ; preds = %12, %0
  %9 = load i32, i32* %4, align 4
  %10 = load i32, i32* %5, align 4
  %11 = icmp slt i32 %9, %10
  br i1 %11, label %12, label %22

12:                                               ; preds = %8
  %13 = load i32, i32* %3, align 4
  store i32 %13, i32* %6, align 4
  %14 = load i32, i32* %2, align 4
  %15 = load i32, i32* %3, align 4
  %16 = add nsw i32 %14, %15
  store i32 %16, i32* %3, align 4
  %17 = load i32, i32* %3, align 4
  %18 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([4 x i8], [4 x i8]* @.str.1, i64 0, i64 0), i32 noundef %17)
  %19 = load i32, i32* %6, align 4
  store i32 %19, i32* %2, align 4
  %20 = load i32, i32* %4, align 4
  %21 = add nsw i32 %20, 1
  store i32 %21, i32* %4, align 4
  br label %8, !llvm.loop !6

22:                                               ; preds = %8
  %23 = load i32, i32* %1, align 4
  ret i32 %23
}
*** IR Dump After X86 Partial Reduction (x86-partial-reduction) ***
; Function Attrs: noinline nounwind optnone sspstrong uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  %6 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  store i32 0, i32* %2, align 4
  store i32 1, i32* %3, align 4
  store i32 1, i32* %4, align 4
  %7 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([7 x i8], [7 x i8]* @.str, i64 0, i64 0), i32* noundef %5, i32* noundef %2, i32* noundef %3)
  br label %8

8:                                                ; preds = %12, %0
  %9 = load i32, i32* %4, align 4
  %10 = load i32, i32* %5, align 4
  %11 = icmp slt i32 %9, %10
  br i1 %11, label %12, label %22

12:                                               ; preds = %8
  %13 = load i32, i32* %3, align 4
  store i32 %13, i32* %6, align 4
  %14 = load i32, i32* %2, align 4
  %15 = load i32, i32* %3, align 4
  %16 = add nsw i32 %14, %15
  store i32 %16, i32* %3, align 4
  %17 = load i32, i32* %3, align 4
  %18 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([4 x i8], [4 x i8]* @.str.1, i64 0, i64 0), i32 noundef %17)
  %19 = load i32, i32* %6, align 4
  store i32 %19, i32* %2, align 4
  %20 = load i32, i32* %4, align 4
  %21 = add nsw i32 %20, 1
  store i32 %21, i32* %4, align 4
  br label %8, !llvm.loop !6

22:                                               ; preds = %8
  %23 = load i32, i32* %1, align 4
  ret i32 %23
}
*** IR Dump Before Expand indirectbr instructions (indirectbr-expand) ***
; Function Attrs: noinline nounwind optnone sspstrong uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  %6 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  store i32 0, i32* %2, align 4
  store i32 1, i32* %3, align 4
  store i32 1, i32* %4, align 4
  %7 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([7 x i8], [7 x i8]* @.str, i64 0, i64 0), i32* noundef %5, i32* noundef %2, i32* noundef %3)
  br label %8

8:                                                ; preds = %12, %0
  %9 = load i32, i32* %4, align 4
  %10 = load i32, i32* %5, align 4
  %11 = icmp slt i32 %9, %10
  br i1 %11, label %12, label %22

12:                                               ; preds = %8
  %13 = load i32, i32* %3, align 4
  store i32 %13, i32* %6, align 4
  %14 = load i32, i32* %2, align 4
  %15 = load i32, i32* %3, align 4
  %16 = add nsw i32 %14, %15
  store i32 %16, i32* %3, align 4
  %17 = load i32, i32* %3, align 4
  %18 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([4 x i8], [4 x i8]* @.str.1, i64 0, i64 0), i32 noundef %17)
  %19 = load i32, i32* %6, align 4
  store i32 %19, i32* %2, align 4
  %20 = load i32, i32* %4, align 4
  %21 = add nsw i32 %20, 1
  store i32 %21, i32* %4, align 4
  br label %8, !llvm.loop !6

22:                                               ; preds = %8
  %23 = load i32, i32* %1, align 4
  ret i32 %23
}
*** IR Dump After Expand indirectbr instructions (indirectbr-expand) ***
; Function Attrs: noinline nounwind optnone sspstrong uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  %6 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  store i32 0, i32* %2, align 4
  store i32 1, i32* %3, align 4
  store i32 1, i32* %4, align 4
  %7 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([7 x i8], [7 x i8]* @.str, i64 0, i64 0), i32* noundef %5, i32* noundef %2, i32* noundef %3)
  br label %8

8:                                                ; preds = %12, %0
  %9 = load i32, i32* %4, align 4
  %10 = load i32, i32* %5, align 4
  %11 = icmp slt i32 %9, %10
  br i1 %11, label %12, label %22

12:                                               ; preds = %8
  %13 = load i32, i32* %3, align 4
  store i32 %13, i32* %6, align 4
  %14 = load i32, i32* %2, align 4
  %15 = load i32, i32* %3, align 4
  %16 = add nsw i32 %14, %15
  store i32 %16, i32* %3, align 4
  %17 = load i32, i32* %3, align 4
  %18 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([4 x i8], [4 x i8]* @.str.1, i64 0, i64 0), i32 noundef %17)
  %19 = load i32, i32* %6, align 4
  store i32 %19, i32* %2, align 4
  %20 = load i32, i32* %4, align 4
  %21 = add nsw i32 %20, 1
  store i32 %21, i32* %4, align 4
  br label %8, !llvm.loop !6

22:                                               ; preds = %8
  %23 = load i32, i32* %1, align 4
  ret i32 %23
}
*** IR Dump Before CodeGen Prepare (codegenprepare) ***
; Function Attrs: noinline nounwind optnone sspstrong uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  %6 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  store i32 0, i32* %2, align 4
  store i32 1, i32* %3, align 4
  store i32 1, i32* %4, align 4
  %7 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([7 x i8], [7 x i8]* @.str, i64 0, i64 0), i32* noundef %5, i32* noundef %2, i32* noundef %3)
  br label %8

8:                                                ; preds = %12, %0
  %9 = load i32, i32* %4, align 4
  %10 = load i32, i32* %5, align 4
  %11 = icmp slt i32 %9, %10
  br i1 %11, label %12, label %22

12:                                               ; preds = %8
  %13 = load i32, i32* %3, align 4
  store i32 %13, i32* %6, align 4
  %14 = load i32, i32* %2, align 4
  %15 = load i32, i32* %3, align 4
  %16 = add nsw i32 %14, %15
  store i32 %16, i32* %3, align 4
  %17 = load i32, i32* %3, align 4
  %18 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([4 x i8], [4 x i8]* @.str.1, i64 0, i64 0), i32 noundef %17)
  %19 = load i32, i32* %6, align 4
  store i32 %19, i32* %2, align 4
  %20 = load i32, i32* %4, align 4
  %21 = add nsw i32 %20, 1
  store i32 %21, i32* %4, align 4
  br label %8, !llvm.loop !6

22:                                               ; preds = %8
  %23 = load i32, i32* %1, align 4
  ret i32 %23
}
*** IR Dump After CodeGen Prepare (codegenprepare) ***
; Function Attrs: noinline nounwind optnone sspstrong uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  %6 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  store i32 0, i32* %2, align 4
  store i32 1, i32* %3, align 4
  store i32 1, i32* %4, align 4
  %7 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([7 x i8], [7 x i8]* @.str, i64 0, i64 0), i32* noundef %5, i32* noundef %2, i32* noundef %3)
  br label %8

8:                                                ; preds = %12, %0
  %9 = load i32, i32* %4, align 4
  %10 = load i32, i32* %5, align 4
  %11 = icmp slt i32 %9, %10
  br i1 %11, label %12, label %22

12:                                               ; preds = %8
  %13 = load i32, i32* %3, align 4
  store i32 %13, i32* %6, align 4
  %14 = load i32, i32* %2, align 4
  %15 = load i32, i32* %3, align 4
  %16 = add nsw i32 %14, %15
  store i32 %16, i32* %3, align 4
  %17 = load i32, i32* %3, align 4
  %18 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([4 x i8], [4 x i8]* @.str.1, i64 0, i64 0), i32 noundef %17)
  %19 = load i32, i32* %6, align 4
  store i32 %19, i32* %2, align 4
  %20 = load i32, i32* %4, align 4
  %21 = add nsw i32 %20, 1
  store i32 %21, i32* %4, align 4
  br label %8, !llvm.loop !6

22:                                               ; preds = %8
  %23 = load i32, i32* %1, align 4
  ret i32 %23
}
*** IR Dump Before Exception handling preparation (dwarfehprepare) ***
; Function Attrs: noinline nounwind optnone sspstrong uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  %6 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  store i32 0, i32* %2, align 4
  store i32 1, i32* %3, align 4
  store i32 1, i32* %4, align 4
  %7 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([7 x i8], [7 x i8]* @.str, i64 0, i64 0), i32* noundef %5, i32* noundef %2, i32* noundef %3)
  br label %8

8:                                                ; preds = %12, %0
  %9 = load i32, i32* %4, align 4
  %10 = load i32, i32* %5, align 4
  %11 = icmp slt i32 %9, %10
  br i1 %11, label %12, label %22

12:                                               ; preds = %8
  %13 = load i32, i32* %3, align 4
  store i32 %13, i32* %6, align 4
  %14 = load i32, i32* %2, align 4
  %15 = load i32, i32* %3, align 4
  %16 = add nsw i32 %14, %15
  store i32 %16, i32* %3, align 4
  %17 = load i32, i32* %3, align 4
  %18 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([4 x i8], [4 x i8]* @.str.1, i64 0, i64 0), i32 noundef %17)
  %19 = load i32, i32* %6, align 4
  store i32 %19, i32* %2, align 4
  %20 = load i32, i32* %4, align 4
  %21 = add nsw i32 %20, 1
  store i32 %21, i32* %4, align 4
  br label %8, !llvm.loop !6

22:                                               ; preds = %8
  %23 = load i32, i32* %1, align 4
  ret i32 %23
}
*** IR Dump After Exception handling preparation (dwarfehprepare) ***
; Function Attrs: noinline nounwind optnone sspstrong uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  %6 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  store i32 0, i32* %2, align 4
  store i32 1, i32* %3, align 4
  store i32 1, i32* %4, align 4
  %7 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([7 x i8], [7 x i8]* @.str, i64 0, i64 0), i32* noundef %5, i32* noundef %2, i32* noundef %3)
  br label %8

8:                                                ; preds = %12, %0
  %9 = load i32, i32* %4, align 4
  %10 = load i32, i32* %5, align 4
  %11 = icmp slt i32 %9, %10
  br i1 %11, label %12, label %22

12:                                               ; preds = %8
  %13 = load i32, i32* %3, align 4
  store i32 %13, i32* %6, align 4
  %14 = load i32, i32* %2, align 4
  %15 = load i32, i32* %3, align 4
  %16 = add nsw i32 %14, %15
  store i32 %16, i32* %3, align 4
  %17 = load i32, i32* %3, align 4
  %18 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([4 x i8], [4 x i8]* @.str.1, i64 0, i64 0), i32 noundef %17)
  %19 = load i32, i32* %6, align 4
  store i32 %19, i32* %2, align 4
  %20 = load i32, i32* %4, align 4
  %21 = add nsw i32 %20, 1
  store i32 %21, i32* %4, align 4
  br label %8, !llvm.loop !6

22:                                               ; preds = %8
  %23 = load i32, i32* %1, align 4
  ret i32 %23
}
*** IR Dump Before Safe Stack instrumentation pass (safe-stack) ***
; Function Attrs: noinline nounwind optnone sspstrong uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  %6 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  store i32 0, i32* %2, align 4
  store i32 1, i32* %3, align 4
  store i32 1, i32* %4, align 4
  %7 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([7 x i8], [7 x i8]* @.str, i64 0, i64 0), i32* noundef %5, i32* noundef %2, i32* noundef %3)
  br label %8

8:                                                ; preds = %12, %0
  %9 = load i32, i32* %4, align 4
  %10 = load i32, i32* %5, align 4
  %11 = icmp slt i32 %9, %10
  br i1 %11, label %12, label %22

12:                                               ; preds = %8
  %13 = load i32, i32* %3, align 4
  store i32 %13, i32* %6, align 4
  %14 = load i32, i32* %2, align 4
  %15 = load i32, i32* %3, align 4
  %16 = add nsw i32 %14, %15
  store i32 %16, i32* %3, align 4
  %17 = load i32, i32* %3, align 4
  %18 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([4 x i8], [4 x i8]* @.str.1, i64 0, i64 0), i32 noundef %17)
  %19 = load i32, i32* %6, align 4
  store i32 %19, i32* %2, align 4
  %20 = load i32, i32* %4, align 4
  %21 = add nsw i32 %20, 1
  store i32 %21, i32* %4, align 4
  br label %8, !llvm.loop !6

22:                                               ; preds = %8
  %23 = load i32, i32* %1, align 4
  ret i32 %23
}
*** IR Dump After Safe Stack instrumentation pass (safe-stack) ***
; Function Attrs: noinline nounwind optnone sspstrong uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  %6 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  store i32 0, i32* %2, align 4
  store i32 1, i32* %3, align 4
  store i32 1, i32* %4, align 4
  %7 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([7 x i8], [7 x i8]* @.str, i64 0, i64 0), i32* noundef %5, i32* noundef %2, i32* noundef %3)
  br label %8

8:                                                ; preds = %12, %0
  %9 = load i32, i32* %4, align 4
  %10 = load i32, i32* %5, align 4
  %11 = icmp slt i32 %9, %10
  br i1 %11, label %12, label %22

12:                                               ; preds = %8
  %13 = load i32, i32* %3, align 4
  store i32 %13, i32* %6, align 4
  %14 = load i32, i32* %2, align 4
  %15 = load i32, i32* %3, align 4
  %16 = add nsw i32 %14, %15
  store i32 %16, i32* %3, align 4
  %17 = load i32, i32* %3, align 4
  %18 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([4 x i8], [4 x i8]* @.str.1, i64 0, i64 0), i32 noundef %17)
  %19 = load i32, i32* %6, align 4
  store i32 %19, i32* %2, align 4
  %20 = load i32, i32* %4, align 4
  %21 = add nsw i32 %20, 1
  store i32 %21, i32* %4, align 4
  br label %8, !llvm.loop !6

22:                                               ; preds = %8
  %23 = load i32, i32* %1, align 4
  ret i32 %23
}
*** IR Dump Before Module Verifier (verify) ***
; Function Attrs: noinline nounwind optnone sspstrong uwtable
define dso_local i32 @main() #0 {
  %StackGuardSlot = alloca i8*, align 8
  %StackGuard = load volatile i8*, i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*), align 8
  call void @llvm.stackprotector(i8* %StackGuard, i8** %StackGuardSlot)
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  %6 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  store i32 0, i32* %2, align 4
  store i32 1, i32* %3, align 4
  store i32 1, i32* %4, align 4
  %7 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([7 x i8], [7 x i8]* @.str, i64 0, i64 0), i32* noundef %5, i32* noundef %2, i32* noundef %3)
  br label %8

8:                                                ; preds = %12, %0
  %9 = load i32, i32* %4, align 4
  %10 = load i32, i32* %5, align 4
  %11 = icmp slt i32 %9, %10
  br i1 %11, label %12, label %22

12:                                               ; preds = %8
  %13 = load i32, i32* %3, align 4
  store i32 %13, i32* %6, align 4
  %14 = load i32, i32* %2, align 4
  %15 = load i32, i32* %3, align 4
  %16 = add nsw i32 %14, %15
  store i32 %16, i32* %3, align 4
  %17 = load i32, i32* %3, align 4
  %18 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([4 x i8], [4 x i8]* @.str.1, i64 0, i64 0), i32 noundef %17)
  %19 = load i32, i32* %6, align 4
  store i32 %19, i32* %2, align 4
  %20 = load i32, i32* %4, align 4
  %21 = add nsw i32 %20, 1
  store i32 %21, i32* %4, align 4
  br label %8, !llvm.loop !6

22:                                               ; preds = %8
  %23 = load i32, i32* %1, align 4
  %StackGuard1 = load volatile i8*, i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*), align 8
  %24 = load volatile i8*, i8** %StackGuardSlot, align 8
  %25 = icmp eq i8* %StackGuard1, %24
  br i1 %25, label %SP_return, label %CallStackCheckFailBlk, !prof !8

SP_return:                                        ; preds = %22
  ret i32 %23

CallStackCheckFailBlk:                            ; preds = %22
  call void @__stack_chk_fail()
  unreachable
}
*** IR Dump After Module Verifier (verify) ***
; Function Attrs: noinline nounwind optnone sspstrong uwtable
define dso_local i32 @main() #0 {
  %StackGuardSlot = alloca i8*, align 8
  %StackGuard = load volatile i8*, i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*), align 8
  call void @llvm.stackprotector(i8* %StackGuard, i8** %StackGuardSlot)
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  %6 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  store i32 0, i32* %2, align 4
  store i32 1, i32* %3, align 4
  store i32 1, i32* %4, align 4
  %7 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([7 x i8], [7 x i8]* @.str, i64 0, i64 0), i32* noundef %5, i32* noundef %2, i32* noundef %3)
  br label %8

8:                                                ; preds = %12, %0
  %9 = load i32, i32* %4, align 4
  %10 = load i32, i32* %5, align 4
  %11 = icmp slt i32 %9, %10
  br i1 %11, label %12, label %22

12:                                               ; preds = %8
  %13 = load i32, i32* %3, align 4
  store i32 %13, i32* %6, align 4
  %14 = load i32, i32* %2, align 4
  %15 = load i32, i32* %3, align 4
  %16 = add nsw i32 %14, %15
  store i32 %16, i32* %3, align 4
  %17 = load i32, i32* %3, align 4
  %18 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([4 x i8], [4 x i8]* @.str.1, i64 0, i64 0), i32 noundef %17)
  %19 = load i32, i32* %6, align 4
  store i32 %19, i32* %2, align 4
  %20 = load i32, i32* %4, align 4
  %21 = add nsw i32 %20, 1
  store i32 %21, i32* %4, align 4
  br label %8, !llvm.loop !6

22:                                               ; preds = %8
  %23 = load i32, i32* %1, align 4
  %StackGuard1 = load volatile i8*, i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*), align 8
  %24 = load volatile i8*, i8** %StackGuardSlot, align 8
  %25 = icmp eq i8* %StackGuard1, %24
  br i1 %25, label %SP_return, label %CallStackCheckFailBlk, !prof !8

SP_return:                                        ; preds = %22
  ret i32 %23

CallStackCheckFailBlk:                            ; preds = %22
  call void @__stack_chk_fail()
  unreachable
}
# *** IR Dump Before X86 DAG->DAG Instruction Selection (amdgpu-isel) ***:
# Machine code for function main: IsSSA, TracksLiveness

# End machine code for function main.

# *** IR Dump After X86 DAG->DAG Instruction Selection (amdgpu-isel) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  %1:gr64 = MOV64ri @.str
  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %1:gr64
  $rsi = COPY %2:gr64
  $rdx = COPY %3:gr64
  $rcx = COPY %4:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
  %27:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %26:gr32 = ADD32rm %27:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  %19:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %19:gr64
  $esi = COPY %22:gr32
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %21:gr32 = COPY $eax
  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
  %16:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %15:gr32 = ADD32ri8 %16:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit $eflags

bb.4.SP_return:
; predecessors: %bb.3

  $eax = COPY %0:gr32
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before Finalize ISel and expand pseudo-instructions (finalize-isel) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  %1:gr64 = MOV64ri @.str
  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %1:gr64
  $rsi = COPY %2:gr64
  $rdx = COPY %3:gr64
  $rcx = COPY %4:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
  %27:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %26:gr32 = ADD32rm %27:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  %19:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %19:gr64
  $esi = COPY %22:gr32
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %21:gr32 = COPY $eax
  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
  %16:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %15:gr32 = ADD32ri8 %16:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit $eflags

bb.4.SP_return:
; predecessors: %bb.3

  $eax = COPY %0:gr32
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After Finalize ISel and expand pseudo-instructions (finalize-isel) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  %1:gr64 = MOV64ri @.str
  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %1:gr64
  $rsi = COPY %2:gr64
  $rdx = COPY %3:gr64
  $rcx = COPY %4:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
  %27:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %26:gr32 = ADD32rm %27:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  %19:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %19:gr64
  $esi = COPY %22:gr32
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %21:gr32 = COPY $eax
  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
  %16:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %15:gr32 = ADD32ri8 %16:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit $eflags

bb.4.SP_return:
; predecessors: %bb.3

  $eax = COPY %0:gr32
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before X86 Domain Reassignment Pass (x86-domain-reassignment) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  %1:gr64 = MOV64ri @.str
  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %1:gr64
  $rsi = COPY %2:gr64
  $rdx = COPY %3:gr64
  $rcx = COPY %4:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
  %27:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %26:gr32 = ADD32rm %27:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  %19:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %19:gr64
  $esi = COPY %22:gr32
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %21:gr32 = COPY $eax
  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
  %16:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %15:gr32 = ADD32ri8 %16:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit $eflags

bb.4.SP_return:
; predecessors: %bb.3

  $eax = COPY %0:gr32
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After X86 Domain Reassignment Pass (x86-domain-reassignment) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  %1:gr64 = MOV64ri @.str
  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %1:gr64
  $rsi = COPY %2:gr64
  $rdx = COPY %3:gr64
  $rcx = COPY %4:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
  %27:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %26:gr32 = ADD32rm %27:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  %19:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %19:gr64
  $esi = COPY %22:gr32
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %21:gr32 = COPY $eax
  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
  %16:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %15:gr32 = ADD32ri8 %16:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit $eflags

bb.4.SP_return:
; predecessors: %bb.3

  $eax = COPY %0:gr32
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before Early Tail Duplication (early-tailduplication) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  %1:gr64 = MOV64ri @.str
  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %1:gr64
  $rsi = COPY %2:gr64
  $rdx = COPY %3:gr64
  $rcx = COPY %4:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
  %27:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %26:gr32 = ADD32rm %27:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  %19:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %19:gr64
  $esi = COPY %22:gr32
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %21:gr32 = COPY $eax
  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
  %16:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %15:gr32 = ADD32ri8 %16:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit $eflags

bb.4.SP_return:
; predecessors: %bb.3

  $eax = COPY %0:gr32
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After Early Tail Duplication (early-tailduplication) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  %1:gr64 = MOV64ri @.str
  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %1:gr64
  $rsi = COPY %2:gr64
  $rdx = COPY %3:gr64
  $rcx = COPY %4:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
  %27:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %26:gr32 = ADD32rm %27:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  %19:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %19:gr64
  $esi = COPY %22:gr32
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %21:gr32 = COPY $eax
  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
  %16:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %15:gr32 = ADD32ri8 %16:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit $eflags

bb.4.SP_return:
; predecessors: %bb.3

  $eax = COPY %0:gr32
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before Optimize machine instruction PHIs (opt-phis) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  %1:gr64 = MOV64ri @.str
  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %1:gr64
  $rsi = COPY %2:gr64
  $rdx = COPY %3:gr64
  $rcx = COPY %4:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
  %27:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %26:gr32 = ADD32rm %27:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  %19:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %19:gr64
  $esi = COPY %22:gr32
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %21:gr32 = COPY $eax
  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
  %16:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %15:gr32 = ADD32ri8 %16:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit $eflags

bb.4.SP_return:
; predecessors: %bb.3

  $eax = COPY %0:gr32
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After Optimize machine instruction PHIs (opt-phis) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  %1:gr64 = MOV64ri @.str
  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %1:gr64
  $rsi = COPY %2:gr64
  $rdx = COPY %3:gr64
  $rcx = COPY %4:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
  %27:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %26:gr32 = ADD32rm %27:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  %19:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %19:gr64
  $esi = COPY %22:gr32
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %21:gr32 = COPY $eax
  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
  %16:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %15:gr32 = ADD32ri8 %16:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit $eflags

bb.4.SP_return:
; predecessors: %bb.3

  $eax = COPY %0:gr32
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before Slot index numbering (slotindexes) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  %1:gr64 = MOV64ri @.str
  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %1:gr64
  $rsi = COPY %2:gr64
  $rdx = COPY %3:gr64
  $rcx = COPY %4:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
  %27:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %26:gr32 = ADD32rm %27:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  %19:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %19:gr64
  $esi = COPY %22:gr32
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %21:gr32 = COPY $eax
  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
  %16:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %15:gr32 = ADD32ri8 %16:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit $eflags

bb.4.SP_return:
; predecessors: %bb.3

  $eax = COPY %0:gr32
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After Slot index numbering (slotindexes) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

0B	bb.0 (%ir-block.0):
	  successors: %bb.1

16B	  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
32B	  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
48B	  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
64B	  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
80B	  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
96B	  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
112B	  %1:gr64 = MOV64ri @.str
128B	  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
144B	  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
160B	  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
176B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
192B	  $rdi = COPY %1:gr64
208B	  $rsi = COPY %2:gr64
224B	  $rdx = COPY %3:gr64
240B	  $rcx = COPY %4:gr64
256B	  $al = MOV8ri 0
272B	  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
288B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
304B	  %5:gr32 = COPY $eax

320B	bb.1 (%ir-block.8):
	; predecessors: %bb.0, %bb.2
	  successors: %bb.3, %bb.2

336B	  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
352B	  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
368B	  JCC_1 %bb.3, 13, implicit $eflags

384B	bb.2 (%ir-block.12):
	; predecessors: %bb.1
	  successors: %bb.1

400B	  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
416B	  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
432B	  %27:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
448B	  %26:gr32 = ADD32rm %27:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.3)
464B	  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
480B	  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
496B	  %19:gr64 = MOV64ri @.str.1
512B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
528B	  $rdi = COPY %19:gr64
544B	  $esi = COPY %22:gr32
560B	  $al = MOV8ri 0
576B	  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
592B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
608B	  %21:gr32 = COPY $eax
624B	  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
640B	  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
656B	  %16:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
672B	  %15:gr32 = ADD32ri8 %16:gr32(tied-def 0), 1, implicit-def $eflags
688B	  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
704B	  JMP_1 %bb.1

720B	bb.3 (%ir-block.22):
	; predecessors: %bb.1
	  successors: %bb.5, %bb.4

736B	  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
752B	  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
768B	  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
784B	  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
800B	  JCC_1 %bb.5, 5, implicit $eflags

816B	bb.4.SP_return:
	; predecessors: %bb.3

832B	  $eax = COPY %0:gr32
848B	  RET64 implicit $eax

864B	bb.5.CallStackCheckFailBlk:
	; predecessors: %bb.3

880B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
896B	  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
912B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before Merge disjoint stack slots (stack-coloring) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

0B	bb.0 (%ir-block.0):
	  successors: %bb.1

16B	  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
32B	  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
48B	  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
64B	  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
80B	  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
96B	  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
112B	  %1:gr64 = MOV64ri @.str
128B	  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
144B	  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
160B	  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
176B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
192B	  $rdi = COPY %1:gr64
208B	  $rsi = COPY %2:gr64
224B	  $rdx = COPY %3:gr64
240B	  $rcx = COPY %4:gr64
256B	  $al = MOV8ri 0
272B	  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
288B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
304B	  %5:gr32 = COPY $eax

320B	bb.1 (%ir-block.8):
	; predecessors: %bb.0, %bb.2
	  successors: %bb.3, %bb.2

336B	  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
352B	  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
368B	  JCC_1 %bb.3, 13, implicit $eflags

384B	bb.2 (%ir-block.12):
	; predecessors: %bb.1
	  successors: %bb.1

400B	  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
416B	  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
432B	  %27:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
448B	  %26:gr32 = ADD32rm %27:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.3)
464B	  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
480B	  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
496B	  %19:gr64 = MOV64ri @.str.1
512B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
528B	  $rdi = COPY %19:gr64
544B	  $esi = COPY %22:gr32
560B	  $al = MOV8ri 0
576B	  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
592B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
608B	  %21:gr32 = COPY $eax
624B	  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
640B	  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
656B	  %16:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
672B	  %15:gr32 = ADD32ri8 %16:gr32(tied-def 0), 1, implicit-def $eflags
688B	  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
704B	  JMP_1 %bb.1

720B	bb.3 (%ir-block.22):
	; predecessors: %bb.1
	  successors: %bb.5, %bb.4

736B	  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
752B	  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
768B	  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
784B	  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
800B	  JCC_1 %bb.5, 5, implicit $eflags

816B	bb.4.SP_return:
	; predecessors: %bb.3

832B	  $eax = COPY %0:gr32
848B	  RET64 implicit $eax

864B	bb.5.CallStackCheckFailBlk:
	; predecessors: %bb.3

880B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
896B	  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
912B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After Merge disjoint stack slots (stack-coloring) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  %1:gr64 = MOV64ri @.str
  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %1:gr64
  $rsi = COPY %2:gr64
  $rdx = COPY %3:gr64
  $rcx = COPY %4:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
  %27:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %26:gr32 = ADD32rm %27:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  %19:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %19:gr64
  $esi = COPY %22:gr32
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %21:gr32 = COPY $eax
  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
  %16:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %15:gr32 = ADD32ri8 %16:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit $eflags

bb.4.SP_return:
; predecessors: %bb.3

  $eax = COPY %0:gr32
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before Local Stack Slot Allocation (localstackalloc) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  %1:gr64 = MOV64ri @.str
  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %1:gr64
  $rsi = COPY %2:gr64
  $rdx = COPY %3:gr64
  $rcx = COPY %4:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
  %27:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %26:gr32 = ADD32rm %27:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  %19:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %19:gr64
  $esi = COPY %22:gr32
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %21:gr32 = COPY $eax
  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
  %16:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %15:gr32 = ADD32ri8 %16:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit $eflags

bb.4.SP_return:
; predecessors: %bb.3

  $eax = COPY %0:gr32
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After Local Stack Slot Allocation (localstackalloc) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  %1:gr64 = MOV64ri @.str
  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %1:gr64
  $rsi = COPY %2:gr64
  $rdx = COPY %3:gr64
  $rcx = COPY %4:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
  %27:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %26:gr32 = ADD32rm %27:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  %19:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %19:gr64
  $esi = COPY %22:gr32
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %21:gr32 = COPY $eax
  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
  %16:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %15:gr32 = ADD32ri8 %16:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit $eflags

bb.4.SP_return:
; predecessors: %bb.3

  $eax = COPY %0:gr32
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before Remove dead machine instructions (dead-mi-elimination) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  %1:gr64 = MOV64ri @.str
  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %1:gr64
  $rsi = COPY %2:gr64
  $rdx = COPY %3:gr64
  $rcx = COPY %4:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
  %27:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %26:gr32 = ADD32rm %27:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  %19:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %19:gr64
  $esi = COPY %22:gr32
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %21:gr32 = COPY $eax
  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
  %16:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %15:gr32 = ADD32ri8 %16:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit $eflags

bb.4.SP_return:
; predecessors: %bb.3

  $eax = COPY %0:gr32
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After Remove dead machine instructions (dead-mi-elimination) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  %1:gr64 = MOV64ri @.str
  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %1:gr64
  $rsi = COPY %2:gr64
  $rdx = COPY %3:gr64
  $rcx = COPY %4:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
  %27:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %26:gr32 = ADD32rm %27:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  %19:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %19:gr64
  $esi = COPY %22:gr32
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %21:gr32 = COPY $eax
  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
  %16:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %15:gr32 = ADD32ri8 %16:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit $eflags

bb.4.SP_return:
; predecessors: %bb.3

  $eax = COPY %0:gr32
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before Early If-Conversion (early-ifcvt) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  %1:gr64 = MOV64ri @.str
  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %1:gr64
  $rsi = COPY %2:gr64
  $rdx = COPY %3:gr64
  $rcx = COPY %4:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
  %27:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %26:gr32 = ADD32rm %27:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  %19:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %19:gr64
  $esi = COPY %22:gr32
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %21:gr32 = COPY $eax
  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
  %16:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %15:gr32 = ADD32ri8 %16:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit $eflags

bb.4.SP_return:
; predecessors: %bb.3

  $eax = COPY %0:gr32
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After Early If-Conversion (early-ifcvt) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  %1:gr64 = MOV64ri @.str
  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %1:gr64
  $rsi = COPY %2:gr64
  $rdx = COPY %3:gr64
  $rcx = COPY %4:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
  %27:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %26:gr32 = ADD32rm %27:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  %19:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %19:gr64
  $esi = COPY %22:gr32
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %21:gr32 = COPY $eax
  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
  %16:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %15:gr32 = ADD32ri8 %16:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit $eflags

bb.4.SP_return:
; predecessors: %bb.3

  $eax = COPY %0:gr32
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before Machine InstCombiner (machine-combiner) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  %1:gr64 = MOV64ri @.str
  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %1:gr64
  $rsi = COPY %2:gr64
  $rdx = COPY %3:gr64
  $rcx = COPY %4:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
  %27:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %26:gr32 = ADD32rm %27:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  %19:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %19:gr64
  $esi = COPY %22:gr32
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %21:gr32 = COPY $eax
  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
  %16:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %15:gr32 = ADD32ri8 %16:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit $eflags

bb.4.SP_return:
; predecessors: %bb.3

  $eax = COPY %0:gr32
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After Machine InstCombiner (machine-combiner) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  %1:gr64 = MOV64ri @.str
  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %1:gr64
  $rsi = COPY %2:gr64
  $rdx = COPY %3:gr64
  $rcx = COPY %4:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
  %27:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %26:gr32 = ADD32rm %27:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  %19:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %19:gr64
  $esi = COPY %22:gr32
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %21:gr32 = COPY $eax
  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
  %16:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %15:gr32 = ADD32ri8 %16:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit $eflags

bb.4.SP_return:
; predecessors: %bb.3

  $eax = COPY %0:gr32
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before X86 cmov Conversion (x86-cmov-conversion) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  %1:gr64 = MOV64ri @.str
  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %1:gr64
  $rsi = COPY %2:gr64
  $rdx = COPY %3:gr64
  $rcx = COPY %4:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
  %27:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %26:gr32 = ADD32rm %27:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  %19:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %19:gr64
  $esi = COPY %22:gr32
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %21:gr32 = COPY $eax
  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
  %16:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %15:gr32 = ADD32ri8 %16:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit $eflags

bb.4.SP_return:
; predecessors: %bb.3

  $eax = COPY %0:gr32
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After X86 cmov Conversion (x86-cmov-conversion) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  %1:gr64 = MOV64ri @.str
  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %1:gr64
  $rsi = COPY %2:gr64
  $rdx = COPY %3:gr64
  $rcx = COPY %4:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
  %27:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %26:gr32 = ADD32rm %27:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  %19:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %19:gr64
  $esi = COPY %22:gr32
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %21:gr32 = COPY $eax
  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
  %16:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %15:gr32 = ADD32ri8 %16:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit $eflags

bb.4.SP_return:
; predecessors: %bb.3

  $eax = COPY %0:gr32
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before Early Machine Loop Invariant Code Motion (early-machinelicm) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  %1:gr64 = MOV64ri @.str
  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %1:gr64
  $rsi = COPY %2:gr64
  $rdx = COPY %3:gr64
  $rcx = COPY %4:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
  %27:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %26:gr32 = ADD32rm %27:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  %19:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %19:gr64
  $esi = COPY %22:gr32
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %21:gr32 = COPY $eax
  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
  %16:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %15:gr32 = ADD32ri8 %16:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit $eflags

bb.4.SP_return:
; predecessors: %bb.3

  $eax = COPY %0:gr32
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After Early Machine Loop Invariant Code Motion (early-machinelicm) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  %1:gr64 = MOV64ri @.str
  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %1:gr64
  $rsi = COPY %2:gr64
  $rdx = COPY %3:gr64
  $rcx = COPY %4:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
  %27:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %26:gr32 = ADD32rm %27:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  %19:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %19:gr64
  $esi = COPY %22:gr32
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %21:gr32 = COPY $eax
  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
  %16:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %15:gr32 = ADD32ri8 %16:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit $eflags

bb.4.SP_return:
; predecessors: %bb.3

  $eax = COPY %0:gr32
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before Machine Common Subexpression Elimination (machine-cse) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  %1:gr64 = MOV64ri @.str
  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %1:gr64
  $rsi = COPY %2:gr64
  $rdx = COPY %3:gr64
  $rcx = COPY %4:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
  %27:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %26:gr32 = ADD32rm %27:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  %19:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %19:gr64
  $esi = COPY %22:gr32
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %21:gr32 = COPY $eax
  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
  %16:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %15:gr32 = ADD32ri8 %16:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit $eflags

bb.4.SP_return:
; predecessors: %bb.3

  $eax = COPY %0:gr32
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After Machine Common Subexpression Elimination (machine-cse) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  %1:gr64 = MOV64ri @.str
  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %1:gr64
  $rsi = COPY %2:gr64
  $rdx = COPY %3:gr64
  $rcx = COPY %4:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
  %27:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %26:gr32 = ADD32rm %27:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  %19:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %19:gr64
  $esi = COPY %22:gr32
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %21:gr32 = COPY $eax
  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
  %16:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %15:gr32 = ADD32ri8 %16:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit $eflags

bb.4.SP_return:
; predecessors: %bb.3

  $eax = COPY %0:gr32
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before Machine code sinking (machine-sink) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  %1:gr64 = MOV64ri @.str
  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %1:gr64
  $rsi = COPY %2:gr64
  $rdx = COPY %3:gr64
  $rcx = COPY %4:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
  %27:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %26:gr32 = ADD32rm %27:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  %19:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %19:gr64
  $esi = COPY %22:gr32
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %21:gr32 = COPY $eax
  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
  %16:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %15:gr32 = ADD32ri8 %16:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit $eflags

bb.4.SP_return:
; predecessors: %bb.3

  $eax = COPY %0:gr32
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After Machine code sinking (machine-sink) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  %1:gr64 = MOV64ri @.str
  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %1:gr64
  $rsi = COPY %2:gr64
  $rdx = COPY %3:gr64
  $rcx = COPY %4:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
  %27:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %26:gr32 = ADD32rm %27:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  %19:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %19:gr64
  $esi = COPY %22:gr32
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %21:gr32 = COPY $eax
  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
  %16:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %15:gr32 = ADD32ri8 %16:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit $eflags

bb.4.SP_return:
; predecessors: %bb.3

  $eax = COPY %0:gr32
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before Peephole Optimizations (peephole-opt) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  %1:gr64 = MOV64ri @.str
  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %1:gr64
  $rsi = COPY %2:gr64
  $rdx = COPY %3:gr64
  $rcx = COPY %4:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
  %27:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %26:gr32 = ADD32rm %27:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  %19:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %19:gr64
  $esi = COPY %22:gr32
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %21:gr32 = COPY $eax
  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
  %16:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %15:gr32 = ADD32ri8 %16:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit $eflags

bb.4.SP_return:
; predecessors: %bb.3

  $eax = COPY %0:gr32
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After Peephole Optimizations (peephole-opt) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  %1:gr64 = MOV64ri @.str
  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %1:gr64
  $rsi = COPY %2:gr64
  $rdx = COPY %3:gr64
  $rcx = COPY %4:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
  %27:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %26:gr32 = ADD32rm %27:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  %19:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %19:gr64
  $esi = COPY %22:gr32
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %21:gr32 = COPY $eax
  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
  %16:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %15:gr32 = ADD32ri8 %16:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit $eflags

bb.4.SP_return:
; predecessors: %bb.3

  $eax = COPY %0:gr32
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before Remove dead machine instructions (dead-mi-elimination) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  %1:gr64 = MOV64ri @.str
  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %1:gr64
  $rsi = COPY %2:gr64
  $rdx = COPY %3:gr64
  $rcx = COPY %4:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
  %27:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %26:gr32 = ADD32rm %27:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  %19:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %19:gr64
  $esi = COPY %22:gr32
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %21:gr32 = COPY $eax
  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
  %16:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %15:gr32 = ADD32ri8 %16:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit $eflags

bb.4.SP_return:
; predecessors: %bb.3

  $eax = COPY %0:gr32
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After Remove dead machine instructions (dead-mi-elimination) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  %1:gr64 = MOV64ri @.str
  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %1:gr64
  $rsi = COPY %2:gr64
  $rdx = COPY %3:gr64
  $rcx = COPY %4:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
  %27:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %26:gr32 = ADD32rm %27:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  %19:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %19:gr64
  $esi = COPY %22:gr32
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %21:gr32 = COPY $eax
  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
  %16:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %15:gr32 = ADD32ri8 %16:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit $eflags

bb.4.SP_return:
; predecessors: %bb.3

  $eax = COPY %0:gr32
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before Live Range Shrink (lrshrink) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  %1:gr64 = MOV64ri @.str
  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %1:gr64
  $rsi = COPY %2:gr64
  $rdx = COPY %3:gr64
  $rcx = COPY %4:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
  %27:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %26:gr32 = ADD32rm %27:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  %19:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %19:gr64
  $esi = COPY %22:gr32
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %21:gr32 = COPY $eax
  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
  %16:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %15:gr32 = ADD32ri8 %16:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit $eflags

bb.4.SP_return:
; predecessors: %bb.3

  $eax = COPY %0:gr32
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After Live Range Shrink (lrshrink) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  %1:gr64 = MOV64ri @.str
  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %1:gr64
  $rsi = COPY %2:gr64
  $rdx = COPY %3:gr64
  $rcx = COPY %4:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
  %27:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %26:gr32 = ADD32rm %27:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  %19:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %19:gr64
  $esi = COPY %22:gr32
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %21:gr32 = COPY $eax
  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
  %16:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %15:gr32 = ADD32ri8 %16:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit $eflags

bb.4.SP_return:
; predecessors: %bb.3

  $eax = COPY %0:gr32
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before X86 Fixup SetCC (x86-fixup-setcc) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  %1:gr64 = MOV64ri @.str
  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %1:gr64
  $rsi = COPY %2:gr64
  $rdx = COPY %3:gr64
  $rcx = COPY %4:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
  %27:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %26:gr32 = ADD32rm %27:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  %19:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %19:gr64
  $esi = COPY %22:gr32
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %21:gr32 = COPY $eax
  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
  %16:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %15:gr32 = ADD32ri8 %16:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit $eflags

bb.4.SP_return:
; predecessors: %bb.3

  $eax = COPY %0:gr32
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After X86 Fixup SetCC (x86-fixup-setcc) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  %1:gr64 = MOV64ri @.str
  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %1:gr64
  $rsi = COPY %2:gr64
  $rdx = COPY %3:gr64
  $rcx = COPY %4:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
  %27:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %26:gr32 = ADD32rm %27:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  %19:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %19:gr64
  $esi = COPY %22:gr32
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %21:gr32 = COPY $eax
  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
  %16:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %15:gr32 = ADD32ri8 %16:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit $eflags

bb.4.SP_return:
; predecessors: %bb.3

  $eax = COPY %0:gr32
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before X86 LEA Optimize (x86-optimize-LEAs) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  %1:gr64 = MOV64ri @.str
  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %1:gr64
  $rsi = COPY %2:gr64
  $rdx = COPY %3:gr64
  $rcx = COPY %4:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
  %27:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %26:gr32 = ADD32rm %27:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  %19:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %19:gr64
  $esi = COPY %22:gr32
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %21:gr32 = COPY $eax
  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
  %16:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %15:gr32 = ADD32ri8 %16:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit $eflags

bb.4.SP_return:
; predecessors: %bb.3

  $eax = COPY %0:gr32
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After X86 LEA Optimize (x86-optimize-LEAs) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  %1:gr64 = MOV64ri @.str
  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %1:gr64
  $rsi = COPY %2:gr64
  $rdx = COPY %3:gr64
  $rcx = COPY %4:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
  %27:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %26:gr32 = ADD32rm %27:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  %19:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %19:gr64
  $esi = COPY %22:gr32
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %21:gr32 = COPY $eax
  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
  %16:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %15:gr32 = ADD32ri8 %16:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit $eflags

bb.4.SP_return:
; predecessors: %bb.3

  $eax = COPY %0:gr32
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before X86 Optimize Call Frame (x86-cf-opt) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  %1:gr64 = MOV64ri @.str
  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %1:gr64
  $rsi = COPY %2:gr64
  $rdx = COPY %3:gr64
  $rcx = COPY %4:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
  %27:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %26:gr32 = ADD32rm %27:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  %19:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %19:gr64
  $esi = COPY %22:gr32
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %21:gr32 = COPY $eax
  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
  %16:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %15:gr32 = ADD32ri8 %16:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit $eflags

bb.4.SP_return:
; predecessors: %bb.3

  $eax = COPY %0:gr32
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After X86 Optimize Call Frame (x86-cf-opt) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  %1:gr64 = MOV64ri @.str
  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %1:gr64
  $rsi = COPY %2:gr64
  $rdx = COPY %3:gr64
  $rcx = COPY %4:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
  %27:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %26:gr32 = ADD32rm %27:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  %19:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %19:gr64
  $esi = COPY %22:gr32
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %21:gr32 = COPY $eax
  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
  %16:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %15:gr32 = ADD32ri8 %16:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit $eflags

bb.4.SP_return:
; predecessors: %bb.3

  $eax = COPY %0:gr32
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before X86 Avoid Store Forwarding Blocks (x86-avoid-SFB) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  %1:gr64 = MOV64ri @.str
  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %1:gr64
  $rsi = COPY %2:gr64
  $rdx = COPY %3:gr64
  $rcx = COPY %4:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
  %27:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %26:gr32 = ADD32rm %27:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  %19:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %19:gr64
  $esi = COPY %22:gr32
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %21:gr32 = COPY $eax
  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
  %16:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %15:gr32 = ADD32ri8 %16:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit $eflags

bb.4.SP_return:
; predecessors: %bb.3

  $eax = COPY %0:gr32
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After X86 Avoid Store Forwarding Blocks (x86-avoid-SFB) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  %1:gr64 = MOV64ri @.str
  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %1:gr64
  $rsi = COPY %2:gr64
  $rdx = COPY %3:gr64
  $rcx = COPY %4:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
  %27:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %26:gr32 = ADD32rm %27:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  %19:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %19:gr64
  $esi = COPY %22:gr32
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %21:gr32 = COPY $eax
  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
  %16:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %15:gr32 = ADD32ri8 %16:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit $eflags

bb.4.SP_return:
; predecessors: %bb.3

  $eax = COPY %0:gr32
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before X86 speculative load hardening (x86-slh) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  %1:gr64 = MOV64ri @.str
  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %1:gr64
  $rsi = COPY %2:gr64
  $rdx = COPY %3:gr64
  $rcx = COPY %4:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
  %27:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %26:gr32 = ADD32rm %27:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  %19:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %19:gr64
  $esi = COPY %22:gr32
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %21:gr32 = COPY $eax
  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
  %16:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %15:gr32 = ADD32ri8 %16:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit $eflags

bb.4.SP_return:
; predecessors: %bb.3

  $eax = COPY %0:gr32
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After X86 speculative load hardening (x86-slh) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  %1:gr64 = MOV64ri @.str
  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %1:gr64
  $rsi = COPY %2:gr64
  $rdx = COPY %3:gr64
  $rcx = COPY %4:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
  %27:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %26:gr32 = ADD32rm %27:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  %19:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %19:gr64
  $esi = COPY %22:gr32
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %21:gr32 = COPY $eax
  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
  %16:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %15:gr32 = ADD32ri8 %16:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit $eflags

bb.4.SP_return:
; predecessors: %bb.3

  $eax = COPY %0:gr32
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before X86 EFLAGS copy lowering (x86-flags-copy-lowering) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  %1:gr64 = MOV64ri @.str
  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %1:gr64
  $rsi = COPY %2:gr64
  $rdx = COPY %3:gr64
  $rcx = COPY %4:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
  %27:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %26:gr32 = ADD32rm %27:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  %19:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %19:gr64
  $esi = COPY %22:gr32
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %21:gr32 = COPY $eax
  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
  %16:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %15:gr32 = ADD32ri8 %16:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit $eflags

bb.4.SP_return:
; predecessors: %bb.3

  $eax = COPY %0:gr32
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After X86 EFLAGS copy lowering (x86-flags-copy-lowering) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  %1:gr64 = MOV64ri @.str
  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %1:gr64
  $rsi = COPY %2:gr64
  $rdx = COPY %3:gr64
  $rcx = COPY %4:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
  %27:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %26:gr32 = ADD32rm %27:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  %19:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %19:gr64
  $esi = COPY %22:gr32
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %21:gr32 = COPY $eax
  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
  %16:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %15:gr32 = ADD32ri8 %16:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit $eflags

bb.4.SP_return:
; predecessors: %bb.3

  $eax = COPY %0:gr32
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before Detect Dead Lanes (detect-dead-lanes) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  %1:gr64 = MOV64ri @.str
  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %1:gr64
  $rsi = COPY %2:gr64
  $rdx = COPY %3:gr64
  $rcx = COPY %4:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
  %27:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %26:gr32 = ADD32rm %27:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  %19:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %19:gr64
  $esi = COPY %22:gr32
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %21:gr32 = COPY $eax
  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
  %16:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %15:gr32 = ADD32ri8 %16:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit $eflags

bb.4.SP_return:
; predecessors: %bb.3

  $eax = COPY %0:gr32
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After Detect Dead Lanes (detect-dead-lanes) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  %1:gr64 = MOV64ri @.str
  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %1:gr64
  $rsi = COPY %2:gr64
  $rdx = COPY %3:gr64
  $rcx = COPY %4:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
  %27:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %26:gr32 = ADD32rm %27:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  %19:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %19:gr64
  $esi = COPY %22:gr32
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %21:gr32 = COPY $eax
  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
  %16:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %15:gr32 = ADD32ri8 %16:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit $eflags

bb.4.SP_return:
; predecessors: %bb.3

  $eax = COPY %0:gr32
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before Process Implicit Definitions (processimpdefs) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  %1:gr64 = MOV64ri @.str
  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %1:gr64
  $rsi = COPY %2:gr64
  $rdx = COPY %3:gr64
  $rcx = COPY %4:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
  %27:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %26:gr32 = ADD32rm %27:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  %19:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %19:gr64
  $esi = COPY %22:gr32
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %21:gr32 = COPY $eax
  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
  %16:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %15:gr32 = ADD32ri8 %16:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit $eflags

bb.4.SP_return:
; predecessors: %bb.3

  $eax = COPY %0:gr32
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After Process Implicit Definitions (processimpdefs) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  %1:gr64 = MOV64ri @.str
  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %1:gr64
  $rsi = COPY %2:gr64
  $rdx = COPY %3:gr64
  $rcx = COPY %4:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
  %27:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %26:gr32 = ADD32rm %27:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  %19:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %19:gr64
  $esi = COPY %22:gr32
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %21:gr32 = COPY $eax
  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
  %16:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %15:gr32 = ADD32ri8 %16:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit $eflags

bb.4.SP_return:
; predecessors: %bb.3

  $eax = COPY %0:gr32
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before Remove unreachable machine basic blocks (unreachable-mbb-elimination) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  %1:gr64 = MOV64ri @.str
  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %1:gr64
  $rsi = COPY %2:gr64
  $rdx = COPY %3:gr64
  $rcx = COPY %4:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
  %27:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %26:gr32 = ADD32rm %27:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  %19:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %19:gr64
  $esi = COPY %22:gr32
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %21:gr32 = COPY $eax
  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
  %16:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %15:gr32 = ADD32ri8 %16:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit $eflags

bb.4.SP_return:
; predecessors: %bb.3

  $eax = COPY %0:gr32
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After Remove unreachable machine basic blocks (unreachable-mbb-elimination) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  %1:gr64 = MOV64ri @.str
  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %1:gr64
  $rsi = COPY %2:gr64
  $rdx = COPY %3:gr64
  $rcx = COPY %4:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
  %27:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %26:gr32 = ADD32rm %27:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  %19:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %19:gr64
  $esi = COPY %22:gr32
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %21:gr32 = COPY $eax
  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
  %16:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %15:gr32 = ADD32ri8 %16:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit $eflags

bb.4.SP_return:
; predecessors: %bb.3

  $eax = COPY %0:gr32
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before Live Variable Analysis (livevars) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  %1:gr64 = MOV64ri @.str
  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %1:gr64
  $rsi = COPY %2:gr64
  $rdx = COPY %3:gr64
  $rcx = COPY %4:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
  %27:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %26:gr32 = ADD32rm %27:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  %19:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %19:gr64
  $esi = COPY %22:gr32
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %21:gr32 = COPY $eax
  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
  %16:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %15:gr32 = ADD32ri8 %16:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit $eflags

bb.4.SP_return:
; predecessors: %bb.3

  $eax = COPY %0:gr32
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After Live Variable Analysis (livevars) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, killed %6:gr64
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  %1:gr64 = MOV64ri @.str
  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY killed %1:gr64
  $rsi = COPY killed %2:gr64
  $rdx = COPY killed %3:gr64
  $rcx = COPY killed %4:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $rsi, implicit killed $rdx, implicit killed $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  dead %5:gr32 = COPY killed $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit killed $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, killed %29:gr32 :: (store (s32) into %ir.6)
  %27:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %26:gr32 = ADD32rm killed %27:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, killed %26:gr32 :: (store (s32) into %ir.3)
  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  %19:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY killed %19:gr64
  $esi = COPY killed %22:gr32
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  dead %21:gr32 = COPY killed $eax
  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, killed %18:gr32 :: (store (s32) into %ir.2)
  %16:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %15:gr32 = ADD32ri8 killed %16:gr32(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, killed %15:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr killed %10:gr64, killed %12:gr64, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit killed $eflags

bb.4.SP_return:
; predecessors: %bb.3

  $eax = COPY killed %0:gr32
  RET64 implicit killed $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before Eliminate PHI nodes for register allocation (phi-node-elimination) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, killed %6:gr64
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  %1:gr64 = MOV64ri @.str
  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY killed %1:gr64
  $rsi = COPY killed %2:gr64
  $rdx = COPY killed %3:gr64
  $rcx = COPY killed %4:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $rsi, implicit killed $rdx, implicit killed $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  dead %5:gr32 = COPY killed $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit killed $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, killed %29:gr32 :: (store (s32) into %ir.6)
  %27:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %26:gr32 = ADD32rm killed %27:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, killed %26:gr32 :: (store (s32) into %ir.3)
  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  %19:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY killed %19:gr64
  $esi = COPY killed %22:gr32
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  dead %21:gr32 = COPY killed $eax
  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, killed %18:gr32 :: (store (s32) into %ir.2)
  %16:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %15:gr32 = ADD32ri8 killed %16:gr32(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, killed %15:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr killed %10:gr64, killed %12:gr64, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit killed $eflags

bb.4.SP_return:
; predecessors: %bb.3

  $eax = COPY killed %0:gr32
  RET64 implicit killed $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After Eliminate PHI nodes for register allocation (phi-node-elimination) ***:
# Machine code for function main: NoPHIs, TracksLiveness
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, killed %6:gr64
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  %1:gr64 = MOV64ri @.str
  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY killed %1:gr64
  $rsi = COPY killed %2:gr64
  $rdx = COPY killed %3:gr64
  $rcx = COPY killed %4:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $rsi, implicit killed $rdx, implicit killed $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  dead %5:gr32 = COPY killed $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit killed $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, killed %29:gr32 :: (store (s32) into %ir.6)
  %27:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %26:gr32 = ADD32rm killed %27:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, killed %26:gr32 :: (store (s32) into %ir.3)
  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  %19:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY killed %19:gr64
  $esi = COPY killed %22:gr32
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  dead %21:gr32 = COPY killed $eax
  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, killed %18:gr32 :: (store (s32) into %ir.2)
  %16:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %15:gr32 = ADD32ri8 killed %16:gr32(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, killed %15:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr killed %10:gr64, killed %12:gr64, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit killed $eflags

bb.4.SP_return:
; predecessors: %bb.3

  $eax = COPY killed %0:gr32
  RET64 implicit killed $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before Two-Address instruction pass (twoaddressinstruction) ***:
# Machine code for function main: NoPHIs, TracksLiveness
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, killed %6:gr64
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  %1:gr64 = MOV64ri @.str
  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY killed %1:gr64
  $rsi = COPY killed %2:gr64
  $rdx = COPY killed %3:gr64
  $rcx = COPY killed %4:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $rsi, implicit killed $rdx, implicit killed $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  dead %5:gr32 = COPY killed $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit killed $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, killed %29:gr32 :: (store (s32) into %ir.6)
  %27:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %26:gr32 = ADD32rm killed %27:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, killed %26:gr32 :: (store (s32) into %ir.3)
  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  %19:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY killed %19:gr64
  $esi = COPY killed %22:gr32
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  dead %21:gr32 = COPY killed $eax
  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, killed %18:gr32 :: (store (s32) into %ir.2)
  %16:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %15:gr32 = ADD32ri8 killed %16:gr32(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, killed %15:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr killed %10:gr64, killed %12:gr64, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit killed $eflags

bb.4.SP_return:
; predecessors: %bb.3

  $eax = COPY killed %0:gr32
  RET64 implicit killed $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After Two-Address instruction pass (twoaddressinstruction) ***:
# Machine code for function main: NoPHIs, TracksLiveness, TiedOpsRewritten
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, killed %6:gr64
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  %1:gr64 = MOV64ri @.str
  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY killed %1:gr64
  $rsi = COPY killed %2:gr64
  $rdx = COPY killed %3:gr64
  $rcx = COPY killed %4:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $rsi, implicit killed $rdx, implicit killed $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  dead %5:gr32 = COPY killed $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit killed $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, killed %29:gr32 :: (store (s32) into %ir.6)
  %27:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %26:gr32 = COPY killed %27:gr32
  %26:gr32 = ADD32rm %26:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, killed %26:gr32 :: (store (s32) into %ir.3)
  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  %19:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY killed %19:gr64
  $esi = COPY killed %22:gr32
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  dead %21:gr32 = COPY killed $eax
  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, killed %18:gr32 :: (store (s32) into %ir.2)
  %16:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %15:gr32 = COPY killed %16:gr32
  %15:gr32 = ADD32ri8 %15:gr32(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, killed %15:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr killed %10:gr64, killed %12:gr64, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit killed $eflags

bb.4.SP_return:
; predecessors: %bb.3

  $eax = COPY killed %0:gr32
  RET64 implicit killed $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before Slot index numbering (slotindexes) ***:
# Machine code for function main: NoPHIs, TracksLiveness, TiedOpsRewritten
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, killed %6:gr64
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  %1:gr64 = MOV64ri @.str
  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY killed %1:gr64
  $rsi = COPY killed %2:gr64
  $rdx = COPY killed %3:gr64
  $rcx = COPY killed %4:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $rsi, implicit killed $rdx, implicit killed $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  dead %5:gr32 = COPY killed $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit killed $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, killed %29:gr32 :: (store (s32) into %ir.6)
  %27:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %26:gr32 = COPY killed %27:gr32
  %26:gr32 = ADD32rm %26:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, killed %26:gr32 :: (store (s32) into %ir.3)
  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  %19:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY killed %19:gr64
  $esi = COPY killed %22:gr32
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  dead %21:gr32 = COPY killed $eax
  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, killed %18:gr32 :: (store (s32) into %ir.2)
  %16:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %15:gr32 = COPY killed %16:gr32
  %15:gr32 = ADD32ri8 %15:gr32(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, killed %15:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr killed %10:gr64, killed %12:gr64, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit killed $eflags

bb.4.SP_return:
; predecessors: %bb.3

  $eax = COPY killed %0:gr32
  RET64 implicit killed $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After Slot index numbering (slotindexes) ***:
# Machine code for function main: NoPHIs, TracksLiveness, TiedOpsRewritten
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

0B	bb.0 (%ir-block.0):
	  successors: %bb.1

16B	  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
32B	  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, killed %6:gr64
48B	  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
64B	  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
80B	  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
96B	  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
112B	  %1:gr64 = MOV64ri @.str
128B	  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
144B	  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
160B	  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
176B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
192B	  $rdi = COPY killed %1:gr64
208B	  $rsi = COPY killed %2:gr64
224B	  $rdx = COPY killed %3:gr64
240B	  $rcx = COPY killed %4:gr64
256B	  $al = MOV8ri 0
272B	  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $rsi, implicit killed $rdx, implicit killed $rcx, implicit-def $eax
288B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
304B	  dead %5:gr32 = COPY killed $eax

320B	bb.1 (%ir-block.8):
	; predecessors: %bb.0, %bb.2
	  successors: %bb.3, %bb.2

336B	  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
352B	  CMP32rm killed %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
368B	  JCC_1 %bb.3, 13, implicit killed $eflags

384B	bb.2 (%ir-block.12):
	; predecessors: %bb.1
	  successors: %bb.1

400B	  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
416B	  MOV32mr %stack.6, 1, $noreg, 0, $noreg, killed %29:gr32 :: (store (s32) into %ir.6)
432B	  %27:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
448B	  %26:gr32 = COPY killed %27:gr32
464B	  %26:gr32 = ADD32rm %26:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
480B	  MOV32mr %stack.3, 1, $noreg, 0, $noreg, killed %26:gr32 :: (store (s32) into %ir.3)
496B	  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
512B	  %19:gr64 = MOV64ri @.str.1
528B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
544B	  $rdi = COPY killed %19:gr64
560B	  $esi = COPY killed %22:gr32
576B	  $al = MOV8ri 0
592B	  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $esi, implicit-def $eax
608B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
624B	  dead %21:gr32 = COPY killed $eax
640B	  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
656B	  MOV32mr %stack.2, 1, $noreg, 0, $noreg, killed %18:gr32 :: (store (s32) into %ir.2)
672B	  %16:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
688B	  %15:gr32 = COPY killed %16:gr32
704B	  %15:gr32 = ADD32ri8 %15:gr32(tied-def 0), 1, implicit-def dead $eflags
720B	  MOV32mr %stack.4, 1, $noreg, 0, $noreg, killed %15:gr32 :: (store (s32) into %ir.4)
736B	  JMP_1 %bb.1

752B	bb.3 (%ir-block.22):
	; predecessors: %bb.1
	  successors: %bb.5, %bb.4

768B	  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
784B	  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
800B	  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
816B	  CMP64rr killed %10:gr64, killed %12:gr64, implicit-def $eflags
832B	  JCC_1 %bb.5, 5, implicit killed $eflags

848B	bb.4.SP_return:
	; predecessors: %bb.3

864B	  $eax = COPY killed %0:gr32
880B	  RET64 implicit killed $eax

896B	bb.5.CallStackCheckFailBlk:
	; predecessors: %bb.3

912B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
928B	  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
944B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before Live Interval Analysis (liveintervals) ***:
# Machine code for function main: NoPHIs, TracksLiveness, TiedOpsRewritten
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

0B	bb.0 (%ir-block.0):
	  successors: %bb.1

16B	  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
32B	  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, killed %6:gr64
48B	  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
64B	  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
80B	  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
96B	  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
112B	  %1:gr64 = MOV64ri @.str
128B	  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
144B	  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
160B	  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
176B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
192B	  $rdi = COPY killed %1:gr64
208B	  $rsi = COPY killed %2:gr64
224B	  $rdx = COPY killed %3:gr64
240B	  $rcx = COPY killed %4:gr64
256B	  $al = MOV8ri 0
272B	  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $rsi, implicit killed $rdx, implicit killed $rcx, implicit-def $eax
288B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
304B	  dead %5:gr32 = COPY killed $eax

320B	bb.1 (%ir-block.8):
	; predecessors: %bb.0, %bb.2
	  successors: %bb.3, %bb.2

336B	  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
352B	  CMP32rm killed %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
368B	  JCC_1 %bb.3, 13, implicit killed $eflags

384B	bb.2 (%ir-block.12):
	; predecessors: %bb.1
	  successors: %bb.1

400B	  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
416B	  MOV32mr %stack.6, 1, $noreg, 0, $noreg, killed %29:gr32 :: (store (s32) into %ir.6)
432B	  %27:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
448B	  %26:gr32 = COPY killed %27:gr32
464B	  %26:gr32 = ADD32rm %26:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
480B	  MOV32mr %stack.3, 1, $noreg, 0, $noreg, killed %26:gr32 :: (store (s32) into %ir.3)
496B	  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
512B	  %19:gr64 = MOV64ri @.str.1
528B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
544B	  $rdi = COPY killed %19:gr64
560B	  $esi = COPY killed %22:gr32
576B	  $al = MOV8ri 0
592B	  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $esi, implicit-def $eax
608B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
624B	  dead %21:gr32 = COPY killed $eax
640B	  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
656B	  MOV32mr %stack.2, 1, $noreg, 0, $noreg, killed %18:gr32 :: (store (s32) into %ir.2)
672B	  %16:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
688B	  %15:gr32 = COPY killed %16:gr32
704B	  %15:gr32 = ADD32ri8 %15:gr32(tied-def 0), 1, implicit-def dead $eflags
720B	  MOV32mr %stack.4, 1, $noreg, 0, $noreg, killed %15:gr32 :: (store (s32) into %ir.4)
736B	  JMP_1 %bb.1

752B	bb.3 (%ir-block.22):
	; predecessors: %bb.1
	  successors: %bb.5, %bb.4

768B	  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
784B	  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
800B	  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
816B	  CMP64rr killed %10:gr64, killed %12:gr64, implicit-def $eflags
832B	  JCC_1 %bb.5, 5, implicit killed $eflags

848B	bb.4.SP_return:
	; predecessors: %bb.3

864B	  $eax = COPY killed %0:gr32
880B	  RET64 implicit killed $eax

896B	bb.5.CallStackCheckFailBlk:
	; predecessors: %bb.3

912B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
928B	  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
944B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After Live Interval Analysis (liveintervals) ***:
# Machine code for function main: NoPHIs, TracksLiveness, TiedOpsRewritten
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

0B	bb.0 (%ir-block.0):
	  successors: %bb.1

16B	  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
32B	  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
48B	  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
64B	  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
80B	  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
96B	  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
112B	  %1:gr64 = MOV64ri @.str
128B	  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
144B	  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
160B	  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
176B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
192B	  $rdi = COPY %1:gr64
208B	  $rsi = COPY %2:gr64
224B	  $rdx = COPY %3:gr64
240B	  $rcx = COPY %4:gr64
256B	  $al = MOV8ri 0
272B	  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $rsi, implicit killed $rdx, implicit killed $rcx, implicit-def $eax
288B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
304B	  dead %5:gr32 = COPY killed $eax

320B	bb.1 (%ir-block.8):
	; predecessors: %bb.0, %bb.2
	  successors: %bb.3, %bb.2

336B	  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
352B	  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
368B	  JCC_1 %bb.3, 13, implicit killed $eflags

384B	bb.2 (%ir-block.12):
	; predecessors: %bb.1
	  successors: %bb.1

400B	  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
416B	  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
432B	  %27:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
448B	  %26:gr32 = COPY %27:gr32
464B	  %26:gr32 = ADD32rm %26:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
480B	  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
496B	  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
512B	  %19:gr64 = MOV64ri @.str.1
528B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
544B	  $rdi = COPY %19:gr64
560B	  $esi = COPY %22:gr32
576B	  $al = MOV8ri 0
592B	  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $esi, implicit-def $eax
608B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
624B	  dead %21:gr32 = COPY killed $eax
640B	  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
656B	  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
672B	  %16:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
688B	  %15:gr32 = COPY %16:gr32
704B	  %15:gr32 = ADD32ri8 %15:gr32(tied-def 0), 1, implicit-def dead $eflags
720B	  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
736B	  JMP_1 %bb.1

752B	bb.3 (%ir-block.22):
	; predecessors: %bb.1
	  successors: %bb.5, %bb.4

768B	  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
784B	  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
800B	  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
816B	  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
832B	  JCC_1 %bb.5, 5, implicit killed $eflags

848B	bb.4.SP_return:
	; predecessors: %bb.3

864B	  $eax = COPY %0:gr32
880B	  RET64 implicit killed $eax

896B	bb.5.CallStackCheckFailBlk:
	; predecessors: %bb.3

912B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
928B	  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
944B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before Simple Register Coalescing (simple-register-coalescing) ***:
# Machine code for function main: NoPHIs, TracksLiveness, TiedOpsRewritten
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

0B	bb.0 (%ir-block.0):
	  successors: %bb.1

16B	  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
32B	  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
48B	  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
64B	  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
80B	  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
96B	  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
112B	  %1:gr64 = MOV64ri @.str
128B	  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
144B	  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
160B	  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
176B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
192B	  $rdi = COPY %1:gr64
208B	  $rsi = COPY %2:gr64
224B	  $rdx = COPY %3:gr64
240B	  $rcx = COPY %4:gr64
256B	  $al = MOV8ri 0
272B	  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $rsi, implicit killed $rdx, implicit killed $rcx, implicit-def $eax
288B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
304B	  dead %5:gr32 = COPY killed $eax

320B	bb.1 (%ir-block.8):
	; predecessors: %bb.0, %bb.2
	  successors: %bb.3, %bb.2

336B	  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
352B	  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
368B	  JCC_1 %bb.3, 13, implicit killed $eflags

384B	bb.2 (%ir-block.12):
	; predecessors: %bb.1
	  successors: %bb.1

400B	  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
416B	  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
432B	  %27:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
448B	  %26:gr32 = COPY %27:gr32
464B	  %26:gr32 = ADD32rm %26:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
480B	  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
496B	  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
512B	  %19:gr64 = MOV64ri @.str.1
528B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
544B	  $rdi = COPY %19:gr64
560B	  $esi = COPY %22:gr32
576B	  $al = MOV8ri 0
592B	  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $esi, implicit-def $eax
608B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
624B	  dead %21:gr32 = COPY killed $eax
640B	  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
656B	  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
672B	  %16:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
688B	  %15:gr32 = COPY %16:gr32
704B	  %15:gr32 = ADD32ri8 %15:gr32(tied-def 0), 1, implicit-def dead $eflags
720B	  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
736B	  JMP_1 %bb.1

752B	bb.3 (%ir-block.22):
	; predecessors: %bb.1
	  successors: %bb.5, %bb.4

768B	  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
784B	  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
800B	  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
816B	  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
832B	  JCC_1 %bb.5, 5, implicit killed $eflags

848B	bb.4.SP_return:
	; predecessors: %bb.3

864B	  $eax = COPY %0:gr32
880B	  RET64 implicit killed $eax

896B	bb.5.CallStackCheckFailBlk:
	; predecessors: %bb.3

912B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
928B	  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
944B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After Simple Register Coalescing (simple-register-coalescing) ***:
# Machine code for function main: NoPHIs, TracksLiveness, TiedOpsRewritten
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

0B	bb.0 (%ir-block.0):
	  successors: %bb.1

16B	  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
32B	  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
48B	  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
64B	  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
80B	  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
96B	  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
112B	  %1:gr64 = MOV64ri @.str
128B	  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
144B	  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
160B	  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
176B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
192B	  $rdi = COPY %1:gr64
208B	  $rsi = COPY %2:gr64
224B	  $rdx = COPY %3:gr64
240B	  $rcx = COPY %4:gr64
256B	  $al = MOV8ri 0
272B	  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $rsi, implicit killed $rdx, implicit killed $rcx, implicit-def $eax
288B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
304B	  dead %5:gr32 = COPY killed $eax

320B	bb.1 (%ir-block.8):
	; predecessors: %bb.0, %bb.2
	  successors: %bb.3, %bb.2

336B	  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
352B	  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
368B	  JCC_1 %bb.3, 13, implicit killed $eflags

384B	bb.2 (%ir-block.12):
	; predecessors: %bb.1
	  successors: %bb.1

400B	  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
416B	  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
432B	  %26:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
464B	  %26:gr32 = ADD32rm %26:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
480B	  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
496B	  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
512B	  %19:gr64 = MOV64ri @.str.1
528B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
544B	  $rdi = COPY %19:gr64
560B	  $esi = COPY %22:gr32
576B	  $al = MOV8ri 0
592B	  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $esi, implicit-def $eax
608B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
624B	  dead %21:gr32 = COPY killed $eax
640B	  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
656B	  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
672B	  %15:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
704B	  %15:gr32 = ADD32ri8 %15:gr32(tied-def 0), 1, implicit-def dead $eflags
720B	  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
736B	  JMP_1 %bb.1

752B	bb.3 (%ir-block.22):
	; predecessors: %bb.1
	  successors: %bb.5, %bb.4

768B	  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
784B	  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
800B	  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
816B	  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
832B	  JCC_1 %bb.5, 5, implicit killed $eflags

848B	bb.4.SP_return:
	; predecessors: %bb.3

864B	  $eax = COPY %0:gr32
880B	  RET64 implicit killed $eax

896B	bb.5.CallStackCheckFailBlk:
	; predecessors: %bb.3

912B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
928B	  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
944B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before Rename Disconnected Subregister Components (rename-independent-subregs) ***:
# Machine code for function main: NoPHIs, TracksLiveness, TiedOpsRewritten
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

0B	bb.0 (%ir-block.0):
	  successors: %bb.1

16B	  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
32B	  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
48B	  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
64B	  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
80B	  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
96B	  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
112B	  %1:gr64 = MOV64ri @.str
128B	  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
144B	  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
160B	  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
176B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
192B	  $rdi = COPY %1:gr64
208B	  $rsi = COPY %2:gr64
224B	  $rdx = COPY %3:gr64
240B	  $rcx = COPY %4:gr64
256B	  $al = MOV8ri 0
272B	  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $rsi, implicit killed $rdx, implicit killed $rcx, implicit-def $eax
288B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
304B	  dead %5:gr32 = COPY killed $eax

320B	bb.1 (%ir-block.8):
	; predecessors: %bb.0, %bb.2
	  successors: %bb.3, %bb.2

336B	  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
352B	  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
368B	  JCC_1 %bb.3, 13, implicit killed $eflags

384B	bb.2 (%ir-block.12):
	; predecessors: %bb.1
	  successors: %bb.1

400B	  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
416B	  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
432B	  %26:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
464B	  %26:gr32 = ADD32rm %26:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
480B	  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
496B	  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
512B	  %19:gr64 = MOV64ri @.str.1
528B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
544B	  $rdi = COPY %19:gr64
560B	  $esi = COPY %22:gr32
576B	  $al = MOV8ri 0
592B	  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $esi, implicit-def $eax
608B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
624B	  dead %21:gr32 = COPY killed $eax
640B	  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
656B	  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
672B	  %15:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
704B	  %15:gr32 = ADD32ri8 %15:gr32(tied-def 0), 1, implicit-def dead $eflags
720B	  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
736B	  JMP_1 %bb.1

752B	bb.3 (%ir-block.22):
	; predecessors: %bb.1
	  successors: %bb.5, %bb.4

768B	  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
784B	  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
800B	  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
816B	  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
832B	  JCC_1 %bb.5, 5, implicit killed $eflags

848B	bb.4.SP_return:
	; predecessors: %bb.3

864B	  $eax = COPY %0:gr32
880B	  RET64 implicit killed $eax

896B	bb.5.CallStackCheckFailBlk:
	; predecessors: %bb.3

912B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
928B	  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
944B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After Rename Disconnected Subregister Components (rename-independent-subregs) ***:
# Machine code for function main: NoPHIs, TracksLiveness, TiedOpsRewritten
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

0B	bb.0 (%ir-block.0):
	  successors: %bb.1

16B	  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
32B	  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
48B	  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
64B	  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
80B	  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
96B	  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
112B	  %1:gr64 = MOV64ri @.str
128B	  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
144B	  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
160B	  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
176B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
192B	  $rdi = COPY %1:gr64
208B	  $rsi = COPY %2:gr64
224B	  $rdx = COPY %3:gr64
240B	  $rcx = COPY %4:gr64
256B	  $al = MOV8ri 0
272B	  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $rsi, implicit killed $rdx, implicit killed $rcx, implicit-def $eax
288B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
304B	  dead %5:gr32 = COPY killed $eax

320B	bb.1 (%ir-block.8):
	; predecessors: %bb.0, %bb.2
	  successors: %bb.3, %bb.2

336B	  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
352B	  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
368B	  JCC_1 %bb.3, 13, implicit killed $eflags

384B	bb.2 (%ir-block.12):
	; predecessors: %bb.1
	  successors: %bb.1

400B	  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
416B	  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
432B	  %26:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
464B	  %26:gr32 = ADD32rm %26:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
480B	  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
496B	  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
512B	  %19:gr64 = MOV64ri @.str.1
528B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
544B	  $rdi = COPY %19:gr64
560B	  $esi = COPY %22:gr32
576B	  $al = MOV8ri 0
592B	  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $esi, implicit-def $eax
608B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
624B	  dead %21:gr32 = COPY killed $eax
640B	  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
656B	  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
672B	  %15:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
704B	  %15:gr32 = ADD32ri8 %15:gr32(tied-def 0), 1, implicit-def dead $eflags
720B	  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
736B	  JMP_1 %bb.1

752B	bb.3 (%ir-block.22):
	; predecessors: %bb.1
	  successors: %bb.5, %bb.4

768B	  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
784B	  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
800B	  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
816B	  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
832B	  JCC_1 %bb.5, 5, implicit killed $eflags

848B	bb.4.SP_return:
	; predecessors: %bb.3

864B	  $eax = COPY %0:gr32
880B	  RET64 implicit killed $eax

896B	bb.5.CallStackCheckFailBlk:
	; predecessors: %bb.3

912B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
928B	  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
944B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before Machine Instruction Scheduler (machine-scheduler) ***:
# Machine code for function main: NoPHIs, TracksLiveness, TiedOpsRewritten
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

0B	bb.0 (%ir-block.0):
	  successors: %bb.1

16B	  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
32B	  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
48B	  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
64B	  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
80B	  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
96B	  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
112B	  %1:gr64 = MOV64ri @.str
128B	  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
144B	  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
160B	  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
176B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
192B	  $rdi = COPY %1:gr64
208B	  $rsi = COPY %2:gr64
224B	  $rdx = COPY %3:gr64
240B	  $rcx = COPY %4:gr64
256B	  $al = MOV8ri 0
272B	  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $rsi, implicit killed $rdx, implicit killed $rcx, implicit-def $eax
288B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
304B	  dead %5:gr32 = COPY killed $eax

320B	bb.1 (%ir-block.8):
	; predecessors: %bb.0, %bb.2
	  successors: %bb.3, %bb.2

336B	  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
352B	  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
368B	  JCC_1 %bb.3, 13, implicit killed $eflags

384B	bb.2 (%ir-block.12):
	; predecessors: %bb.1
	  successors: %bb.1

400B	  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
416B	  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
432B	  %26:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
464B	  %26:gr32 = ADD32rm %26:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
480B	  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
496B	  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
512B	  %19:gr64 = MOV64ri @.str.1
528B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
544B	  $rdi = COPY %19:gr64
560B	  $esi = COPY %22:gr32
576B	  $al = MOV8ri 0
592B	  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $esi, implicit-def $eax
608B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
624B	  dead %21:gr32 = COPY killed $eax
640B	  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
656B	  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
672B	  %15:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
704B	  %15:gr32 = ADD32ri8 %15:gr32(tied-def 0), 1, implicit-def dead $eflags
720B	  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
736B	  JMP_1 %bb.1

752B	bb.3 (%ir-block.22):
	; predecessors: %bb.1
	  successors: %bb.5, %bb.4

768B	  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
784B	  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
800B	  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
816B	  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
832B	  JCC_1 %bb.5, 5, implicit killed $eflags

848B	bb.4.SP_return:
	; predecessors: %bb.3

864B	  $eax = COPY %0:gr32
880B	  RET64 implicit killed $eax

896B	bb.5.CallStackCheckFailBlk:
	; predecessors: %bb.3

912B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
928B	  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
944B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After Machine Instruction Scheduler (machine-scheduler) ***:
# Machine code for function main: NoPHIs, TracksLiveness, TiedOpsRewritten
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

0B	bb.0 (%ir-block.0):
	  successors: %bb.1

16B	  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
32B	  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
48B	  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
64B	  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
80B	  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
96B	  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
112B	  %1:gr64 = MOV64ri @.str
128B	  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
144B	  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
160B	  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
176B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
192B	  $rdi = COPY %1:gr64
208B	  $rsi = COPY %2:gr64
224B	  $rdx = COPY %3:gr64
240B	  $rcx = COPY %4:gr64
256B	  $al = MOV8ri 0
272B	  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $rsi, implicit killed $rdx, implicit killed $rcx, implicit-def $eax
288B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
304B	  dead %5:gr32 = COPY killed $eax

320B	bb.1 (%ir-block.8):
	; predecessors: %bb.0, %bb.2
	  successors: %bb.3, %bb.2

336B	  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
352B	  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
368B	  JCC_1 %bb.3, 13, implicit killed $eflags

384B	bb.2 (%ir-block.12):
	; predecessors: %bb.1
	  successors: %bb.1

400B	  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
416B	  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
432B	  %26:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
464B	  %26:gr32 = ADD32rm %26:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
480B	  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
496B	  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
512B	  %19:gr64 = MOV64ri @.str.1
528B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
544B	  $rdi = COPY %19:gr64
560B	  $esi = COPY %22:gr32
576B	  $al = MOV8ri 0
592B	  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $esi, implicit-def $eax
608B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
624B	  dead %21:gr32 = COPY killed $eax
640B	  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
656B	  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
672B	  %15:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
704B	  %15:gr32 = ADD32ri8 %15:gr32(tied-def 0), 1, implicit-def dead $eflags
720B	  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
736B	  JMP_1 %bb.1

752B	bb.3 (%ir-block.22):
	; predecessors: %bb.1
	  successors: %bb.5, %bb.4

768B	  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
784B	  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
800B	  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
816B	  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
832B	  JCC_1 %bb.5, 5, implicit killed $eflags

848B	bb.4.SP_return:
	; predecessors: %bb.3

864B	  $eax = COPY %0:gr32
880B	  RET64 implicit killed $eax

896B	bb.5.CallStackCheckFailBlk:
	; predecessors: %bb.3

912B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
928B	  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
944B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before Debug Variable Analysis (livedebugvars) ***:
# Machine code for function main: NoPHIs, TracksLiveness, TiedOpsRewritten
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

0B	bb.0 (%ir-block.0):
	  successors: %bb.1

16B	  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
32B	  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
48B	  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
64B	  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
80B	  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
96B	  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
112B	  %1:gr64 = MOV64ri @.str
128B	  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
144B	  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
160B	  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
176B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
192B	  $rdi = COPY %1:gr64
208B	  $rsi = COPY %2:gr64
224B	  $rdx = COPY %3:gr64
240B	  $rcx = COPY %4:gr64
256B	  $al = MOV8ri 0
272B	  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $rsi, implicit killed $rdx, implicit killed $rcx, implicit-def $eax
288B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
304B	  dead %5:gr32 = COPY killed $eax

320B	bb.1 (%ir-block.8):
	; predecessors: %bb.0, %bb.2
	  successors: %bb.3, %bb.2

336B	  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
352B	  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
368B	  JCC_1 %bb.3, 13, implicit killed $eflags

384B	bb.2 (%ir-block.12):
	; predecessors: %bb.1
	  successors: %bb.1

400B	  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
416B	  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
432B	  %26:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
464B	  %26:gr32 = ADD32rm %26:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
480B	  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
496B	  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
512B	  %19:gr64 = MOV64ri @.str.1
528B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
544B	  $rdi = COPY %19:gr64
560B	  $esi = COPY %22:gr32
576B	  $al = MOV8ri 0
592B	  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $esi, implicit-def $eax
608B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
624B	  dead %21:gr32 = COPY killed $eax
640B	  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
656B	  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
672B	  %15:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
704B	  %15:gr32 = ADD32ri8 %15:gr32(tied-def 0), 1, implicit-def dead $eflags
720B	  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
736B	  JMP_1 %bb.1

752B	bb.3 (%ir-block.22):
	; predecessors: %bb.1
	  successors: %bb.5, %bb.4

768B	  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
784B	  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
800B	  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
816B	  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
832B	  JCC_1 %bb.5, 5, implicit killed $eflags

848B	bb.4.SP_return:
	; predecessors: %bb.3

864B	  $eax = COPY %0:gr32
880B	  RET64 implicit killed $eax

896B	bb.5.CallStackCheckFailBlk:
	; predecessors: %bb.3

912B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
928B	  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
944B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After Debug Variable Analysis (livedebugvars) ***:
# Machine code for function main: NoPHIs, TracksLiveness, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

0B	bb.0 (%ir-block.0):
	  successors: %bb.1

16B	  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
32B	  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
48B	  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
64B	  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
80B	  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
96B	  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
112B	  %1:gr64 = MOV64ri @.str
128B	  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
144B	  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
160B	  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
176B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
192B	  $rdi = COPY %1:gr64
208B	  $rsi = COPY %2:gr64
224B	  $rdx = COPY %3:gr64
240B	  $rcx = COPY %4:gr64
256B	  $al = MOV8ri 0
272B	  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $rsi, implicit killed $rdx, implicit killed $rcx, implicit-def $eax
288B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
304B	  dead %5:gr32 = COPY killed $eax

320B	bb.1 (%ir-block.8):
	; predecessors: %bb.0, %bb.2
	  successors: %bb.3, %bb.2

336B	  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
352B	  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
368B	  JCC_1 %bb.3, 13, implicit killed $eflags

384B	bb.2 (%ir-block.12):
	; predecessors: %bb.1
	  successors: %bb.1

400B	  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
416B	  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
432B	  %26:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
464B	  %26:gr32 = ADD32rm %26:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
480B	  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
496B	  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
512B	  %19:gr64 = MOV64ri @.str.1
528B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
544B	  $rdi = COPY %19:gr64
560B	  $esi = COPY %22:gr32
576B	  $al = MOV8ri 0
592B	  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $esi, implicit-def $eax
608B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
624B	  dead %21:gr32 = COPY killed $eax
640B	  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
656B	  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
672B	  %15:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
704B	  %15:gr32 = ADD32ri8 %15:gr32(tied-def 0), 1, implicit-def dead $eflags
720B	  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
736B	  JMP_1 %bb.1

752B	bb.3 (%ir-block.22):
	; predecessors: %bb.1
	  successors: %bb.5, %bb.4

768B	  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
784B	  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
800B	  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
816B	  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
832B	  JCC_1 %bb.5, 5, implicit killed $eflags

848B	bb.4.SP_return:
	; predecessors: %bb.3

864B	  $eax = COPY %0:gr32
880B	  RET64 implicit killed $eax

896B	bb.5.CallStackCheckFailBlk:
	; predecessors: %bb.3

912B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
928B	  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
944B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before Live Stack Slot Analysis (livestacks) ***:
# Machine code for function main: NoPHIs, TracksLiveness, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

0B	bb.0 (%ir-block.0):
	  successors: %bb.1

16B	  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
32B	  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
48B	  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
64B	  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
80B	  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
96B	  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
112B	  %1:gr64 = MOV64ri @.str
128B	  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
144B	  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
160B	  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
176B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
192B	  $rdi = COPY %1:gr64
208B	  $rsi = COPY %2:gr64
224B	  $rdx = COPY %3:gr64
240B	  $rcx = COPY %4:gr64
256B	  $al = MOV8ri 0
272B	  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $rsi, implicit killed $rdx, implicit killed $rcx, implicit-def $eax
288B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
304B	  dead %5:gr32 = COPY killed $eax

320B	bb.1 (%ir-block.8):
	; predecessors: %bb.0, %bb.2
	  successors: %bb.3, %bb.2

336B	  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
352B	  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
368B	  JCC_1 %bb.3, 13, implicit killed $eflags

384B	bb.2 (%ir-block.12):
	; predecessors: %bb.1
	  successors: %bb.1

400B	  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
416B	  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
432B	  %26:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
464B	  %26:gr32 = ADD32rm %26:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
480B	  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
496B	  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
512B	  %19:gr64 = MOV64ri @.str.1
528B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
544B	  $rdi = COPY %19:gr64
560B	  $esi = COPY %22:gr32
576B	  $al = MOV8ri 0
592B	  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $esi, implicit-def $eax
608B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
624B	  dead %21:gr32 = COPY killed $eax
640B	  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
656B	  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
672B	  %15:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
704B	  %15:gr32 = ADD32ri8 %15:gr32(tied-def 0), 1, implicit-def dead $eflags
720B	  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
736B	  JMP_1 %bb.1

752B	bb.3 (%ir-block.22):
	; predecessors: %bb.1
	  successors: %bb.5, %bb.4

768B	  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
784B	  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
800B	  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
816B	  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
832B	  JCC_1 %bb.5, 5, implicit killed $eflags

848B	bb.4.SP_return:
	; predecessors: %bb.3

864B	  $eax = COPY %0:gr32
880B	  RET64 implicit killed $eax

896B	bb.5.CallStackCheckFailBlk:
	; predecessors: %bb.3

912B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
928B	  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
944B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After Live Stack Slot Analysis (livestacks) ***:
# Machine code for function main: NoPHIs, TracksLiveness, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

0B	bb.0 (%ir-block.0):
	  successors: %bb.1

16B	  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
32B	  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
48B	  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
64B	  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
80B	  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
96B	  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
112B	  %1:gr64 = MOV64ri @.str
128B	  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
144B	  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
160B	  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
176B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
192B	  $rdi = COPY %1:gr64
208B	  $rsi = COPY %2:gr64
224B	  $rdx = COPY %3:gr64
240B	  $rcx = COPY %4:gr64
256B	  $al = MOV8ri 0
272B	  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $rsi, implicit killed $rdx, implicit killed $rcx, implicit-def $eax
288B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
304B	  dead %5:gr32 = COPY killed $eax

320B	bb.1 (%ir-block.8):
	; predecessors: %bb.0, %bb.2
	  successors: %bb.3, %bb.2

336B	  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
352B	  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
368B	  JCC_1 %bb.3, 13, implicit killed $eflags

384B	bb.2 (%ir-block.12):
	; predecessors: %bb.1
	  successors: %bb.1

400B	  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
416B	  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
432B	  %26:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
464B	  %26:gr32 = ADD32rm %26:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
480B	  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
496B	  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
512B	  %19:gr64 = MOV64ri @.str.1
528B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
544B	  $rdi = COPY %19:gr64
560B	  $esi = COPY %22:gr32
576B	  $al = MOV8ri 0
592B	  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $esi, implicit-def $eax
608B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
624B	  dead %21:gr32 = COPY killed $eax
640B	  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
656B	  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
672B	  %15:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
704B	  %15:gr32 = ADD32ri8 %15:gr32(tied-def 0), 1, implicit-def dead $eflags
720B	  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
736B	  JMP_1 %bb.1

752B	bb.3 (%ir-block.22):
	; predecessors: %bb.1
	  successors: %bb.5, %bb.4

768B	  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
784B	  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
800B	  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
816B	  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
832B	  JCC_1 %bb.5, 5, implicit killed $eflags

848B	bb.4.SP_return:
	; predecessors: %bb.3

864B	  $eax = COPY %0:gr32
880B	  RET64 implicit killed $eax

896B	bb.5.CallStackCheckFailBlk:
	; predecessors: %bb.3

912B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
928B	  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
944B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before Virtual Register Map (virtregmap) ***:
# Machine code for function main: NoPHIs, TracksLiveness, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

0B	bb.0 (%ir-block.0):
	  successors: %bb.1

16B	  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
32B	  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
48B	  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
64B	  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
80B	  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
96B	  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
112B	  %1:gr64 = MOV64ri @.str
128B	  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
144B	  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
160B	  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
176B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
192B	  $rdi = COPY %1:gr64
208B	  $rsi = COPY %2:gr64
224B	  $rdx = COPY %3:gr64
240B	  $rcx = COPY %4:gr64
256B	  $al = MOV8ri 0
272B	  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $rsi, implicit killed $rdx, implicit killed $rcx, implicit-def $eax
288B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
304B	  dead %5:gr32 = COPY killed $eax

320B	bb.1 (%ir-block.8):
	; predecessors: %bb.0, %bb.2
	  successors: %bb.3, %bb.2

336B	  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
352B	  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
368B	  JCC_1 %bb.3, 13, implicit killed $eflags

384B	bb.2 (%ir-block.12):
	; predecessors: %bb.1
	  successors: %bb.1

400B	  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
416B	  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
432B	  %26:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
464B	  %26:gr32 = ADD32rm %26:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
480B	  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
496B	  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
512B	  %19:gr64 = MOV64ri @.str.1
528B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
544B	  $rdi = COPY %19:gr64
560B	  $esi = COPY %22:gr32
576B	  $al = MOV8ri 0
592B	  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $esi, implicit-def $eax
608B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
624B	  dead %21:gr32 = COPY killed $eax
640B	  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
656B	  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
672B	  %15:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
704B	  %15:gr32 = ADD32ri8 %15:gr32(tied-def 0), 1, implicit-def dead $eflags
720B	  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
736B	  JMP_1 %bb.1

752B	bb.3 (%ir-block.22):
	; predecessors: %bb.1
	  successors: %bb.5, %bb.4

768B	  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
784B	  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
800B	  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
816B	  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
832B	  JCC_1 %bb.5, 5, implicit killed $eflags

848B	bb.4.SP_return:
	; predecessors: %bb.3

864B	  $eax = COPY %0:gr32
880B	  RET64 implicit killed $eax

896B	bb.5.CallStackCheckFailBlk:
	; predecessors: %bb.3

912B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
928B	  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
944B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After Virtual Register Map (virtregmap) ***:
# Machine code for function main: NoPHIs, TracksLiveness, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

0B	bb.0 (%ir-block.0):
	  successors: %bb.1

16B	  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
32B	  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
48B	  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
64B	  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
80B	  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
96B	  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
112B	  %1:gr64 = MOV64ri @.str
128B	  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
144B	  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
160B	  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
176B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
192B	  $rdi = COPY %1:gr64
208B	  $rsi = COPY %2:gr64
224B	  $rdx = COPY %3:gr64
240B	  $rcx = COPY %4:gr64
256B	  $al = MOV8ri 0
272B	  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $rsi, implicit killed $rdx, implicit killed $rcx, implicit-def $eax
288B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
304B	  dead %5:gr32 = COPY killed $eax

320B	bb.1 (%ir-block.8):
	; predecessors: %bb.0, %bb.2
	  successors: %bb.3, %bb.2

336B	  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
352B	  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
368B	  JCC_1 %bb.3, 13, implicit killed $eflags

384B	bb.2 (%ir-block.12):
	; predecessors: %bb.1
	  successors: %bb.1

400B	  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
416B	  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
432B	  %26:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
464B	  %26:gr32 = ADD32rm %26:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
480B	  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
496B	  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
512B	  %19:gr64 = MOV64ri @.str.1
528B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
544B	  $rdi = COPY %19:gr64
560B	  $esi = COPY %22:gr32
576B	  $al = MOV8ri 0
592B	  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $esi, implicit-def $eax
608B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
624B	  dead %21:gr32 = COPY killed $eax
640B	  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
656B	  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
672B	  %15:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
704B	  %15:gr32 = ADD32ri8 %15:gr32(tied-def 0), 1, implicit-def dead $eflags
720B	  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
736B	  JMP_1 %bb.1

752B	bb.3 (%ir-block.22):
	; predecessors: %bb.1
	  successors: %bb.5, %bb.4

768B	  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
784B	  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
800B	  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
816B	  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
832B	  JCC_1 %bb.5, 5, implicit killed $eflags

848B	bb.4.SP_return:
	; predecessors: %bb.3

864B	  $eax = COPY %0:gr32
880B	  RET64 implicit killed $eax

896B	bb.5.CallStackCheckFailBlk:
	; predecessors: %bb.3

912B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
928B	  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
944B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before Live Register Matrix (liveregmatrix) ***:
# Machine code for function main: NoPHIs, TracksLiveness, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

0B	bb.0 (%ir-block.0):
	  successors: %bb.1

16B	  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
32B	  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
48B	  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
64B	  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
80B	  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
96B	  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
112B	  %1:gr64 = MOV64ri @.str
128B	  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
144B	  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
160B	  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
176B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
192B	  $rdi = COPY %1:gr64
208B	  $rsi = COPY %2:gr64
224B	  $rdx = COPY %3:gr64
240B	  $rcx = COPY %4:gr64
256B	  $al = MOV8ri 0
272B	  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $rsi, implicit killed $rdx, implicit killed $rcx, implicit-def $eax
288B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
304B	  dead %5:gr32 = COPY killed $eax

320B	bb.1 (%ir-block.8):
	; predecessors: %bb.0, %bb.2
	  successors: %bb.3, %bb.2

336B	  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
352B	  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
368B	  JCC_1 %bb.3, 13, implicit killed $eflags

384B	bb.2 (%ir-block.12):
	; predecessors: %bb.1
	  successors: %bb.1

400B	  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
416B	  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
432B	  %26:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
464B	  %26:gr32 = ADD32rm %26:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
480B	  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
496B	  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
512B	  %19:gr64 = MOV64ri @.str.1
528B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
544B	  $rdi = COPY %19:gr64
560B	  $esi = COPY %22:gr32
576B	  $al = MOV8ri 0
592B	  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $esi, implicit-def $eax
608B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
624B	  dead %21:gr32 = COPY killed $eax
640B	  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
656B	  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
672B	  %15:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
704B	  %15:gr32 = ADD32ri8 %15:gr32(tied-def 0), 1, implicit-def dead $eflags
720B	  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
736B	  JMP_1 %bb.1

752B	bb.3 (%ir-block.22):
	; predecessors: %bb.1
	  successors: %bb.5, %bb.4

768B	  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
784B	  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
800B	  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
816B	  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
832B	  JCC_1 %bb.5, 5, implicit killed $eflags

848B	bb.4.SP_return:
	; predecessors: %bb.3

864B	  $eax = COPY %0:gr32
880B	  RET64 implicit killed $eax

896B	bb.5.CallStackCheckFailBlk:
	; predecessors: %bb.3

912B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
928B	  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
944B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After Live Register Matrix (liveregmatrix) ***:
# Machine code for function main: NoPHIs, TracksLiveness, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

0B	bb.0 (%ir-block.0):
	  successors: %bb.1

16B	  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
32B	  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
48B	  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
64B	  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
80B	  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
96B	  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
112B	  %1:gr64 = MOV64ri @.str
128B	  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
144B	  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
160B	  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
176B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
192B	  $rdi = COPY %1:gr64
208B	  $rsi = COPY %2:gr64
224B	  $rdx = COPY %3:gr64
240B	  $rcx = COPY %4:gr64
256B	  $al = MOV8ri 0
272B	  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $rsi, implicit killed $rdx, implicit killed $rcx, implicit-def $eax
288B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
304B	  dead %5:gr32 = COPY killed $eax

320B	bb.1 (%ir-block.8):
	; predecessors: %bb.0, %bb.2
	  successors: %bb.3, %bb.2

336B	  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
352B	  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
368B	  JCC_1 %bb.3, 13, implicit killed $eflags

384B	bb.2 (%ir-block.12):
	; predecessors: %bb.1
	  successors: %bb.1

400B	  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
416B	  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
432B	  %26:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
464B	  %26:gr32 = ADD32rm %26:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
480B	  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
496B	  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
512B	  %19:gr64 = MOV64ri @.str.1
528B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
544B	  $rdi = COPY %19:gr64
560B	  $esi = COPY %22:gr32
576B	  $al = MOV8ri 0
592B	  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $esi, implicit-def $eax
608B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
624B	  dead %21:gr32 = COPY killed $eax
640B	  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
656B	  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
672B	  %15:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
704B	  %15:gr32 = ADD32ri8 %15:gr32(tied-def 0), 1, implicit-def dead $eflags
720B	  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
736B	  JMP_1 %bb.1

752B	bb.3 (%ir-block.22):
	; predecessors: %bb.1
	  successors: %bb.5, %bb.4

768B	  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
784B	  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
800B	  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
816B	  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
832B	  JCC_1 %bb.5, 5, implicit killed $eflags

848B	bb.4.SP_return:
	; predecessors: %bb.3

864B	  $eax = COPY %0:gr32
880B	  RET64 implicit killed $eax

896B	bb.5.CallStackCheckFailBlk:
	; predecessors: %bb.3

912B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
928B	  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
944B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before Greedy Register Allocator (greedy) ***:
# Machine code for function main: NoPHIs, TracksLiveness, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

0B	bb.0 (%ir-block.0):
	  successors: %bb.1

16B	  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
32B	  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
48B	  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
64B	  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
80B	  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
96B	  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
112B	  %1:gr64 = MOV64ri @.str
128B	  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
144B	  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
160B	  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
176B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
192B	  $rdi = COPY %1:gr64
208B	  $rsi = COPY %2:gr64
224B	  $rdx = COPY %3:gr64
240B	  $rcx = COPY %4:gr64
256B	  $al = MOV8ri 0
272B	  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $rsi, implicit killed $rdx, implicit killed $rcx, implicit-def $eax
288B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
304B	  dead %5:gr32 = COPY killed $eax

320B	bb.1 (%ir-block.8):
	; predecessors: %bb.0, %bb.2
	  successors: %bb.3, %bb.2

336B	  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
352B	  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
368B	  JCC_1 %bb.3, 13, implicit killed $eflags

384B	bb.2 (%ir-block.12):
	; predecessors: %bb.1
	  successors: %bb.1

400B	  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
416B	  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
432B	  %26:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
464B	  %26:gr32 = ADD32rm %26:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
480B	  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
496B	  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
512B	  %19:gr64 = MOV64ri @.str.1
528B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
544B	  $rdi = COPY %19:gr64
560B	  $esi = COPY %22:gr32
576B	  $al = MOV8ri 0
592B	  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $esi, implicit-def $eax
608B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
624B	  dead %21:gr32 = COPY killed $eax
640B	  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
656B	  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
672B	  %15:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
704B	  %15:gr32 = ADD32ri8 %15:gr32(tied-def 0), 1, implicit-def dead $eflags
720B	  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
736B	  JMP_1 %bb.1

752B	bb.3 (%ir-block.22):
	; predecessors: %bb.1
	  successors: %bb.5, %bb.4

768B	  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
784B	  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
800B	  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
816B	  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
832B	  JCC_1 %bb.5, 5, implicit killed $eflags

848B	bb.4.SP_return:
	; predecessors: %bb.3

864B	  $eax = COPY %0:gr32
880B	  RET64 implicit killed $eax

896B	bb.5.CallStackCheckFailBlk:
	; predecessors: %bb.3

912B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
928B	  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
944B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After Greedy Register Allocator (greedy) ***:
# Machine code for function main: NoPHIs, TracksLiveness, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

0B	bb.0 (%ir-block.0):
	  successors: %bb.1

16B	  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
32B	  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
48B	  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
64B	  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
80B	  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
96B	  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
112B	  %1:gr64 = MOV64ri @.str
128B	  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
144B	  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
160B	  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
176B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
192B	  $rdi = COPY %1:gr64
208B	  $rsi = COPY %2:gr64
224B	  $rdx = COPY %3:gr64
240B	  $rcx = COPY %4:gr64
256B	  $al = MOV8ri 0
272B	  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
288B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
304B	  dead %5:gr32 = COPY $eax

320B	bb.1 (%ir-block.8):
	; predecessors: %bb.0, %bb.2
	  successors: %bb.3, %bb.2

336B	  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
352B	  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
368B	  JCC_1 %bb.3, 13, implicit killed $eflags

384B	bb.2 (%ir-block.12):
	; predecessors: %bb.1
	  successors: %bb.1

400B	  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
416B	  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
432B	  %26:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
464B	  %26:gr32 = ADD32rm %26:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
480B	  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
496B	  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
512B	  %19:gr64 = MOV64ri @.str.1
528B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
544B	  $rdi = COPY %19:gr64
560B	  $esi = COPY %22:gr32
576B	  $al = MOV8ri 0
592B	  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
608B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
624B	  dead %21:gr32 = COPY $eax
640B	  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
656B	  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
672B	  %15:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
704B	  %15:gr32 = ADD32ri8 %15:gr32(tied-def 0), 1, implicit-def dead $eflags
720B	  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
736B	  JMP_1 %bb.1

752B	bb.3 (%ir-block.22):
	; predecessors: %bb.1
	  successors: %bb.5, %bb.4

768B	  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
784B	  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
800B	  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
816B	  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
832B	  JCC_1 %bb.5, 5, implicit killed $eflags

848B	bb.4.SP_return:
	; predecessors: %bb.3

864B	  $eax = COPY %0:gr32
880B	  RET64 implicit $eax

896B	bb.5.CallStackCheckFailBlk:
	; predecessors: %bb.3

912B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
928B	  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
944B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before Tile Register Configure (tileconfig) ***:
# Machine code for function main: NoPHIs, TracksLiveness, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

0B	bb.0 (%ir-block.0):
	  successors: %bb.1

16B	  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
32B	  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
48B	  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
64B	  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
80B	  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
96B	  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
112B	  %1:gr64 = MOV64ri @.str
128B	  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
144B	  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
160B	  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
176B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
192B	  $rdi = COPY %1:gr64
208B	  $rsi = COPY %2:gr64
224B	  $rdx = COPY %3:gr64
240B	  $rcx = COPY %4:gr64
256B	  $al = MOV8ri 0
272B	  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
288B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
304B	  dead %5:gr32 = COPY $eax

320B	bb.1 (%ir-block.8):
	; predecessors: %bb.0, %bb.2
	  successors: %bb.3, %bb.2

336B	  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
352B	  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
368B	  JCC_1 %bb.3, 13, implicit killed $eflags

384B	bb.2 (%ir-block.12):
	; predecessors: %bb.1
	  successors: %bb.1

400B	  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
416B	  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
432B	  %26:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
464B	  %26:gr32 = ADD32rm %26:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
480B	  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
496B	  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
512B	  %19:gr64 = MOV64ri @.str.1
528B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
544B	  $rdi = COPY %19:gr64
560B	  $esi = COPY %22:gr32
576B	  $al = MOV8ri 0
592B	  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
608B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
624B	  dead %21:gr32 = COPY $eax
640B	  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
656B	  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
672B	  %15:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
704B	  %15:gr32 = ADD32ri8 %15:gr32(tied-def 0), 1, implicit-def dead $eflags
720B	  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
736B	  JMP_1 %bb.1

752B	bb.3 (%ir-block.22):
	; predecessors: %bb.1
	  successors: %bb.5, %bb.4

768B	  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
784B	  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
800B	  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
816B	  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
832B	  JCC_1 %bb.5, 5, implicit killed $eflags

848B	bb.4.SP_return:
	; predecessors: %bb.3

864B	  $eax = COPY %0:gr32
880B	  RET64 implicit $eax

896B	bb.5.CallStackCheckFailBlk:
	; predecessors: %bb.3

912B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
928B	  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
944B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After Tile Register Configure (tileconfig) ***:
# Machine code for function main: NoPHIs, TracksLiveness, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

0B	bb.0 (%ir-block.0):
	  successors: %bb.1

16B	  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
32B	  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
48B	  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
64B	  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
80B	  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
96B	  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
112B	  %1:gr64 = MOV64ri @.str
128B	  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
144B	  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
160B	  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
176B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
192B	  $rdi = COPY %1:gr64
208B	  $rsi = COPY %2:gr64
224B	  $rdx = COPY %3:gr64
240B	  $rcx = COPY %4:gr64
256B	  $al = MOV8ri 0
272B	  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
288B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
304B	  dead %5:gr32 = COPY $eax

320B	bb.1 (%ir-block.8):
	; predecessors: %bb.0, %bb.2
	  successors: %bb.3, %bb.2

336B	  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
352B	  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
368B	  JCC_1 %bb.3, 13, implicit killed $eflags

384B	bb.2 (%ir-block.12):
	; predecessors: %bb.1
	  successors: %bb.1

400B	  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
416B	  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
432B	  %26:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
464B	  %26:gr32 = ADD32rm %26:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
480B	  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
496B	  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
512B	  %19:gr64 = MOV64ri @.str.1
528B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
544B	  $rdi = COPY %19:gr64
560B	  $esi = COPY %22:gr32
576B	  $al = MOV8ri 0
592B	  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
608B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
624B	  dead %21:gr32 = COPY $eax
640B	  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
656B	  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
672B	  %15:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
704B	  %15:gr32 = ADD32ri8 %15:gr32(tied-def 0), 1, implicit-def dead $eflags
720B	  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
736B	  JMP_1 %bb.1

752B	bb.3 (%ir-block.22):
	; predecessors: %bb.1
	  successors: %bb.5, %bb.4

768B	  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
784B	  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
800B	  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
816B	  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
832B	  JCC_1 %bb.5, 5, implicit killed $eflags

848B	bb.4.SP_return:
	; predecessors: %bb.3

864B	  $eax = COPY %0:gr32
880B	  RET64 implicit $eax

896B	bb.5.CallStackCheckFailBlk:
	; predecessors: %bb.3

912B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
928B	  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
944B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before Virtual Register Rewriter (virtregrewriter) ***:
# Machine code for function main: NoPHIs, TracksLiveness, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

0B	bb.0 (%ir-block.0):
	  successors: %bb.1

16B	  %6:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
32B	  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, %6:gr64
48B	  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
64B	  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
80B	  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
96B	  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
112B	  %1:gr64 = MOV64ri @.str
128B	  %2:gr64 = LEA64r %stack.5, 1, $noreg, 0, $noreg
144B	  %3:gr64 = LEA64r %stack.2, 1, $noreg, 0, $noreg
160B	  %4:gr64 = LEA64r %stack.3, 1, $noreg, 0, $noreg
176B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
192B	  $rdi = COPY %1:gr64
208B	  $rsi = COPY %2:gr64
224B	  $rdx = COPY %3:gr64
240B	  $rcx = COPY %4:gr64
256B	  $al = MOV8ri 0
272B	  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
288B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
304B	  dead %5:gr32 = COPY $eax

320B	bb.1 (%ir-block.8):
	; predecessors: %bb.0, %bb.2
	  successors: %bb.3, %bb.2

336B	  %9:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
352B	  CMP32rm %9:gr32, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
368B	  JCC_1 %bb.3, 13, implicit killed $eflags

384B	bb.2 (%ir-block.12):
	; predecessors: %bb.1
	  successors: %bb.1

400B	  %29:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
416B	  MOV32mr %stack.6, 1, $noreg, 0, $noreg, %29:gr32 :: (store (s32) into %ir.6)
432B	  %26:gr32 = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
464B	  %26:gr32 = ADD32rm %26:gr32(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
480B	  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %26:gr32 :: (store (s32) into %ir.3)
496B	  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
512B	  %19:gr64 = MOV64ri @.str.1
528B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
544B	  $rdi = COPY %19:gr64
560B	  $esi = COPY %22:gr32
576B	  $al = MOV8ri 0
592B	  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
608B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
624B	  dead %21:gr32 = COPY $eax
640B	  %18:gr32 = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
656B	  MOV32mr %stack.2, 1, $noreg, 0, $noreg, %18:gr32 :: (store (s32) into %ir.2)
672B	  %15:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
704B	  %15:gr32 = ADD32ri8 %15:gr32(tied-def 0), 1, implicit-def dead $eflags
720B	  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %15:gr32 :: (store (s32) into %ir.4)
736B	  JMP_1 %bb.1

752B	bb.3 (%ir-block.22):
	; predecessors: %bb.1
	  successors: %bb.5, %bb.4

768B	  %0:gr32 = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
784B	  %10:gr64 = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
800B	  %12:gr64 = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
816B	  CMP64rr %10:gr64, %12:gr64, implicit-def $eflags
832B	  JCC_1 %bb.5, 5, implicit killed $eflags

848B	bb.4.SP_return:
	; predecessors: %bb.3

864B	  $eax = COPY %0:gr32
880B	  RET64 implicit $eax

896B	bb.5.CallStackCheckFailBlk:
	; predecessors: %bb.3

912B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
928B	  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
944B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After Virtual Register Rewriter (virtregrewriter) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

0B	bb.0 (%ir-block.0):
	  successors: %bb.1

16B	  renamable $rax = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
32B	  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, killed renamable $rax
48B	  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
64B	  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
80B	  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
96B	  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
112B	  renamable $rdi = MOV64ri @.str
128B	  renamable $rsi = LEA64r %stack.5, 1, $noreg, 0, $noreg
144B	  renamable $rdx = LEA64r %stack.2, 1, $noreg, 0, $noreg
160B	  renamable $rcx = LEA64r %stack.3, 1, $noreg, 0, $noreg
176B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
256B	  $al = MOV8ri 0
272B	  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
288B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

320B	bb.1 (%ir-block.8):
	; predecessors: %bb.0, %bb.2
	  successors: %bb.3, %bb.2

336B	  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
352B	  CMP32rm killed renamable $eax, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
368B	  JCC_1 %bb.3, 13, implicit killed $eflags

384B	bb.2 (%ir-block.12):
	; predecessors: %bb.1
	  successors: %bb.1

400B	  renamable $eax = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
416B	  MOV32mr %stack.6, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.6)
432B	  renamable $eax = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
464B	  renamable $eax = ADD32rm killed renamable $eax(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
480B	  MOV32mr %stack.3, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.3)
496B	  renamable $esi = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
512B	  renamable $rdi = MOV64ri @.str.1
528B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
576B	  $al = MOV8ri 0
592B	  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
608B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
640B	  renamable $eax = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
656B	  MOV32mr %stack.2, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.2)
672B	  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
704B	  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
720B	  MOV32mr %stack.4, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
736B	  JMP_1 %bb.1

752B	bb.3 (%ir-block.22):
	; predecessors: %bb.1
	  successors: %bb.5, %bb.4

768B	  renamable $eax = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
784B	  renamable $rcx = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
800B	  renamable $rdx = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
816B	  CMP64rr killed renamable $rcx, killed renamable $rdx, implicit-def $eflags
832B	  JCC_1 %bb.5, 5, implicit killed $eflags

848B	bb.4.SP_return:
	; predecessors: %bb.3
	  liveins: $eax
880B	  RET64 implicit $eax

896B	bb.5.CallStackCheckFailBlk:
	; predecessors: %bb.3

912B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
928B	  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
944B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before Register Allocation Pass Scoring (regallocscoringpass) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

0B	bb.0 (%ir-block.0):
	  successors: %bb.1

16B	  renamable $rax = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
32B	  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, killed renamable $rax
48B	  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
64B	  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
80B	  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
96B	  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
112B	  renamable $rdi = MOV64ri @.str
128B	  renamable $rsi = LEA64r %stack.5, 1, $noreg, 0, $noreg
144B	  renamable $rdx = LEA64r %stack.2, 1, $noreg, 0, $noreg
160B	  renamable $rcx = LEA64r %stack.3, 1, $noreg, 0, $noreg
176B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
256B	  $al = MOV8ri 0
272B	  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
288B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

320B	bb.1 (%ir-block.8):
	; predecessors: %bb.0, %bb.2
	  successors: %bb.3, %bb.2

336B	  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
352B	  CMP32rm killed renamable $eax, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
368B	  JCC_1 %bb.3, 13, implicit killed $eflags

384B	bb.2 (%ir-block.12):
	; predecessors: %bb.1
	  successors: %bb.1

400B	  renamable $eax = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
416B	  MOV32mr %stack.6, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.6)
432B	  renamable $eax = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
464B	  renamable $eax = ADD32rm killed renamable $eax(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
480B	  MOV32mr %stack.3, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.3)
496B	  renamable $esi = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
512B	  renamable $rdi = MOV64ri @.str.1
528B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
576B	  $al = MOV8ri 0
592B	  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
608B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
640B	  renamable $eax = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
656B	  MOV32mr %stack.2, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.2)
672B	  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
704B	  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
720B	  MOV32mr %stack.4, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
736B	  JMP_1 %bb.1

752B	bb.3 (%ir-block.22):
	; predecessors: %bb.1
	  successors: %bb.5, %bb.4

768B	  renamable $eax = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
784B	  renamable $rcx = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
800B	  renamable $rdx = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
816B	  CMP64rr killed renamable $rcx, killed renamable $rdx, implicit-def $eflags
832B	  JCC_1 %bb.5, 5, implicit killed $eflags

848B	bb.4.SP_return:
	; predecessors: %bb.3
	  liveins: $eax
880B	  RET64 implicit $eax

896B	bb.5.CallStackCheckFailBlk:
	; predecessors: %bb.3

912B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
928B	  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
944B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After Register Allocation Pass Scoring (regallocscoringpass) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

0B	bb.0 (%ir-block.0):
	  successors: %bb.1

16B	  renamable $rax = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
32B	  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, killed renamable $rax
48B	  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
64B	  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
80B	  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
96B	  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
112B	  renamable $rdi = MOV64ri @.str
128B	  renamable $rsi = LEA64r %stack.5, 1, $noreg, 0, $noreg
144B	  renamable $rdx = LEA64r %stack.2, 1, $noreg, 0, $noreg
160B	  renamable $rcx = LEA64r %stack.3, 1, $noreg, 0, $noreg
176B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
256B	  $al = MOV8ri 0
272B	  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
288B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

320B	bb.1 (%ir-block.8):
	; predecessors: %bb.0, %bb.2
	  successors: %bb.3, %bb.2

336B	  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
352B	  CMP32rm killed renamable $eax, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
368B	  JCC_1 %bb.3, 13, implicit killed $eflags

384B	bb.2 (%ir-block.12):
	; predecessors: %bb.1
	  successors: %bb.1

400B	  renamable $eax = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
416B	  MOV32mr %stack.6, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.6)
432B	  renamable $eax = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
464B	  renamable $eax = ADD32rm killed renamable $eax(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
480B	  MOV32mr %stack.3, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.3)
496B	  renamable $esi = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
512B	  renamable $rdi = MOV64ri @.str.1
528B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
576B	  $al = MOV8ri 0
592B	  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
608B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
640B	  renamable $eax = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
656B	  MOV32mr %stack.2, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.2)
672B	  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
704B	  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
720B	  MOV32mr %stack.4, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
736B	  JMP_1 %bb.1

752B	bb.3 (%ir-block.22):
	; predecessors: %bb.1
	  successors: %bb.5, %bb.4

768B	  renamable $eax = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
784B	  renamable $rcx = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
800B	  renamable $rdx = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
816B	  CMP64rr killed renamable $rcx, killed renamable $rdx, implicit-def $eflags
832B	  JCC_1 %bb.5, 5, implicit killed $eflags

848B	bb.4.SP_return:
	; predecessors: %bb.3
	  liveins: $eax
880B	  RET64 implicit $eax

896B	bb.5.CallStackCheckFailBlk:
	; predecessors: %bb.3

912B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
928B	  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
944B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before Stack Slot Coloring (stack-slot-coloring) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

0B	bb.0 (%ir-block.0):
	  successors: %bb.1

16B	  renamable $rax = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
32B	  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, killed renamable $rax
48B	  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
64B	  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
80B	  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
96B	  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
112B	  renamable $rdi = MOV64ri @.str
128B	  renamable $rsi = LEA64r %stack.5, 1, $noreg, 0, $noreg
144B	  renamable $rdx = LEA64r %stack.2, 1, $noreg, 0, $noreg
160B	  renamable $rcx = LEA64r %stack.3, 1, $noreg, 0, $noreg
176B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
256B	  $al = MOV8ri 0
272B	  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
288B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

320B	bb.1 (%ir-block.8):
	; predecessors: %bb.0, %bb.2
	  successors: %bb.3, %bb.2

336B	  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
352B	  CMP32rm killed renamable $eax, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
368B	  JCC_1 %bb.3, 13, implicit killed $eflags

384B	bb.2 (%ir-block.12):
	; predecessors: %bb.1
	  successors: %bb.1

400B	  renamable $eax = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
416B	  MOV32mr %stack.6, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.6)
432B	  renamable $eax = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
464B	  renamable $eax = ADD32rm killed renamable $eax(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
480B	  MOV32mr %stack.3, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.3)
496B	  renamable $esi = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
512B	  renamable $rdi = MOV64ri @.str.1
528B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
576B	  $al = MOV8ri 0
592B	  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
608B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
640B	  renamable $eax = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
656B	  MOV32mr %stack.2, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.2)
672B	  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
704B	  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
720B	  MOV32mr %stack.4, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
736B	  JMP_1 %bb.1

752B	bb.3 (%ir-block.22):
	; predecessors: %bb.1
	  successors: %bb.5, %bb.4

768B	  renamable $eax = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
784B	  renamable $rcx = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
800B	  renamable $rdx = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
816B	  CMP64rr killed renamable $rcx, killed renamable $rdx, implicit-def $eflags
832B	  JCC_1 %bb.5, 5, implicit killed $eflags

848B	bb.4.SP_return:
	; predecessors: %bb.3
	  liveins: $eax
880B	  RET64 implicit $eax

896B	bb.5.CallStackCheckFailBlk:
	; predecessors: %bb.3

912B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
928B	  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
944B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After Stack Slot Coloring (stack-slot-coloring) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

0B	bb.0 (%ir-block.0):
	  successors: %bb.1

16B	  renamable $rax = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
32B	  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, killed renamable $rax
48B	  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
64B	  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
80B	  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
96B	  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
112B	  renamable $rdi = MOV64ri @.str
128B	  renamable $rsi = LEA64r %stack.5, 1, $noreg, 0, $noreg
144B	  renamable $rdx = LEA64r %stack.2, 1, $noreg, 0, $noreg
160B	  renamable $rcx = LEA64r %stack.3, 1, $noreg, 0, $noreg
176B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
256B	  $al = MOV8ri 0
272B	  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
288B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

320B	bb.1 (%ir-block.8):
	; predecessors: %bb.0, %bb.2
	  successors: %bb.3, %bb.2

336B	  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
352B	  CMP32rm killed renamable $eax, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
368B	  JCC_1 %bb.3, 13, implicit killed $eflags

384B	bb.2 (%ir-block.12):
	; predecessors: %bb.1
	  successors: %bb.1

400B	  renamable $eax = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
416B	  MOV32mr %stack.6, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.6)
432B	  renamable $eax = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
464B	  renamable $eax = ADD32rm killed renamable $eax(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
480B	  MOV32mr %stack.3, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.3)
496B	  renamable $esi = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
512B	  renamable $rdi = MOV64ri @.str.1
528B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
576B	  $al = MOV8ri 0
592B	  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
608B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
640B	  renamable $eax = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
656B	  MOV32mr %stack.2, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.2)
672B	  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
704B	  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
720B	  MOV32mr %stack.4, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
736B	  JMP_1 %bb.1

752B	bb.3 (%ir-block.22):
	; predecessors: %bb.1
	  successors: %bb.5, %bb.4

768B	  renamable $eax = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
784B	  renamable $rcx = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
800B	  renamable $rdx = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
816B	  CMP64rr killed renamable $rcx, killed renamable $rdx, implicit-def $eflags
832B	  JCC_1 %bb.5, 5, implicit killed $eflags

848B	bb.4.SP_return:
	; predecessors: %bb.3
	  liveins: $eax
880B	  RET64 implicit $eax

896B	bb.5.CallStackCheckFailBlk:
	; predecessors: %bb.3

912B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
928B	  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
944B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before Machine Copy Propagation Pass (machine-cp) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

0B	bb.0 (%ir-block.0):
	  successors: %bb.1

16B	  renamable $rax = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
32B	  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, killed renamable $rax
48B	  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
64B	  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
80B	  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
96B	  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
112B	  renamable $rdi = MOV64ri @.str
128B	  renamable $rsi = LEA64r %stack.5, 1, $noreg, 0, $noreg
144B	  renamable $rdx = LEA64r %stack.2, 1, $noreg, 0, $noreg
160B	  renamable $rcx = LEA64r %stack.3, 1, $noreg, 0, $noreg
176B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
256B	  $al = MOV8ri 0
272B	  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
288B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

320B	bb.1 (%ir-block.8):
	; predecessors: %bb.0, %bb.2
	  successors: %bb.3, %bb.2

336B	  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
352B	  CMP32rm killed renamable $eax, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
368B	  JCC_1 %bb.3, 13, implicit killed $eflags

384B	bb.2 (%ir-block.12):
	; predecessors: %bb.1
	  successors: %bb.1

400B	  renamable $eax = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
416B	  MOV32mr %stack.6, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.6)
432B	  renamable $eax = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
464B	  renamable $eax = ADD32rm killed renamable $eax(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
480B	  MOV32mr %stack.3, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.3)
496B	  renamable $esi = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
512B	  renamable $rdi = MOV64ri @.str.1
528B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
576B	  $al = MOV8ri 0
592B	  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
608B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
640B	  renamable $eax = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
656B	  MOV32mr %stack.2, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.2)
672B	  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
704B	  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
720B	  MOV32mr %stack.4, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
736B	  JMP_1 %bb.1

752B	bb.3 (%ir-block.22):
	; predecessors: %bb.1
	  successors: %bb.5, %bb.4

768B	  renamable $eax = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
784B	  renamable $rcx = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
800B	  renamable $rdx = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
816B	  CMP64rr killed renamable $rcx, killed renamable $rdx, implicit-def $eflags
832B	  JCC_1 %bb.5, 5, implicit killed $eflags

848B	bb.4.SP_return:
	; predecessors: %bb.3
	  liveins: $eax
880B	  RET64 implicit $eax

896B	bb.5.CallStackCheckFailBlk:
	; predecessors: %bb.3

912B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
928B	  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
944B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After Machine Copy Propagation Pass (machine-cp) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  renamable $rax = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, killed renamable $rax
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r %stack.5, 1, $noreg, 0, $noreg
  renamable $rdx = LEA64r %stack.2, 1, $noreg, 0, $noreg
  renamable $rcx = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit killed $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  renamable $eax = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.6)
  renamable $eax = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  renamable $eax = ADD32rm killed renamable $eax(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.3)
  renamable $esi = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  renamable $rdi = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  renamable $eax = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.2)
  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  renamable $eax = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  renamable $rcx = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  renamable $rdx = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr killed renamable $rcx, killed renamable $rdx, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit killed $eflags

bb.4.SP_return:
; predecessors: %bb.3
  liveins: $eax
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before Machine Loop Invariant Code Motion (machinelicm) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  renamable $rax = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, killed renamable $rax
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r %stack.5, 1, $noreg, 0, $noreg
  renamable $rdx = LEA64r %stack.2, 1, $noreg, 0, $noreg
  renamable $rcx = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit killed $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  renamable $eax = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.6)
  renamable $eax = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  renamable $eax = ADD32rm killed renamable $eax(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.3)
  renamable $esi = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  renamable $rdi = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  renamable $eax = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.2)
  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  renamable $eax = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  renamable $rcx = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  renamable $rdx = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr killed renamable $rcx, killed renamable $rdx, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit killed $eflags

bb.4.SP_return:
; predecessors: %bb.3
  liveins: $eax
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After Machine Loop Invariant Code Motion (machinelicm) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  renamable $rax = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, killed renamable $rax
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r %stack.5, 1, $noreg, 0, $noreg
  renamable $rdx = LEA64r %stack.2, 1, $noreg, 0, $noreg
  renamable $rcx = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit killed $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  renamable $eax = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.6)
  renamable $eax = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  renamable $eax = ADD32rm killed renamable $eax(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.3)
  renamable $esi = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  renamable $rdi = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  renamable $eax = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.2)
  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  renamable $eax = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  renamable $rcx = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  renamable $rdx = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr killed renamable $rcx, killed renamable $rdx, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit killed $eflags

bb.4.SP_return:
; predecessors: %bb.3
  liveins: $eax
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before X86 Lower Tile Copy (lowertilecopy) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  renamable $rax = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, killed renamable $rax
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r %stack.5, 1, $noreg, 0, $noreg
  renamable $rdx = LEA64r %stack.2, 1, $noreg, 0, $noreg
  renamable $rcx = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit killed $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  renamable $eax = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.6)
  renamable $eax = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  renamable $eax = ADD32rm killed renamable $eax(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.3)
  renamable $esi = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  renamable $rdi = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  renamable $eax = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.2)
  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  renamable $eax = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  renamable $rcx = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  renamable $rdx = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr killed renamable $rcx, killed renamable $rdx, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit killed $eflags

bb.4.SP_return:
; predecessors: %bb.3
  liveins: $eax
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After X86 Lower Tile Copy (lowertilecopy) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  renamable $rax = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, killed renamable $rax
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r %stack.5, 1, $noreg, 0, $noreg
  renamable $rdx = LEA64r %stack.2, 1, $noreg, 0, $noreg
  renamable $rcx = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit killed $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  renamable $eax = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.6)
  renamable $eax = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  renamable $eax = ADD32rm killed renamable $eax(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.3)
  renamable $esi = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  renamable $rdi = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  renamable $eax = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.2)
  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  renamable $eax = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  renamable $rcx = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  renamable $rdx = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr killed renamable $rcx, killed renamable $rdx, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit killed $eflags

bb.4.SP_return:
; predecessors: %bb.3
  liveins: $eax
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before X86 FP Stackifier (x86-codegen) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  renamable $rax = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, killed renamable $rax
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r %stack.5, 1, $noreg, 0, $noreg
  renamable $rdx = LEA64r %stack.2, 1, $noreg, 0, $noreg
  renamable $rcx = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit killed $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  renamable $eax = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.6)
  renamable $eax = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  renamable $eax = ADD32rm killed renamable $eax(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.3)
  renamable $esi = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  renamable $rdi = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  renamable $eax = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.2)
  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  renamable $eax = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  renamable $rcx = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  renamable $rdx = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr killed renamable $rcx, killed renamable $rdx, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit killed $eflags

bb.4.SP_return:
; predecessors: %bb.3
  liveins: $eax
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After X86 FP Stackifier (x86-codegen) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  renamable $rax = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, killed renamable $rax
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r %stack.5, 1, $noreg, 0, $noreg
  renamable $rdx = LEA64r %stack.2, 1, $noreg, 0, $noreg
  renamable $rcx = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit killed $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  renamable $eax = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.6)
  renamable $eax = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  renamable $eax = ADD32rm killed renamable $eax(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.3)
  renamable $esi = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  renamable $rdi = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  renamable $eax = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.2)
  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  renamable $eax = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  renamable $rcx = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  renamable $rdx = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr killed renamable $rcx, killed renamable $rdx, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit killed $eflags

bb.4.SP_return:
; predecessors: %bb.3
  liveins: $eax
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before X86 Load Value Injection (LVI) Load Hardening (x86-lvi-load) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  renamable $rax = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, killed renamable $rax
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r %stack.5, 1, $noreg, 0, $noreg
  renamable $rdx = LEA64r %stack.2, 1, $noreg, 0, $noreg
  renamable $rcx = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit killed $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  renamable $eax = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.6)
  renamable $eax = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  renamable $eax = ADD32rm killed renamable $eax(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.3)
  renamable $esi = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  renamable $rdi = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  renamable $eax = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.2)
  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  renamable $eax = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  renamable $rcx = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  renamable $rdx = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr killed renamable $rcx, killed renamable $rdx, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit killed $eflags

bb.4.SP_return:
; predecessors: %bb.3
  liveins: $eax
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After X86 Load Value Injection (LVI) Load Hardening (x86-lvi-load) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  renamable $rax = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, killed renamable $rax
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r %stack.5, 1, $noreg, 0, $noreg
  renamable $rdx = LEA64r %stack.2, 1, $noreg, 0, $noreg
  renamable $rcx = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit killed $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  renamable $eax = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.6)
  renamable $eax = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  renamable $eax = ADD32rm killed renamable $eax(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.3)
  renamable $esi = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  renamable $rdi = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  renamable $eax = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.2)
  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  renamable $eax = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  renamable $rcx = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  renamable $rdx = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr killed renamable $rcx, killed renamable $rdx, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit killed $eflags

bb.4.SP_return:
; predecessors: %bb.3
  liveins: $eax
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before Remove Redundant DEBUG_VALUE analysis (removeredundantdebugvalues) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  renamable $rax = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, killed renamable $rax
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r %stack.5, 1, $noreg, 0, $noreg
  renamable $rdx = LEA64r %stack.2, 1, $noreg, 0, $noreg
  renamable $rcx = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit killed $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  renamable $eax = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.6)
  renamable $eax = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  renamable $eax = ADD32rm killed renamable $eax(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.3)
  renamable $esi = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  renamable $rdi = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  renamable $eax = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.2)
  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  renamable $eax = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  renamable $rcx = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  renamable $rdx = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr killed renamable $rcx, killed renamable $rdx, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit killed $eflags

bb.4.SP_return:
; predecessors: %bb.3
  liveins: $eax
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After Remove Redundant DEBUG_VALUE analysis (removeredundantdebugvalues) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  renamable $rax = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, killed renamable $rax
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r %stack.5, 1, $noreg, 0, $noreg
  renamable $rdx = LEA64r %stack.2, 1, $noreg, 0, $noreg
  renamable $rcx = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit killed $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  renamable $eax = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.6)
  renamable $eax = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  renamable $eax = ADD32rm killed renamable $eax(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.3)
  renamable $esi = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  renamable $rdi = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  renamable $eax = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.2)
  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  renamable $eax = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  renamable $rcx = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  renamable $rdx = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr killed renamable $rcx, killed renamable $rdx, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit killed $eflags

bb.4.SP_return:
; predecessors: %bb.3
  liveins: $eax
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before Fixup Statepoint Caller Saved (fixup-statepoint-caller-saved) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  renamable $rax = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, killed renamable $rax
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r %stack.5, 1, $noreg, 0, $noreg
  renamable $rdx = LEA64r %stack.2, 1, $noreg, 0, $noreg
  renamable $rcx = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit killed $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  renamable $eax = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.6)
  renamable $eax = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  renamable $eax = ADD32rm killed renamable $eax(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.3)
  renamable $esi = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  renamable $rdi = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  renamable $eax = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.2)
  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  renamable $eax = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  renamable $rcx = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  renamable $rdx = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr killed renamable $rcx, killed renamable $rdx, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit killed $eflags

bb.4.SP_return:
; predecessors: %bb.3
  liveins: $eax
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After Fixup Statepoint Caller Saved (fixup-statepoint-caller-saved) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  renamable $rax = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, killed renamable $rax
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r %stack.5, 1, $noreg, 0, $noreg
  renamable $rdx = LEA64r %stack.2, 1, $noreg, 0, $noreg
  renamable $rcx = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit killed $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  renamable $eax = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.6)
  renamable $eax = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  renamable $eax = ADD32rm killed renamable $eax(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.3)
  renamable $esi = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  renamable $rdi = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  renamable $eax = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.2)
  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  renamable $eax = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  renamable $rcx = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  renamable $rdx = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr killed renamable $rcx, killed renamable $rdx, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit killed $eflags

bb.4.SP_return:
; predecessors: %bb.3
  liveins: $eax
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before PostRA Machine Sink (postra-machine-sink) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  renamable $rax = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, killed renamable $rax
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r %stack.5, 1, $noreg, 0, $noreg
  renamable $rdx = LEA64r %stack.2, 1, $noreg, 0, $noreg
  renamable $rcx = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit killed $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  renamable $eax = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.6)
  renamable $eax = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  renamable $eax = ADD32rm killed renamable $eax(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.3)
  renamable $esi = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  renamable $rdi = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  renamable $eax = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.2)
  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  renamable $eax = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  renamable $rcx = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  renamable $rdx = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr killed renamable $rcx, killed renamable $rdx, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit killed $eflags

bb.4.SP_return:
; predecessors: %bb.3
  liveins: $eax
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After PostRA Machine Sink (postra-machine-sink) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  renamable $rax = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, killed renamable $rax
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r %stack.5, 1, $noreg, 0, $noreg
  renamable $rdx = LEA64r %stack.2, 1, $noreg, 0, $noreg
  renamable $rcx = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit killed $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  renamable $eax = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.6)
  renamable $eax = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  renamable $eax = ADD32rm killed renamable $eax(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.3)
  renamable $esi = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  renamable $rdi = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  renamable $eax = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.2)
  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  renamable $eax = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  renamable $rcx = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  renamable $rdx = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr killed renamable $rcx, killed renamable $rdx, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit killed $eflags

bb.4.SP_return:
; predecessors: %bb.3
  liveins: $eax
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before Shrink Wrapping analysis (shrink-wrap) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  renamable $rax = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, killed renamable $rax
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r %stack.5, 1, $noreg, 0, $noreg
  renamable $rdx = LEA64r %stack.2, 1, $noreg, 0, $noreg
  renamable $rcx = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit killed $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  renamable $eax = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.6)
  renamable $eax = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  renamable $eax = ADD32rm killed renamable $eax(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.3)
  renamable $esi = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  renamable $rdi = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  renamable $eax = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.2)
  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  renamable $eax = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  renamable $rcx = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  renamable $rdx = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr killed renamable $rcx, killed renamable $rdx, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit killed $eflags

bb.4.SP_return:
; predecessors: %bb.3
  liveins: $eax
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After Shrink Wrapping analysis (shrink-wrap) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  renamable $rax = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, killed renamable $rax
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r %stack.5, 1, $noreg, 0, $noreg
  renamable $rdx = LEA64r %stack.2, 1, $noreg, 0, $noreg
  renamable $rcx = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit killed $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  renamable $eax = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.6)
  renamable $eax = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  renamable $eax = ADD32rm killed renamable $eax(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.3)
  renamable $esi = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  renamable $rdi = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  renamable $eax = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.2)
  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  renamable $eax = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  renamable $rcx = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  renamable $rdx = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr killed renamable $rcx, killed renamable $rdx, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit killed $eflags

bb.4.SP_return:
; predecessors: %bb.3
  liveins: $eax
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before Prologue/Epilogue Insertion & Frame Finalization (prologepilog) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#0: size=8, align=8, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=4, align=4, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
  fi#5: size=4, align=4, at location [SP+8]
  fi#6: size=4, align=4, at location [SP+8]

bb.0 (%ir-block.0):
  successors: %bb.1

  renamable $rax = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg, killed renamable $rax
  MOV32mi %stack.1, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi %stack.2, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.4)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r %stack.5, 1, $noreg, 0, $noreg
  renamable $rdx = LEA64r %stack.2, 1, $noreg, 0, $noreg
  renamable $rcx = LEA64r %stack.3, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, %stack.5, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit killed $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  renamable $eax = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  MOV32mr %stack.6, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.6)
  renamable $eax = MOV32rm %stack.2, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  renamable $eax = ADD32rm killed renamable $eax(tied-def 0), %stack.3, 1, $noreg, 0, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.3)
  renamable $esi = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.3)
  renamable $rdi = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  renamable $eax = MOV32rm %stack.6, 1, $noreg, 0, $noreg :: (load (s32) from %ir.6)
  MOV32mr %stack.2, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.2)
  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  renamable $eax = MOV32rm %stack.1, 1, $noreg, 0, $noreg :: (dereferenceable load (s32) from %ir.1)
  renamable $rcx = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  renamable $rdx = MOV64rm %stack.0.StackGuardSlot, 1, $noreg, 0, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr killed renamable $rcx, killed renamable $rdx, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit killed $eflags

bb.4.SP_return:
; predecessors: %bb.3
  liveins: $eax
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After Prologue/Epilogue Insertion & Frame Finalization (prologepilog) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=8, align=8, at location [SP-16]
  fi#1: size=4, align=4, at location [SP-40]
  fi#2: size=4, align=4, at location [SP-20]
  fi#3: size=4, align=4, at location [SP-24]
  fi#4: size=4, align=4, at location [SP-32]
  fi#5: size=4, align=4, at location [SP-28]
  fi#6: size=4, align=4, at location [SP-36]

bb.0 (%ir-block.0):
  successors: %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  renamable $rax = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr $rbp, 1, $noreg, -8, $noreg, killed renamable $rax
  MOV32mi $rbp, 1, $noreg, -32, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi $rbp, 1, $noreg, -12, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi $rbp, 1, $noreg, -16, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi $rbp, 1, $noreg, -24, $noreg, 1 :: (store (s32) into %ir.4)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -20, $noreg
  renamable $rdx = LEA64r $rbp, 1, $noreg, -12, $noreg
  renamable $rcx = LEA64r $rbp, 1, $noreg, -16, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -20, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit killed $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -28, $noreg, killed renamable $eax :: (store (s32) into %ir.6)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $eax = ADD32rm killed renamable $eax(tied-def 0), $rbp, 1, $noreg, -16, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -16, $noreg, killed renamable $eax :: (store (s32) into %ir.3)
  renamable $esi = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  renamable $rdi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.6)
  MOV32mr $rbp, 1, $noreg, -12, $noreg, killed renamable $eax :: (store (s32) into %ir.2)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -24, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  renamable $eax = MOV32rm $rbp, 1, $noreg, -32, $noreg :: (dereferenceable load (s32) from %ir.1)
  renamable $rcx = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  renamable $rdx = MOV64rm $rbp, 1, $noreg, -8, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr killed renamable $rcx, killed renamable $rdx, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit killed $eflags

bb.4.SP_return:
; predecessors: %bb.3
  liveins: $eax
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before Control Flow Optimizer (branch-folder) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=8, align=8, at location [SP-16]
  fi#1: size=4, align=4, at location [SP-40]
  fi#2: size=4, align=4, at location [SP-20]
  fi#3: size=4, align=4, at location [SP-24]
  fi#4: size=4, align=4, at location [SP-32]
  fi#5: size=4, align=4, at location [SP-28]
  fi#6: size=4, align=4, at location [SP-36]

bb.0 (%ir-block.0):
  successors: %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  renamable $rax = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr $rbp, 1, $noreg, -8, $noreg, killed renamable $rax
  MOV32mi $rbp, 1, $noreg, -32, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi $rbp, 1, $noreg, -12, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi $rbp, 1, $noreg, -16, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi $rbp, 1, $noreg, -24, $noreg, 1 :: (store (s32) into %ir.4)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -20, $noreg
  renamable $rdx = LEA64r $rbp, 1, $noreg, -12, $noreg
  renamable $rcx = LEA64r $rbp, 1, $noreg, -16, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -20, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit killed $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -28, $noreg, killed renamable $eax :: (store (s32) into %ir.6)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $eax = ADD32rm killed renamable $eax(tied-def 0), $rbp, 1, $noreg, -16, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -16, $noreg, killed renamable $eax :: (store (s32) into %ir.3)
  renamable $esi = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  renamable $rdi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.6)
  MOV32mr $rbp, 1, $noreg, -12, $noreg, killed renamable $eax :: (store (s32) into %ir.2)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -24, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  renamable $eax = MOV32rm $rbp, 1, $noreg, -32, $noreg :: (dereferenceable load (s32) from %ir.1)
  renamable $rcx = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  renamable $rdx = MOV64rm $rbp, 1, $noreg, -8, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr killed renamable $rcx, killed renamable $rdx, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit killed $eflags

bb.4.SP_return:
; predecessors: %bb.3
  liveins: $eax
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After Control Flow Optimizer (branch-folder) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=8, align=8, at location [SP-16]
  fi#1: size=4, align=4, at location [SP-40]
  fi#2: size=4, align=4, at location [SP-20]
  fi#3: size=4, align=4, at location [SP-24]
  fi#4: size=4, align=4, at location [SP-32]
  fi#5: size=4, align=4, at location [SP-28]
  fi#6: size=4, align=4, at location [SP-36]

bb.0 (%ir-block.0):
  successors: %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  renamable $rax = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr $rbp, 1, $noreg, -8, $noreg, killed renamable $rax
  MOV32mi $rbp, 1, $noreg, -32, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi $rbp, 1, $noreg, -12, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi $rbp, 1, $noreg, -16, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi $rbp, 1, $noreg, -24, $noreg, 1 :: (store (s32) into %ir.4)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -20, $noreg
  renamable $rdx = LEA64r $rbp, 1, $noreg, -12, $noreg
  renamable $rcx = LEA64r $rbp, 1, $noreg, -16, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -20, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit killed $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -28, $noreg, killed renamable $eax :: (store (s32) into %ir.6)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $eax = ADD32rm killed renamable $eax(tied-def 0), $rbp, 1, $noreg, -16, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -16, $noreg, killed renamable $eax :: (store (s32) into %ir.3)
  renamable $esi = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  renamable $rdi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.6)
  MOV32mr $rbp, 1, $noreg, -12, $noreg, killed renamable $eax :: (store (s32) into %ir.2)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -24, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  renamable $eax = MOV32rm $rbp, 1, $noreg, -32, $noreg :: (dereferenceable load (s32) from %ir.1)
  renamable $rcx = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  renamable $rdx = MOV64rm $rbp, 1, $noreg, -8, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr killed renamable $rcx, killed renamable $rdx, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit killed $eflags

bb.4.SP_return:
; predecessors: %bb.3
  liveins: $eax
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before Tail Duplication (tailduplication) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=8, align=8, at location [SP-16]
  fi#1: size=4, align=4, at location [SP-40]
  fi#2: size=4, align=4, at location [SP-20]
  fi#3: size=4, align=4, at location [SP-24]
  fi#4: size=4, align=4, at location [SP-32]
  fi#5: size=4, align=4, at location [SP-28]
  fi#6: size=4, align=4, at location [SP-36]

bb.0 (%ir-block.0):
  successors: %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  renamable $rax = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr $rbp, 1, $noreg, -8, $noreg, killed renamable $rax
  MOV32mi $rbp, 1, $noreg, -32, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi $rbp, 1, $noreg, -12, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi $rbp, 1, $noreg, -16, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi $rbp, 1, $noreg, -24, $noreg, 1 :: (store (s32) into %ir.4)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -20, $noreg
  renamable $rdx = LEA64r $rbp, 1, $noreg, -12, $noreg
  renamable $rcx = LEA64r $rbp, 1, $noreg, -16, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -20, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit killed $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -28, $noreg, killed renamable $eax :: (store (s32) into %ir.6)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $eax = ADD32rm killed renamable $eax(tied-def 0), $rbp, 1, $noreg, -16, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -16, $noreg, killed renamable $eax :: (store (s32) into %ir.3)
  renamable $esi = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  renamable $rdi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.6)
  MOV32mr $rbp, 1, $noreg, -12, $noreg, killed renamable $eax :: (store (s32) into %ir.2)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -24, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  renamable $eax = MOV32rm $rbp, 1, $noreg, -32, $noreg :: (dereferenceable load (s32) from %ir.1)
  renamable $rcx = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  renamable $rdx = MOV64rm $rbp, 1, $noreg, -8, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr killed renamable $rcx, killed renamable $rdx, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit killed $eflags

bb.4.SP_return:
; predecessors: %bb.3
  liveins: $eax
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After Tail Duplication (tailduplication) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=8, align=8, at location [SP-16]
  fi#1: size=4, align=4, at location [SP-40]
  fi#2: size=4, align=4, at location [SP-20]
  fi#3: size=4, align=4, at location [SP-24]
  fi#4: size=4, align=4, at location [SP-32]
  fi#5: size=4, align=4, at location [SP-28]
  fi#6: size=4, align=4, at location [SP-36]

bb.0 (%ir-block.0):
  successors: %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  renamable $rax = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr $rbp, 1, $noreg, -8, $noreg, killed renamable $rax
  MOV32mi $rbp, 1, $noreg, -32, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi $rbp, 1, $noreg, -12, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi $rbp, 1, $noreg, -16, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi $rbp, 1, $noreg, -24, $noreg, 1 :: (store (s32) into %ir.4)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -20, $noreg
  renamable $rdx = LEA64r $rbp, 1, $noreg, -12, $noreg
  renamable $rcx = LEA64r $rbp, 1, $noreg, -16, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -20, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit killed $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -28, $noreg, killed renamable $eax :: (store (s32) into %ir.6)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $eax = ADD32rm killed renamable $eax(tied-def 0), $rbp, 1, $noreg, -16, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -16, $noreg, killed renamable $eax :: (store (s32) into %ir.3)
  renamable $esi = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  renamable $rdi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.6)
  MOV32mr $rbp, 1, $noreg, -12, $noreg, killed renamable $eax :: (store (s32) into %ir.2)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -24, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  renamable $eax = MOV32rm $rbp, 1, $noreg, -32, $noreg :: (dereferenceable load (s32) from %ir.1)
  renamable $rcx = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  renamable $rdx = MOV64rm $rbp, 1, $noreg, -8, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr killed renamable $rcx, killed renamable $rdx, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit killed $eflags

bb.4.SP_return:
; predecessors: %bb.3
  liveins: $eax
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before Machine Copy Propagation Pass (machine-cp) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=8, align=8, at location [SP-16]
  fi#1: size=4, align=4, at location [SP-40]
  fi#2: size=4, align=4, at location [SP-20]
  fi#3: size=4, align=4, at location [SP-24]
  fi#4: size=4, align=4, at location [SP-32]
  fi#5: size=4, align=4, at location [SP-28]
  fi#6: size=4, align=4, at location [SP-36]

bb.0 (%ir-block.0):
  successors: %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  renamable $rax = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr $rbp, 1, $noreg, -8, $noreg, killed renamable $rax
  MOV32mi $rbp, 1, $noreg, -32, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi $rbp, 1, $noreg, -12, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi $rbp, 1, $noreg, -16, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi $rbp, 1, $noreg, -24, $noreg, 1 :: (store (s32) into %ir.4)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -20, $noreg
  renamable $rdx = LEA64r $rbp, 1, $noreg, -12, $noreg
  renamable $rcx = LEA64r $rbp, 1, $noreg, -16, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -20, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit killed $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -28, $noreg, killed renamable $eax :: (store (s32) into %ir.6)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $eax = ADD32rm killed renamable $eax(tied-def 0), $rbp, 1, $noreg, -16, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -16, $noreg, killed renamable $eax :: (store (s32) into %ir.3)
  renamable $esi = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  renamable $rdi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.6)
  MOV32mr $rbp, 1, $noreg, -12, $noreg, killed renamable $eax :: (store (s32) into %ir.2)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -24, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  renamable $eax = MOV32rm $rbp, 1, $noreg, -32, $noreg :: (dereferenceable load (s32) from %ir.1)
  renamable $rcx = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  renamable $rdx = MOV64rm $rbp, 1, $noreg, -8, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr killed renamable $rcx, killed renamable $rdx, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit killed $eflags

bb.4.SP_return:
; predecessors: %bb.3
  liveins: $eax
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After Machine Copy Propagation Pass (machine-cp) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=8, align=8, at location [SP-16]
  fi#1: size=4, align=4, at location [SP-40]
  fi#2: size=4, align=4, at location [SP-20]
  fi#3: size=4, align=4, at location [SP-24]
  fi#4: size=4, align=4, at location [SP-32]
  fi#5: size=4, align=4, at location [SP-28]
  fi#6: size=4, align=4, at location [SP-36]

bb.0 (%ir-block.0):
  successors: %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  renamable $rax = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr $rbp, 1, $noreg, -8, $noreg, killed renamable $rax
  MOV32mi $rbp, 1, $noreg, -32, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi $rbp, 1, $noreg, -12, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi $rbp, 1, $noreg, -16, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi $rbp, 1, $noreg, -24, $noreg, 1 :: (store (s32) into %ir.4)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -20, $noreg
  renamable $rdx = LEA64r $rbp, 1, $noreg, -12, $noreg
  renamable $rcx = LEA64r $rbp, 1, $noreg, -16, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -20, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit killed $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -28, $noreg, killed renamable $eax :: (store (s32) into %ir.6)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $eax = ADD32rm killed renamable $eax(tied-def 0), $rbp, 1, $noreg, -16, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -16, $noreg, killed renamable $eax :: (store (s32) into %ir.3)
  renamable $esi = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  renamable $rdi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.6)
  MOV32mr $rbp, 1, $noreg, -12, $noreg, killed renamable $eax :: (store (s32) into %ir.2)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -24, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  renamable $eax = MOV32rm $rbp, 1, $noreg, -32, $noreg :: (dereferenceable load (s32) from %ir.1)
  renamable $rcx = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  renamable $rdx = MOV64rm $rbp, 1, $noreg, -8, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr killed renamable $rcx, killed renamable $rdx, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit killed $eflags

bb.4.SP_return:
; predecessors: %bb.3
  liveins: $eax
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before Post-RA pseudo instruction expansion pass (postrapseudos) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=8, align=8, at location [SP-16]
  fi#1: size=4, align=4, at location [SP-40]
  fi#2: size=4, align=4, at location [SP-20]
  fi#3: size=4, align=4, at location [SP-24]
  fi#4: size=4, align=4, at location [SP-32]
  fi#5: size=4, align=4, at location [SP-28]
  fi#6: size=4, align=4, at location [SP-36]

bb.0 (%ir-block.0):
  successors: %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  renamable $rax = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr $rbp, 1, $noreg, -8, $noreg, killed renamable $rax
  MOV32mi $rbp, 1, $noreg, -32, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi $rbp, 1, $noreg, -12, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi $rbp, 1, $noreg, -16, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi $rbp, 1, $noreg, -24, $noreg, 1 :: (store (s32) into %ir.4)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -20, $noreg
  renamable $rdx = LEA64r $rbp, 1, $noreg, -12, $noreg
  renamable $rcx = LEA64r $rbp, 1, $noreg, -16, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -20, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit killed $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -28, $noreg, killed renamable $eax :: (store (s32) into %ir.6)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $eax = ADD32rm killed renamable $eax(tied-def 0), $rbp, 1, $noreg, -16, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -16, $noreg, killed renamable $eax :: (store (s32) into %ir.3)
  renamable $esi = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  renamable $rdi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.6)
  MOV32mr $rbp, 1, $noreg, -12, $noreg, killed renamable $eax :: (store (s32) into %ir.2)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -24, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  renamable $eax = MOV32rm $rbp, 1, $noreg, -32, $noreg :: (dereferenceable load (s32) from %ir.1)
  renamable $rcx = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  renamable $rdx = MOV64rm $rbp, 1, $noreg, -8, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr killed renamable $rcx, killed renamable $rdx, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit killed $eflags

bb.4.SP_return:
; predecessors: %bb.3
  liveins: $eax
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After Post-RA pseudo instruction expansion pass (postrapseudos) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=8, align=8, at location [SP-16]
  fi#1: size=4, align=4, at location [SP-40]
  fi#2: size=4, align=4, at location [SP-20]
  fi#3: size=4, align=4, at location [SP-24]
  fi#4: size=4, align=4, at location [SP-32]
  fi#5: size=4, align=4, at location [SP-28]
  fi#6: size=4, align=4, at location [SP-36]

bb.0 (%ir-block.0):
  successors: %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  renamable $rax = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr $rbp, 1, $noreg, -8, $noreg, killed renamable $rax
  MOV32mi $rbp, 1, $noreg, -32, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi $rbp, 1, $noreg, -12, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi $rbp, 1, $noreg, -16, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi $rbp, 1, $noreg, -24, $noreg, 1 :: (store (s32) into %ir.4)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -20, $noreg
  renamable $rdx = LEA64r $rbp, 1, $noreg, -12, $noreg
  renamable $rcx = LEA64r $rbp, 1, $noreg, -16, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -20, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit killed $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -28, $noreg, killed renamable $eax :: (store (s32) into %ir.6)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $eax = ADD32rm killed renamable $eax(tied-def 0), $rbp, 1, $noreg, -16, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -16, $noreg, killed renamable $eax :: (store (s32) into %ir.3)
  renamable $esi = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  renamable $rdi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.6)
  MOV32mr $rbp, 1, $noreg, -12, $noreg, killed renamable $eax :: (store (s32) into %ir.2)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -24, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  renamable $eax = MOV32rm $rbp, 1, $noreg, -32, $noreg :: (dereferenceable load (s32) from %ir.1)
  renamable $rcx = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  renamable $rdx = MOV64rm $rbp, 1, $noreg, -8, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr killed renamable $rcx, killed renamable $rdx, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit killed $eflags

bb.4.SP_return:
; predecessors: %bb.3
  liveins: $eax
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before X86 pseudo instruction expansion pass (x86-pseudo) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=8, align=8, at location [SP-16]
  fi#1: size=4, align=4, at location [SP-40]
  fi#2: size=4, align=4, at location [SP-20]
  fi#3: size=4, align=4, at location [SP-24]
  fi#4: size=4, align=4, at location [SP-32]
  fi#5: size=4, align=4, at location [SP-28]
  fi#6: size=4, align=4, at location [SP-36]

bb.0 (%ir-block.0):
  successors: %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  renamable $rax = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr $rbp, 1, $noreg, -8, $noreg, killed renamable $rax
  MOV32mi $rbp, 1, $noreg, -32, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi $rbp, 1, $noreg, -12, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi $rbp, 1, $noreg, -16, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi $rbp, 1, $noreg, -24, $noreg, 1 :: (store (s32) into %ir.4)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -20, $noreg
  renamable $rdx = LEA64r $rbp, 1, $noreg, -12, $noreg
  renamable $rcx = LEA64r $rbp, 1, $noreg, -16, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -20, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit killed $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -28, $noreg, killed renamable $eax :: (store (s32) into %ir.6)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $eax = ADD32rm killed renamable $eax(tied-def 0), $rbp, 1, $noreg, -16, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -16, $noreg, killed renamable $eax :: (store (s32) into %ir.3)
  renamable $esi = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  renamable $rdi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.6)
  MOV32mr $rbp, 1, $noreg, -12, $noreg, killed renamable $eax :: (store (s32) into %ir.2)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -24, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  renamable $eax = MOV32rm $rbp, 1, $noreg, -32, $noreg :: (dereferenceable load (s32) from %ir.1)
  renamable $rcx = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  renamable $rdx = MOV64rm $rbp, 1, $noreg, -8, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr killed renamable $rcx, killed renamable $rdx, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit killed $eflags

bb.4.SP_return:
; predecessors: %bb.3
  liveins: $eax
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After X86 pseudo instruction expansion pass (x86-pseudo) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=8, align=8, at location [SP-16]
  fi#1: size=4, align=4, at location [SP-40]
  fi#2: size=4, align=4, at location [SP-20]
  fi#3: size=4, align=4, at location [SP-24]
  fi#4: size=4, align=4, at location [SP-32]
  fi#5: size=4, align=4, at location [SP-28]
  fi#6: size=4, align=4, at location [SP-36]

bb.0 (%ir-block.0):
  successors: %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  renamable $rax = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr $rbp, 1, $noreg, -8, $noreg, killed renamable $rax
  MOV32mi $rbp, 1, $noreg, -32, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi $rbp, 1, $noreg, -12, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi $rbp, 1, $noreg, -16, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi $rbp, 1, $noreg, -24, $noreg, 1 :: (store (s32) into %ir.4)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -20, $noreg
  renamable $rdx = LEA64r $rbp, 1, $noreg, -12, $noreg
  renamable $rcx = LEA64r $rbp, 1, $noreg, -16, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -20, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit killed $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -28, $noreg, killed renamable $eax :: (store (s32) into %ir.6)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $eax = ADD32rm killed renamable $eax(tied-def 0), $rbp, 1, $noreg, -16, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -16, $noreg, killed renamable $eax :: (store (s32) into %ir.3)
  renamable $esi = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  renamable $rdi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.6)
  MOV32mr $rbp, 1, $noreg, -12, $noreg, killed renamable $eax :: (store (s32) into %ir.2)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -24, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  renamable $eax = MOV32rm $rbp, 1, $noreg, -32, $noreg :: (dereferenceable load (s32) from %ir.1)
  renamable $rcx = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  renamable $rdx = MOV64rm $rbp, 1, $noreg, -8, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr killed renamable $rcx, killed renamable $rdx, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit killed $eflags

bb.4.SP_return:
; predecessors: %bb.3
  liveins: $eax
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before Post RA top-down list latency scheduler (post-RA-sched) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=8, align=8, at location [SP-16]
  fi#1: size=4, align=4, at location [SP-40]
  fi#2: size=4, align=4, at location [SP-20]
  fi#3: size=4, align=4, at location [SP-24]
  fi#4: size=4, align=4, at location [SP-32]
  fi#5: size=4, align=4, at location [SP-28]
  fi#6: size=4, align=4, at location [SP-36]

bb.0 (%ir-block.0):
  successors: %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  renamable $rax = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr $rbp, 1, $noreg, -8, $noreg, killed renamable $rax
  MOV32mi $rbp, 1, $noreg, -32, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi $rbp, 1, $noreg, -12, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi $rbp, 1, $noreg, -16, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi $rbp, 1, $noreg, -24, $noreg, 1 :: (store (s32) into %ir.4)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -20, $noreg
  renamable $rdx = LEA64r $rbp, 1, $noreg, -12, $noreg
  renamable $rcx = LEA64r $rbp, 1, $noreg, -16, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -20, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit killed $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -28, $noreg, killed renamable $eax :: (store (s32) into %ir.6)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $eax = ADD32rm killed renamable $eax(tied-def 0), $rbp, 1, $noreg, -16, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -16, $noreg, killed renamable $eax :: (store (s32) into %ir.3)
  renamable $esi = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  renamable $rdi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.6)
  MOV32mr $rbp, 1, $noreg, -12, $noreg, killed renamable $eax :: (store (s32) into %ir.2)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -24, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  renamable $eax = MOV32rm $rbp, 1, $noreg, -32, $noreg :: (dereferenceable load (s32) from %ir.1)
  renamable $rcx = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  renamable $rdx = MOV64rm $rbp, 1, $noreg, -8, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr killed renamable $rcx, killed renamable $rdx, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit killed $eflags

bb.4.SP_return:
; predecessors: %bb.3
  liveins: $eax
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After Post RA top-down list latency scheduler (post-RA-sched) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=8, align=8, at location [SP-16]
  fi#1: size=4, align=4, at location [SP-40]
  fi#2: size=4, align=4, at location [SP-20]
  fi#3: size=4, align=4, at location [SP-24]
  fi#4: size=4, align=4, at location [SP-32]
  fi#5: size=4, align=4, at location [SP-28]
  fi#6: size=4, align=4, at location [SP-36]

bb.0 (%ir-block.0):
  successors: %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  renamable $rax = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr $rbp, 1, $noreg, -8, $noreg, killed renamable $rax
  MOV32mi $rbp, 1, $noreg, -32, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi $rbp, 1, $noreg, -12, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi $rbp, 1, $noreg, -16, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi $rbp, 1, $noreg, -24, $noreg, 1 :: (store (s32) into %ir.4)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -20, $noreg
  renamable $rdx = LEA64r $rbp, 1, $noreg, -12, $noreg
  renamable $rcx = LEA64r $rbp, 1, $noreg, -16, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -20, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit killed $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -28, $noreg, killed renamable $eax :: (store (s32) into %ir.6)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $eax = ADD32rm killed renamable $eax(tied-def 0), $rbp, 1, $noreg, -16, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -16, $noreg, killed renamable $eax :: (store (s32) into %ir.3)
  renamable $esi = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  renamable $rdi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.6)
  MOV32mr $rbp, 1, $noreg, -12, $noreg, killed renamable $eax :: (store (s32) into %ir.2)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -24, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  renamable $eax = MOV32rm $rbp, 1, $noreg, -32, $noreg :: (dereferenceable load (s32) from %ir.1)
  renamable $rcx = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  renamable $rdx = MOV64rm $rbp, 1, $noreg, -8, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr killed renamable $rcx, killed renamable $rdx, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit killed $eflags

bb.4.SP_return:
; predecessors: %bb.3
  liveins: $eax
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before Analyze Machine Code For Garbage Collection (gc-analysis) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=8, align=8, at location [SP-16]
  fi#1: size=4, align=4, at location [SP-40]
  fi#2: size=4, align=4, at location [SP-20]
  fi#3: size=4, align=4, at location [SP-24]
  fi#4: size=4, align=4, at location [SP-32]
  fi#5: size=4, align=4, at location [SP-28]
  fi#6: size=4, align=4, at location [SP-36]

bb.0 (%ir-block.0):
  successors: %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  renamable $rax = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr $rbp, 1, $noreg, -8, $noreg, killed renamable $rax
  MOV32mi $rbp, 1, $noreg, -32, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi $rbp, 1, $noreg, -12, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi $rbp, 1, $noreg, -16, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi $rbp, 1, $noreg, -24, $noreg, 1 :: (store (s32) into %ir.4)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -20, $noreg
  renamable $rdx = LEA64r $rbp, 1, $noreg, -12, $noreg
  renamable $rcx = LEA64r $rbp, 1, $noreg, -16, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -20, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit killed $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -28, $noreg, killed renamable $eax :: (store (s32) into %ir.6)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $eax = ADD32rm killed renamable $eax(tied-def 0), $rbp, 1, $noreg, -16, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -16, $noreg, killed renamable $eax :: (store (s32) into %ir.3)
  renamable $esi = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  renamable $rdi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.6)
  MOV32mr $rbp, 1, $noreg, -12, $noreg, killed renamable $eax :: (store (s32) into %ir.2)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -24, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  renamable $eax = MOV32rm $rbp, 1, $noreg, -32, $noreg :: (dereferenceable load (s32) from %ir.1)
  renamable $rcx = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  renamable $rdx = MOV64rm $rbp, 1, $noreg, -8, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr killed renamable $rcx, killed renamable $rdx, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit killed $eflags

bb.4.SP_return:
; predecessors: %bb.3
  liveins: $eax
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After Analyze Machine Code For Garbage Collection (gc-analysis) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=8, align=8, at location [SP-16]
  fi#1: size=4, align=4, at location [SP-40]
  fi#2: size=4, align=4, at location [SP-20]
  fi#3: size=4, align=4, at location [SP-24]
  fi#4: size=4, align=4, at location [SP-32]
  fi#5: size=4, align=4, at location [SP-28]
  fi#6: size=4, align=4, at location [SP-36]

bb.0 (%ir-block.0):
  successors: %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  renamable $rax = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr $rbp, 1, $noreg, -8, $noreg, killed renamable $rax
  MOV32mi $rbp, 1, $noreg, -32, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi $rbp, 1, $noreg, -12, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi $rbp, 1, $noreg, -16, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi $rbp, 1, $noreg, -24, $noreg, 1 :: (store (s32) into %ir.4)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -20, $noreg
  renamable $rdx = LEA64r $rbp, 1, $noreg, -12, $noreg
  renamable $rcx = LEA64r $rbp, 1, $noreg, -16, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -20, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit killed $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -28, $noreg, killed renamable $eax :: (store (s32) into %ir.6)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $eax = ADD32rm killed renamable $eax(tied-def 0), $rbp, 1, $noreg, -16, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -16, $noreg, killed renamable $eax :: (store (s32) into %ir.3)
  renamable $esi = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  renamable $rdi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.6)
  MOV32mr $rbp, 1, $noreg, -12, $noreg, killed renamable $eax :: (store (s32) into %ir.2)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -24, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  renamable $eax = MOV32rm $rbp, 1, $noreg, -32, $noreg :: (dereferenceable load (s32) from %ir.1)
  renamable $rcx = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  renamable $rdx = MOV64rm $rbp, 1, $noreg, -8, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr killed renamable $rcx, killed renamable $rdx, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit killed $eflags

bb.4.SP_return:
; predecessors: %bb.3
  liveins: $eax
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before Branch Probability Basic Block Placement (block-placement) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=8, align=8, at location [SP-16]
  fi#1: size=4, align=4, at location [SP-40]
  fi#2: size=4, align=4, at location [SP-20]
  fi#3: size=4, align=4, at location [SP-24]
  fi#4: size=4, align=4, at location [SP-32]
  fi#5: size=4, align=4, at location [SP-28]
  fi#6: size=4, align=4, at location [SP-36]

bb.0 (%ir-block.0):
  successors: %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  renamable $rax = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr $rbp, 1, $noreg, -8, $noreg, killed renamable $rax
  MOV32mi $rbp, 1, $noreg, -32, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi $rbp, 1, $noreg, -12, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi $rbp, 1, $noreg, -16, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi $rbp, 1, $noreg, -24, $noreg, 1 :: (store (s32) into %ir.4)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -20, $noreg
  renamable $rdx = LEA64r $rbp, 1, $noreg, -12, $noreg
  renamable $rcx = LEA64r $rbp, 1, $noreg, -16, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -20, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit killed $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -28, $noreg, killed renamable $eax :: (store (s32) into %ir.6)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $eax = ADD32rm killed renamable $eax(tied-def 0), $rbp, 1, $noreg, -16, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -16, $noreg, killed renamable $eax :: (store (s32) into %ir.3)
  renamable $esi = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  renamable $rdi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.6)
  MOV32mr $rbp, 1, $noreg, -12, $noreg, killed renamable $eax :: (store (s32) into %ir.2)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -24, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  renamable $eax = MOV32rm $rbp, 1, $noreg, -32, $noreg :: (dereferenceable load (s32) from %ir.1)
  renamable $rcx = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  renamable $rdx = MOV64rm $rbp, 1, $noreg, -8, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr killed renamable $rcx, killed renamable $rdx, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit killed $eflags

bb.4.SP_return:
; predecessors: %bb.3
  liveins: $eax
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After Branch Probability Basic Block Placement (block-placement) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=8, align=8, at location [SP-16]
  fi#1: size=4, align=4, at location [SP-40]
  fi#2: size=4, align=4, at location [SP-20]
  fi#3: size=4, align=4, at location [SP-24]
  fi#4: size=4, align=4, at location [SP-32]
  fi#5: size=4, align=4, at location [SP-28]
  fi#6: size=4, align=4, at location [SP-36]

bb.0 (%ir-block.0):
  successors: %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  renamable $rax = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr $rbp, 1, $noreg, -8, $noreg, killed renamable $rax
  MOV32mi $rbp, 1, $noreg, -32, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi $rbp, 1, $noreg, -12, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi $rbp, 1, $noreg, -16, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi $rbp, 1, $noreg, -24, $noreg, 1 :: (store (s32) into %ir.4)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -20, $noreg
  renamable $rdx = LEA64r $rbp, 1, $noreg, -12, $noreg
  renamable $rcx = LEA64r $rbp, 1, $noreg, -16, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -20, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit killed $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -28, $noreg, killed renamable $eax :: (store (s32) into %ir.6)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $eax = ADD32rm killed renamable $eax(tied-def 0), $rbp, 1, $noreg, -16, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -16, $noreg, killed renamable $eax :: (store (s32) into %ir.3)
  renamable $esi = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  renamable $rdi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.6)
  MOV32mr $rbp, 1, $noreg, -12, $noreg, killed renamable $eax :: (store (s32) into %ir.2)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -24, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  renamable $eax = MOV32rm $rbp, 1, $noreg, -32, $noreg :: (dereferenceable load (s32) from %ir.1)
  renamable $rcx = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  renamable $rdx = MOV64rm $rbp, 1, $noreg, -8, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr killed renamable $rcx, killed renamable $rdx, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit killed $eflags

bb.4.SP_return:
; predecessors: %bb.3
  liveins: $eax
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before Insert fentry calls (fentry-insert) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=8, align=8, at location [SP-16]
  fi#1: size=4, align=4, at location [SP-40]
  fi#2: size=4, align=4, at location [SP-20]
  fi#3: size=4, align=4, at location [SP-24]
  fi#4: size=4, align=4, at location [SP-32]
  fi#5: size=4, align=4, at location [SP-28]
  fi#6: size=4, align=4, at location [SP-36]

bb.0 (%ir-block.0):
  successors: %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  renamable $rax = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr $rbp, 1, $noreg, -8, $noreg, killed renamable $rax
  MOV32mi $rbp, 1, $noreg, -32, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi $rbp, 1, $noreg, -12, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi $rbp, 1, $noreg, -16, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi $rbp, 1, $noreg, -24, $noreg, 1 :: (store (s32) into %ir.4)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -20, $noreg
  renamable $rdx = LEA64r $rbp, 1, $noreg, -12, $noreg
  renamable $rcx = LEA64r $rbp, 1, $noreg, -16, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -20, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit killed $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -28, $noreg, killed renamable $eax :: (store (s32) into %ir.6)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $eax = ADD32rm killed renamable $eax(tied-def 0), $rbp, 1, $noreg, -16, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -16, $noreg, killed renamable $eax :: (store (s32) into %ir.3)
  renamable $esi = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  renamable $rdi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.6)
  MOV32mr $rbp, 1, $noreg, -12, $noreg, killed renamable $eax :: (store (s32) into %ir.2)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -24, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  renamable $eax = MOV32rm $rbp, 1, $noreg, -32, $noreg :: (dereferenceable load (s32) from %ir.1)
  renamable $rcx = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  renamable $rdx = MOV64rm $rbp, 1, $noreg, -8, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr killed renamable $rcx, killed renamable $rdx, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit killed $eflags

bb.4.SP_return:
; predecessors: %bb.3
  liveins: $eax
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After Insert fentry calls (fentry-insert) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=8, align=8, at location [SP-16]
  fi#1: size=4, align=4, at location [SP-40]
  fi#2: size=4, align=4, at location [SP-20]
  fi#3: size=4, align=4, at location [SP-24]
  fi#4: size=4, align=4, at location [SP-32]
  fi#5: size=4, align=4, at location [SP-28]
  fi#6: size=4, align=4, at location [SP-36]

bb.0 (%ir-block.0):
  successors: %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  renamable $rax = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr $rbp, 1, $noreg, -8, $noreg, killed renamable $rax
  MOV32mi $rbp, 1, $noreg, -32, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi $rbp, 1, $noreg, -12, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi $rbp, 1, $noreg, -16, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi $rbp, 1, $noreg, -24, $noreg, 1 :: (store (s32) into %ir.4)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -20, $noreg
  renamable $rdx = LEA64r $rbp, 1, $noreg, -12, $noreg
  renamable $rcx = LEA64r $rbp, 1, $noreg, -16, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -20, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit killed $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -28, $noreg, killed renamable $eax :: (store (s32) into %ir.6)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $eax = ADD32rm killed renamable $eax(tied-def 0), $rbp, 1, $noreg, -16, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -16, $noreg, killed renamable $eax :: (store (s32) into %ir.3)
  renamable $esi = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  renamable $rdi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.6)
  MOV32mr $rbp, 1, $noreg, -12, $noreg, killed renamable $eax :: (store (s32) into %ir.2)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -24, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  renamable $eax = MOV32rm $rbp, 1, $noreg, -32, $noreg :: (dereferenceable load (s32) from %ir.1)
  renamable $rcx = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  renamable $rdx = MOV64rm $rbp, 1, $noreg, -8, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr killed renamable $rcx, killed renamable $rdx, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit killed $eflags

bb.4.SP_return:
; predecessors: %bb.3
  liveins: $eax
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before Insert XRay ops (xray-instrumentation) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=8, align=8, at location [SP-16]
  fi#1: size=4, align=4, at location [SP-40]
  fi#2: size=4, align=4, at location [SP-20]
  fi#3: size=4, align=4, at location [SP-24]
  fi#4: size=4, align=4, at location [SP-32]
  fi#5: size=4, align=4, at location [SP-28]
  fi#6: size=4, align=4, at location [SP-36]

bb.0 (%ir-block.0):
  successors: %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  renamable $rax = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr $rbp, 1, $noreg, -8, $noreg, killed renamable $rax
  MOV32mi $rbp, 1, $noreg, -32, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi $rbp, 1, $noreg, -12, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi $rbp, 1, $noreg, -16, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi $rbp, 1, $noreg, -24, $noreg, 1 :: (store (s32) into %ir.4)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -20, $noreg
  renamable $rdx = LEA64r $rbp, 1, $noreg, -12, $noreg
  renamable $rcx = LEA64r $rbp, 1, $noreg, -16, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -20, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit killed $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -28, $noreg, killed renamable $eax :: (store (s32) into %ir.6)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $eax = ADD32rm killed renamable $eax(tied-def 0), $rbp, 1, $noreg, -16, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -16, $noreg, killed renamable $eax :: (store (s32) into %ir.3)
  renamable $esi = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  renamable $rdi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.6)
  MOV32mr $rbp, 1, $noreg, -12, $noreg, killed renamable $eax :: (store (s32) into %ir.2)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -24, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  renamable $eax = MOV32rm $rbp, 1, $noreg, -32, $noreg :: (dereferenceable load (s32) from %ir.1)
  renamable $rcx = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  renamable $rdx = MOV64rm $rbp, 1, $noreg, -8, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr killed renamable $rcx, killed renamable $rdx, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit killed $eflags

bb.4.SP_return:
; predecessors: %bb.3
  liveins: $eax
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After Insert XRay ops (xray-instrumentation) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=8, align=8, at location [SP-16]
  fi#1: size=4, align=4, at location [SP-40]
  fi#2: size=4, align=4, at location [SP-20]
  fi#3: size=4, align=4, at location [SP-24]
  fi#4: size=4, align=4, at location [SP-32]
  fi#5: size=4, align=4, at location [SP-28]
  fi#6: size=4, align=4, at location [SP-36]

bb.0 (%ir-block.0):
  successors: %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  renamable $rax = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr $rbp, 1, $noreg, -8, $noreg, killed renamable $rax
  MOV32mi $rbp, 1, $noreg, -32, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi $rbp, 1, $noreg, -12, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi $rbp, 1, $noreg, -16, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi $rbp, 1, $noreg, -24, $noreg, 1 :: (store (s32) into %ir.4)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -20, $noreg
  renamable $rdx = LEA64r $rbp, 1, $noreg, -12, $noreg
  renamable $rcx = LEA64r $rbp, 1, $noreg, -16, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -20, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit killed $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -28, $noreg, killed renamable $eax :: (store (s32) into %ir.6)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $eax = ADD32rm killed renamable $eax(tied-def 0), $rbp, 1, $noreg, -16, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -16, $noreg, killed renamable $eax :: (store (s32) into %ir.3)
  renamable $esi = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  renamable $rdi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.6)
  MOV32mr $rbp, 1, $noreg, -12, $noreg, killed renamable $eax :: (store (s32) into %ir.2)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -24, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  renamable $eax = MOV32rm $rbp, 1, $noreg, -32, $noreg :: (dereferenceable load (s32) from %ir.1)
  renamable $rcx = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  renamable $rdx = MOV64rm $rbp, 1, $noreg, -8, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr killed renamable $rcx, killed renamable $rdx, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit killed $eflags

bb.4.SP_return:
; predecessors: %bb.3
  liveins: $eax
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before Implement the 'patchable-function' attribute (patchable-function) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=8, align=8, at location [SP-16]
  fi#1: size=4, align=4, at location [SP-40]
  fi#2: size=4, align=4, at location [SP-20]
  fi#3: size=4, align=4, at location [SP-24]
  fi#4: size=4, align=4, at location [SP-32]
  fi#5: size=4, align=4, at location [SP-28]
  fi#6: size=4, align=4, at location [SP-36]

bb.0 (%ir-block.0):
  successors: %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  renamable $rax = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr $rbp, 1, $noreg, -8, $noreg, killed renamable $rax
  MOV32mi $rbp, 1, $noreg, -32, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi $rbp, 1, $noreg, -12, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi $rbp, 1, $noreg, -16, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi $rbp, 1, $noreg, -24, $noreg, 1 :: (store (s32) into %ir.4)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -20, $noreg
  renamable $rdx = LEA64r $rbp, 1, $noreg, -12, $noreg
  renamable $rcx = LEA64r $rbp, 1, $noreg, -16, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -20, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit killed $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -28, $noreg, killed renamable $eax :: (store (s32) into %ir.6)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $eax = ADD32rm killed renamable $eax(tied-def 0), $rbp, 1, $noreg, -16, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -16, $noreg, killed renamable $eax :: (store (s32) into %ir.3)
  renamable $esi = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  renamable $rdi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.6)
  MOV32mr $rbp, 1, $noreg, -12, $noreg, killed renamable $eax :: (store (s32) into %ir.2)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -24, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  renamable $eax = MOV32rm $rbp, 1, $noreg, -32, $noreg :: (dereferenceable load (s32) from %ir.1)
  renamable $rcx = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  renamable $rdx = MOV64rm $rbp, 1, $noreg, -8, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr killed renamable $rcx, killed renamable $rdx, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit killed $eflags

bb.4.SP_return:
; predecessors: %bb.3
  liveins: $eax
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After Implement the 'patchable-function' attribute (patchable-function) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=8, align=8, at location [SP-16]
  fi#1: size=4, align=4, at location [SP-40]
  fi#2: size=4, align=4, at location [SP-20]
  fi#3: size=4, align=4, at location [SP-24]
  fi#4: size=4, align=4, at location [SP-32]
  fi#5: size=4, align=4, at location [SP-28]
  fi#6: size=4, align=4, at location [SP-36]

bb.0 (%ir-block.0):
  successors: %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  renamable $rax = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr $rbp, 1, $noreg, -8, $noreg, killed renamable $rax
  MOV32mi $rbp, 1, $noreg, -32, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi $rbp, 1, $noreg, -12, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi $rbp, 1, $noreg, -16, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi $rbp, 1, $noreg, -24, $noreg, 1 :: (store (s32) into %ir.4)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -20, $noreg
  renamable $rdx = LEA64r $rbp, 1, $noreg, -12, $noreg
  renamable $rcx = LEA64r $rbp, 1, $noreg, -16, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -20, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit killed $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -28, $noreg, killed renamable $eax :: (store (s32) into %ir.6)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $eax = ADD32rm killed renamable $eax(tied-def 0), $rbp, 1, $noreg, -16, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -16, $noreg, killed renamable $eax :: (store (s32) into %ir.3)
  renamable $esi = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  renamable $rdi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.6)
  MOV32mr $rbp, 1, $noreg, -12, $noreg, killed renamable $eax :: (store (s32) into %ir.2)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -24, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  renamable $eax = MOV32rm $rbp, 1, $noreg, -32, $noreg :: (dereferenceable load (s32) from %ir.1)
  renamable $rcx = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  renamable $rdx = MOV64rm $rbp, 1, $noreg, -8, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr killed renamable $rcx, killed renamable $rdx, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit killed $eflags

bb.4.SP_return:
; predecessors: %bb.3
  liveins: $eax
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before X86 Execution Dependency Fix (x86-execution-domain-fix) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=8, align=8, at location [SP-16]
  fi#1: size=4, align=4, at location [SP-40]
  fi#2: size=4, align=4, at location [SP-20]
  fi#3: size=4, align=4, at location [SP-24]
  fi#4: size=4, align=4, at location [SP-32]
  fi#5: size=4, align=4, at location [SP-28]
  fi#6: size=4, align=4, at location [SP-36]

bb.0 (%ir-block.0):
  successors: %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  renamable $rax = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr $rbp, 1, $noreg, -8, $noreg, killed renamable $rax
  MOV32mi $rbp, 1, $noreg, -32, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi $rbp, 1, $noreg, -12, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi $rbp, 1, $noreg, -16, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi $rbp, 1, $noreg, -24, $noreg, 1 :: (store (s32) into %ir.4)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -20, $noreg
  renamable $rdx = LEA64r $rbp, 1, $noreg, -12, $noreg
  renamable $rcx = LEA64r $rbp, 1, $noreg, -16, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -20, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit killed $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -28, $noreg, killed renamable $eax :: (store (s32) into %ir.6)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $eax = ADD32rm killed renamable $eax(tied-def 0), $rbp, 1, $noreg, -16, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -16, $noreg, killed renamable $eax :: (store (s32) into %ir.3)
  renamable $esi = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  renamable $rdi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.6)
  MOV32mr $rbp, 1, $noreg, -12, $noreg, killed renamable $eax :: (store (s32) into %ir.2)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -24, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  renamable $eax = MOV32rm $rbp, 1, $noreg, -32, $noreg :: (dereferenceable load (s32) from %ir.1)
  renamable $rcx = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  renamable $rdx = MOV64rm $rbp, 1, $noreg, -8, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr killed renamable $rcx, killed renamable $rdx, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit killed $eflags

bb.4.SP_return:
; predecessors: %bb.3
  liveins: $eax
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After X86 Execution Dependency Fix (x86-execution-domain-fix) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=8, align=8, at location [SP-16]
  fi#1: size=4, align=4, at location [SP-40]
  fi#2: size=4, align=4, at location [SP-20]
  fi#3: size=4, align=4, at location [SP-24]
  fi#4: size=4, align=4, at location [SP-32]
  fi#5: size=4, align=4, at location [SP-28]
  fi#6: size=4, align=4, at location [SP-36]

bb.0 (%ir-block.0):
  successors: %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  renamable $rax = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr $rbp, 1, $noreg, -8, $noreg, killed renamable $rax
  MOV32mi $rbp, 1, $noreg, -32, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi $rbp, 1, $noreg, -12, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi $rbp, 1, $noreg, -16, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi $rbp, 1, $noreg, -24, $noreg, 1 :: (store (s32) into %ir.4)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -20, $noreg
  renamable $rdx = LEA64r $rbp, 1, $noreg, -12, $noreg
  renamable $rcx = LEA64r $rbp, 1, $noreg, -16, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -20, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit killed $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -28, $noreg, killed renamable $eax :: (store (s32) into %ir.6)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $eax = ADD32rm killed renamable $eax(tied-def 0), $rbp, 1, $noreg, -16, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -16, $noreg, killed renamable $eax :: (store (s32) into %ir.3)
  renamable $esi = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  renamable $rdi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.6)
  MOV32mr $rbp, 1, $noreg, -12, $noreg, killed renamable $eax :: (store (s32) into %ir.2)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -24, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  renamable $eax = MOV32rm $rbp, 1, $noreg, -32, $noreg :: (dereferenceable load (s32) from %ir.1)
  renamable $rcx = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  renamable $rdx = MOV64rm $rbp, 1, $noreg, -8, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr killed renamable $rcx, killed renamable $rdx, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit killed $eflags

bb.4.SP_return:
; predecessors: %bb.3
  liveins: $eax
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before BreakFalseDeps (break-false-deps) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=8, align=8, at location [SP-16]
  fi#1: size=4, align=4, at location [SP-40]
  fi#2: size=4, align=4, at location [SP-20]
  fi#3: size=4, align=4, at location [SP-24]
  fi#4: size=4, align=4, at location [SP-32]
  fi#5: size=4, align=4, at location [SP-28]
  fi#6: size=4, align=4, at location [SP-36]

bb.0 (%ir-block.0):
  successors: %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  renamable $rax = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr $rbp, 1, $noreg, -8, $noreg, killed renamable $rax
  MOV32mi $rbp, 1, $noreg, -32, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi $rbp, 1, $noreg, -12, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi $rbp, 1, $noreg, -16, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi $rbp, 1, $noreg, -24, $noreg, 1 :: (store (s32) into %ir.4)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -20, $noreg
  renamable $rdx = LEA64r $rbp, 1, $noreg, -12, $noreg
  renamable $rcx = LEA64r $rbp, 1, $noreg, -16, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -20, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit killed $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -28, $noreg, killed renamable $eax :: (store (s32) into %ir.6)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $eax = ADD32rm killed renamable $eax(tied-def 0), $rbp, 1, $noreg, -16, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -16, $noreg, killed renamable $eax :: (store (s32) into %ir.3)
  renamable $esi = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  renamable $rdi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.6)
  MOV32mr $rbp, 1, $noreg, -12, $noreg, killed renamable $eax :: (store (s32) into %ir.2)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -24, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  renamable $eax = MOV32rm $rbp, 1, $noreg, -32, $noreg :: (dereferenceable load (s32) from %ir.1)
  renamable $rcx = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  renamable $rdx = MOV64rm $rbp, 1, $noreg, -8, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr killed renamable $rcx, killed renamable $rdx, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit killed $eflags

bb.4.SP_return:
; predecessors: %bb.3
  liveins: $eax
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After BreakFalseDeps (break-false-deps) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=8, align=8, at location [SP-16]
  fi#1: size=4, align=4, at location [SP-40]
  fi#2: size=4, align=4, at location [SP-20]
  fi#3: size=4, align=4, at location [SP-24]
  fi#4: size=4, align=4, at location [SP-32]
  fi#5: size=4, align=4, at location [SP-28]
  fi#6: size=4, align=4, at location [SP-36]

bb.0 (%ir-block.0):
  successors: %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  renamable $rax = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr $rbp, 1, $noreg, -8, $noreg, killed renamable $rax
  MOV32mi $rbp, 1, $noreg, -32, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi $rbp, 1, $noreg, -12, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi $rbp, 1, $noreg, -16, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi $rbp, 1, $noreg, -24, $noreg, 1 :: (store (s32) into %ir.4)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -20, $noreg
  renamable $rdx = LEA64r $rbp, 1, $noreg, -12, $noreg
  renamable $rcx = LEA64r $rbp, 1, $noreg, -16, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -20, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit killed $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -28, $noreg, killed renamable $eax :: (store (s32) into %ir.6)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $eax = ADD32rm killed renamable $eax(tied-def 0), $rbp, 1, $noreg, -16, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -16, $noreg, killed renamable $eax :: (store (s32) into %ir.3)
  renamable $esi = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  renamable $rdi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.6)
  MOV32mr $rbp, 1, $noreg, -12, $noreg, killed renamable $eax :: (store (s32) into %ir.2)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -24, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  renamable $eax = MOV32rm $rbp, 1, $noreg, -32, $noreg :: (dereferenceable load (s32) from %ir.1)
  renamable $rcx = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  renamable $rdx = MOV64rm $rbp, 1, $noreg, -8, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr killed renamable $rcx, killed renamable $rdx, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit killed $eflags

bb.4.SP_return:
; predecessors: %bb.3
  liveins: $eax
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before X86 Byte/Word Instruction Fixup (x86-fixup-bw-insts) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=8, align=8, at location [SP-16]
  fi#1: size=4, align=4, at location [SP-40]
  fi#2: size=4, align=4, at location [SP-20]
  fi#3: size=4, align=4, at location [SP-24]
  fi#4: size=4, align=4, at location [SP-32]
  fi#5: size=4, align=4, at location [SP-28]
  fi#6: size=4, align=4, at location [SP-36]

bb.0 (%ir-block.0):
  successors: %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  renamable $rax = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr $rbp, 1, $noreg, -8, $noreg, killed renamable $rax
  MOV32mi $rbp, 1, $noreg, -32, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi $rbp, 1, $noreg, -12, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi $rbp, 1, $noreg, -16, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi $rbp, 1, $noreg, -24, $noreg, 1 :: (store (s32) into %ir.4)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -20, $noreg
  renamable $rdx = LEA64r $rbp, 1, $noreg, -12, $noreg
  renamable $rcx = LEA64r $rbp, 1, $noreg, -16, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -20, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit killed $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -28, $noreg, killed renamable $eax :: (store (s32) into %ir.6)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $eax = ADD32rm killed renamable $eax(tied-def 0), $rbp, 1, $noreg, -16, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -16, $noreg, killed renamable $eax :: (store (s32) into %ir.3)
  renamable $esi = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  renamable $rdi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.6)
  MOV32mr $rbp, 1, $noreg, -12, $noreg, killed renamable $eax :: (store (s32) into %ir.2)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -24, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  renamable $eax = MOV32rm $rbp, 1, $noreg, -32, $noreg :: (dereferenceable load (s32) from %ir.1)
  renamable $rcx = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  renamable $rdx = MOV64rm $rbp, 1, $noreg, -8, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr killed renamable $rcx, killed renamable $rdx, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit killed $eflags

bb.4.SP_return:
; predecessors: %bb.3
  liveins: $eax
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After X86 Byte/Word Instruction Fixup (x86-fixup-bw-insts) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=8, align=8, at location [SP-16]
  fi#1: size=4, align=4, at location [SP-40]
  fi#2: size=4, align=4, at location [SP-20]
  fi#3: size=4, align=4, at location [SP-24]
  fi#4: size=4, align=4, at location [SP-32]
  fi#5: size=4, align=4, at location [SP-28]
  fi#6: size=4, align=4, at location [SP-36]

bb.0 (%ir-block.0):
  successors: %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  renamable $rax = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr $rbp, 1, $noreg, -8, $noreg, killed renamable $rax
  MOV32mi $rbp, 1, $noreg, -32, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi $rbp, 1, $noreg, -12, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi $rbp, 1, $noreg, -16, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi $rbp, 1, $noreg, -24, $noreg, 1 :: (store (s32) into %ir.4)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -20, $noreg
  renamable $rdx = LEA64r $rbp, 1, $noreg, -12, $noreg
  renamable $rcx = LEA64r $rbp, 1, $noreg, -16, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -20, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit killed $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -28, $noreg, killed renamable $eax :: (store (s32) into %ir.6)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $eax = ADD32rm killed renamable $eax(tied-def 0), $rbp, 1, $noreg, -16, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -16, $noreg, killed renamable $eax :: (store (s32) into %ir.3)
  renamable $esi = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  renamable $rdi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.6)
  MOV32mr $rbp, 1, $noreg, -12, $noreg, killed renamable $eax :: (store (s32) into %ir.2)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -24, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  renamable $eax = MOV32rm $rbp, 1, $noreg, -32, $noreg :: (dereferenceable load (s32) from %ir.1)
  renamable $rcx = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  renamable $rdx = MOV64rm $rbp, 1, $noreg, -8, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr killed renamable $rcx, killed renamable $rdx, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit killed $eflags

bb.4.SP_return:
; predecessors: %bb.3
  liveins: $eax
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before X86 LEA Fixup (x86-fixup-LEAs) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=8, align=8, at location [SP-16]
  fi#1: size=4, align=4, at location [SP-40]
  fi#2: size=4, align=4, at location [SP-20]
  fi#3: size=4, align=4, at location [SP-24]
  fi#4: size=4, align=4, at location [SP-32]
  fi#5: size=4, align=4, at location [SP-28]
  fi#6: size=4, align=4, at location [SP-36]

bb.0 (%ir-block.0):
  successors: %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  renamable $rax = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr $rbp, 1, $noreg, -8, $noreg, killed renamable $rax
  MOV32mi $rbp, 1, $noreg, -32, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi $rbp, 1, $noreg, -12, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi $rbp, 1, $noreg, -16, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi $rbp, 1, $noreg, -24, $noreg, 1 :: (store (s32) into %ir.4)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -20, $noreg
  renamable $rdx = LEA64r $rbp, 1, $noreg, -12, $noreg
  renamable $rcx = LEA64r $rbp, 1, $noreg, -16, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -20, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit killed $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -28, $noreg, killed renamable $eax :: (store (s32) into %ir.6)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $eax = ADD32rm killed renamable $eax(tied-def 0), $rbp, 1, $noreg, -16, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -16, $noreg, killed renamable $eax :: (store (s32) into %ir.3)
  renamable $esi = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  renamable $rdi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.6)
  MOV32mr $rbp, 1, $noreg, -12, $noreg, killed renamable $eax :: (store (s32) into %ir.2)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -24, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  renamable $eax = MOV32rm $rbp, 1, $noreg, -32, $noreg :: (dereferenceable load (s32) from %ir.1)
  renamable $rcx = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  renamable $rdx = MOV64rm $rbp, 1, $noreg, -8, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr killed renamable $rcx, killed renamable $rdx, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit killed $eflags

bb.4.SP_return:
; predecessors: %bb.3
  liveins: $eax
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After X86 LEA Fixup (x86-fixup-LEAs) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=8, align=8, at location [SP-16]
  fi#1: size=4, align=4, at location [SP-40]
  fi#2: size=4, align=4, at location [SP-20]
  fi#3: size=4, align=4, at location [SP-24]
  fi#4: size=4, align=4, at location [SP-32]
  fi#5: size=4, align=4, at location [SP-28]
  fi#6: size=4, align=4, at location [SP-36]

bb.0 (%ir-block.0):
  successors: %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  renamable $rax = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr $rbp, 1, $noreg, -8, $noreg, killed renamable $rax
  MOV32mi $rbp, 1, $noreg, -32, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi $rbp, 1, $noreg, -12, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi $rbp, 1, $noreg, -16, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi $rbp, 1, $noreg, -24, $noreg, 1 :: (store (s32) into %ir.4)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -20, $noreg
  renamable $rdx = LEA64r $rbp, 1, $noreg, -12, $noreg
  renamable $rcx = LEA64r $rbp, 1, $noreg, -16, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -20, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit killed $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -28, $noreg, killed renamable $eax :: (store (s32) into %ir.6)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $eax = ADD32rm killed renamable $eax(tied-def 0), $rbp, 1, $noreg, -16, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -16, $noreg, killed renamable $eax :: (store (s32) into %ir.3)
  renamable $esi = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  renamable $rdi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.6)
  MOV32mr $rbp, 1, $noreg, -12, $noreg, killed renamable $eax :: (store (s32) into %ir.2)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -24, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  renamable $eax = MOV32rm $rbp, 1, $noreg, -32, $noreg :: (dereferenceable load (s32) from %ir.1)
  renamable $rcx = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  renamable $rdx = MOV64rm $rbp, 1, $noreg, -8, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr killed renamable $rcx, killed renamable $rdx, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit killed $eflags

bb.4.SP_return:
; predecessors: %bb.3
  liveins: $eax
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before Compressing EVEX instrs to VEX encoding when possible (x86-evex-to-vex-compress) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=8, align=8, at location [SP-16]
  fi#1: size=4, align=4, at location [SP-40]
  fi#2: size=4, align=4, at location [SP-20]
  fi#3: size=4, align=4, at location [SP-24]
  fi#4: size=4, align=4, at location [SP-32]
  fi#5: size=4, align=4, at location [SP-28]
  fi#6: size=4, align=4, at location [SP-36]

bb.0 (%ir-block.0):
  successors: %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  renamable $rax = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr $rbp, 1, $noreg, -8, $noreg, killed renamable $rax
  MOV32mi $rbp, 1, $noreg, -32, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi $rbp, 1, $noreg, -12, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi $rbp, 1, $noreg, -16, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi $rbp, 1, $noreg, -24, $noreg, 1 :: (store (s32) into %ir.4)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -20, $noreg
  renamable $rdx = LEA64r $rbp, 1, $noreg, -12, $noreg
  renamable $rcx = LEA64r $rbp, 1, $noreg, -16, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -20, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit killed $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -28, $noreg, killed renamable $eax :: (store (s32) into %ir.6)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $eax = ADD32rm killed renamable $eax(tied-def 0), $rbp, 1, $noreg, -16, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -16, $noreg, killed renamable $eax :: (store (s32) into %ir.3)
  renamable $esi = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  renamable $rdi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.6)
  MOV32mr $rbp, 1, $noreg, -12, $noreg, killed renamable $eax :: (store (s32) into %ir.2)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -24, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  renamable $eax = MOV32rm $rbp, 1, $noreg, -32, $noreg :: (dereferenceable load (s32) from %ir.1)
  renamable $rcx = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  renamable $rdx = MOV64rm $rbp, 1, $noreg, -8, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr killed renamable $rcx, killed renamable $rdx, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit killed $eflags

bb.4.SP_return:
; predecessors: %bb.3
  liveins: $eax
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After Compressing EVEX instrs to VEX encoding when possible (x86-evex-to-vex-compress) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=8, align=8, at location [SP-16]
  fi#1: size=4, align=4, at location [SP-40]
  fi#2: size=4, align=4, at location [SP-20]
  fi#3: size=4, align=4, at location [SP-24]
  fi#4: size=4, align=4, at location [SP-32]
  fi#5: size=4, align=4, at location [SP-28]
  fi#6: size=4, align=4, at location [SP-36]

bb.0 (%ir-block.0):
  successors: %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  renamable $rax = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr $rbp, 1, $noreg, -8, $noreg, killed renamable $rax
  MOV32mi $rbp, 1, $noreg, -32, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi $rbp, 1, $noreg, -12, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi $rbp, 1, $noreg, -16, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi $rbp, 1, $noreg, -24, $noreg, 1 :: (store (s32) into %ir.4)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -20, $noreg
  renamable $rdx = LEA64r $rbp, 1, $noreg, -12, $noreg
  renamable $rcx = LEA64r $rbp, 1, $noreg, -16, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -20, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit killed $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -28, $noreg, killed renamable $eax :: (store (s32) into %ir.6)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $eax = ADD32rm killed renamable $eax(tied-def 0), $rbp, 1, $noreg, -16, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -16, $noreg, killed renamable $eax :: (store (s32) into %ir.3)
  renamable $esi = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  renamable $rdi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.6)
  MOV32mr $rbp, 1, $noreg, -12, $noreg, killed renamable $eax :: (store (s32) into %ir.2)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -24, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  renamable $eax = MOV32rm $rbp, 1, $noreg, -32, $noreg :: (dereferenceable load (s32) from %ir.1)
  renamable $rcx = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  renamable $rdx = MOV64rm $rbp, 1, $noreg, -8, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr killed renamable $rcx, killed renamable $rdx, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit killed $eflags

bb.4.SP_return:
; predecessors: %bb.3
  liveins: $eax
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before Contiguously Lay Out Funclets (funclet-layout) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=8, align=8, at location [SP-16]
  fi#1: size=4, align=4, at location [SP-40]
  fi#2: size=4, align=4, at location [SP-20]
  fi#3: size=4, align=4, at location [SP-24]
  fi#4: size=4, align=4, at location [SP-32]
  fi#5: size=4, align=4, at location [SP-28]
  fi#6: size=4, align=4, at location [SP-36]

bb.0 (%ir-block.0):
  successors: %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  renamable $rax = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr $rbp, 1, $noreg, -8, $noreg, killed renamable $rax
  MOV32mi $rbp, 1, $noreg, -32, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi $rbp, 1, $noreg, -12, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi $rbp, 1, $noreg, -16, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi $rbp, 1, $noreg, -24, $noreg, 1 :: (store (s32) into %ir.4)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -20, $noreg
  renamable $rdx = LEA64r $rbp, 1, $noreg, -12, $noreg
  renamable $rcx = LEA64r $rbp, 1, $noreg, -16, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -20, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit killed $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -28, $noreg, killed renamable $eax :: (store (s32) into %ir.6)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $eax = ADD32rm killed renamable $eax(tied-def 0), $rbp, 1, $noreg, -16, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -16, $noreg, killed renamable $eax :: (store (s32) into %ir.3)
  renamable $esi = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  renamable $rdi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.6)
  MOV32mr $rbp, 1, $noreg, -12, $noreg, killed renamable $eax :: (store (s32) into %ir.2)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -24, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  renamable $eax = MOV32rm $rbp, 1, $noreg, -32, $noreg :: (dereferenceable load (s32) from %ir.1)
  renamable $rcx = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  renamable $rdx = MOV64rm $rbp, 1, $noreg, -8, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr killed renamable $rcx, killed renamable $rdx, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit killed $eflags

bb.4.SP_return:
; predecessors: %bb.3
  liveins: $eax
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After Contiguously Lay Out Funclets (funclet-layout) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=8, align=8, at location [SP-16]
  fi#1: size=4, align=4, at location [SP-40]
  fi#2: size=4, align=4, at location [SP-20]
  fi#3: size=4, align=4, at location [SP-24]
  fi#4: size=4, align=4, at location [SP-32]
  fi#5: size=4, align=4, at location [SP-28]
  fi#6: size=4, align=4, at location [SP-36]

bb.0 (%ir-block.0):
  successors: %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  renamable $rax = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr $rbp, 1, $noreg, -8, $noreg, killed renamable $rax
  MOV32mi $rbp, 1, $noreg, -32, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi $rbp, 1, $noreg, -12, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi $rbp, 1, $noreg, -16, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi $rbp, 1, $noreg, -24, $noreg, 1 :: (store (s32) into %ir.4)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -20, $noreg
  renamable $rdx = LEA64r $rbp, 1, $noreg, -12, $noreg
  renamable $rcx = LEA64r $rbp, 1, $noreg, -16, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -20, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit killed $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -28, $noreg, killed renamable $eax :: (store (s32) into %ir.6)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $eax = ADD32rm killed renamable $eax(tied-def 0), $rbp, 1, $noreg, -16, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -16, $noreg, killed renamable $eax :: (store (s32) into %ir.3)
  renamable $esi = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  renamable $rdi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.6)
  MOV32mr $rbp, 1, $noreg, -12, $noreg, killed renamable $eax :: (store (s32) into %ir.2)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -24, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  renamable $eax = MOV32rm $rbp, 1, $noreg, -32, $noreg :: (dereferenceable load (s32) from %ir.1)
  renamable $rcx = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  renamable $rdx = MOV64rm $rbp, 1, $noreg, -8, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr killed renamable $rcx, killed renamable $rdx, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit killed $eflags

bb.4.SP_return:
; predecessors: %bb.3
  liveins: $eax
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before StackMap Liveness Analysis (stackmap-liveness) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=8, align=8, at location [SP-16]
  fi#1: size=4, align=4, at location [SP-40]
  fi#2: size=4, align=4, at location [SP-20]
  fi#3: size=4, align=4, at location [SP-24]
  fi#4: size=4, align=4, at location [SP-32]
  fi#5: size=4, align=4, at location [SP-28]
  fi#6: size=4, align=4, at location [SP-36]

bb.0 (%ir-block.0):
  successors: %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  renamable $rax = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr $rbp, 1, $noreg, -8, $noreg, killed renamable $rax
  MOV32mi $rbp, 1, $noreg, -32, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi $rbp, 1, $noreg, -12, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi $rbp, 1, $noreg, -16, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi $rbp, 1, $noreg, -24, $noreg, 1 :: (store (s32) into %ir.4)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -20, $noreg
  renamable $rdx = LEA64r $rbp, 1, $noreg, -12, $noreg
  renamable $rcx = LEA64r $rbp, 1, $noreg, -16, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -20, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit killed $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -28, $noreg, killed renamable $eax :: (store (s32) into %ir.6)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $eax = ADD32rm killed renamable $eax(tied-def 0), $rbp, 1, $noreg, -16, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -16, $noreg, killed renamable $eax :: (store (s32) into %ir.3)
  renamable $esi = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  renamable $rdi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.6)
  MOV32mr $rbp, 1, $noreg, -12, $noreg, killed renamable $eax :: (store (s32) into %ir.2)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -24, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  renamable $eax = MOV32rm $rbp, 1, $noreg, -32, $noreg :: (dereferenceable load (s32) from %ir.1)
  renamable $rcx = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  renamable $rdx = MOV64rm $rbp, 1, $noreg, -8, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr killed renamable $rcx, killed renamable $rdx, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit killed $eflags

bb.4.SP_return:
; predecessors: %bb.3
  liveins: $eax
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After StackMap Liveness Analysis (stackmap-liveness) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=8, align=8, at location [SP-16]
  fi#1: size=4, align=4, at location [SP-40]
  fi#2: size=4, align=4, at location [SP-20]
  fi#3: size=4, align=4, at location [SP-24]
  fi#4: size=4, align=4, at location [SP-32]
  fi#5: size=4, align=4, at location [SP-28]
  fi#6: size=4, align=4, at location [SP-36]

bb.0 (%ir-block.0):
  successors: %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  renamable $rax = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr $rbp, 1, $noreg, -8, $noreg, killed renamable $rax
  MOV32mi $rbp, 1, $noreg, -32, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi $rbp, 1, $noreg, -12, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi $rbp, 1, $noreg, -16, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi $rbp, 1, $noreg, -24, $noreg, 1 :: (store (s32) into %ir.4)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -20, $noreg
  renamable $rdx = LEA64r $rbp, 1, $noreg, -12, $noreg
  renamable $rcx = LEA64r $rbp, 1, $noreg, -16, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -20, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit killed $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -28, $noreg, killed renamable $eax :: (store (s32) into %ir.6)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $eax = ADD32rm killed renamable $eax(tied-def 0), $rbp, 1, $noreg, -16, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -16, $noreg, killed renamable $eax :: (store (s32) into %ir.3)
  renamable $esi = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  renamable $rdi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.6)
  MOV32mr $rbp, 1, $noreg, -12, $noreg, killed renamable $eax :: (store (s32) into %ir.2)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -24, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  renamable $eax = MOV32rm $rbp, 1, $noreg, -32, $noreg :: (dereferenceable load (s32) from %ir.1)
  renamable $rcx = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  renamable $rdx = MOV64rm $rbp, 1, $noreg, -8, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr killed renamable $rcx, killed renamable $rdx, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit killed $eflags

bb.4.SP_return:
; predecessors: %bb.3
  liveins: $eax
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before Live DEBUG_VALUE analysis (livedebugvalues) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=8, align=8, at location [SP-16]
  fi#1: size=4, align=4, at location [SP-40]
  fi#2: size=4, align=4, at location [SP-20]
  fi#3: size=4, align=4, at location [SP-24]
  fi#4: size=4, align=4, at location [SP-32]
  fi#5: size=4, align=4, at location [SP-28]
  fi#6: size=4, align=4, at location [SP-36]

bb.0 (%ir-block.0):
  successors: %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  renamable $rax = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr $rbp, 1, $noreg, -8, $noreg, killed renamable $rax
  MOV32mi $rbp, 1, $noreg, -32, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi $rbp, 1, $noreg, -12, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi $rbp, 1, $noreg, -16, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi $rbp, 1, $noreg, -24, $noreg, 1 :: (store (s32) into %ir.4)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -20, $noreg
  renamable $rdx = LEA64r $rbp, 1, $noreg, -12, $noreg
  renamable $rcx = LEA64r $rbp, 1, $noreg, -16, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -20, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit killed $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -28, $noreg, killed renamable $eax :: (store (s32) into %ir.6)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $eax = ADD32rm killed renamable $eax(tied-def 0), $rbp, 1, $noreg, -16, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -16, $noreg, killed renamable $eax :: (store (s32) into %ir.3)
  renamable $esi = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  renamable $rdi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.6)
  MOV32mr $rbp, 1, $noreg, -12, $noreg, killed renamable $eax :: (store (s32) into %ir.2)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -24, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  renamable $eax = MOV32rm $rbp, 1, $noreg, -32, $noreg :: (dereferenceable load (s32) from %ir.1)
  renamable $rcx = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  renamable $rdx = MOV64rm $rbp, 1, $noreg, -8, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr killed renamable $rcx, killed renamable $rdx, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit killed $eflags

bb.4.SP_return:
; predecessors: %bb.3
  liveins: $eax
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After Live DEBUG_VALUE analysis (livedebugvalues) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=8, align=8, at location [SP-16]
  fi#1: size=4, align=4, at location [SP-40]
  fi#2: size=4, align=4, at location [SP-20]
  fi#3: size=4, align=4, at location [SP-24]
  fi#4: size=4, align=4, at location [SP-32]
  fi#5: size=4, align=4, at location [SP-28]
  fi#6: size=4, align=4, at location [SP-36]

bb.0 (%ir-block.0):
  successors: %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  renamable $rax = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr $rbp, 1, $noreg, -8, $noreg, killed renamable $rax
  MOV32mi $rbp, 1, $noreg, -32, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi $rbp, 1, $noreg, -12, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi $rbp, 1, $noreg, -16, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi $rbp, 1, $noreg, -24, $noreg, 1 :: (store (s32) into %ir.4)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -20, $noreg
  renamable $rdx = LEA64r $rbp, 1, $noreg, -12, $noreg
  renamable $rcx = LEA64r $rbp, 1, $noreg, -16, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -20, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit killed $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -28, $noreg, killed renamable $eax :: (store (s32) into %ir.6)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $eax = ADD32rm killed renamable $eax(tied-def 0), $rbp, 1, $noreg, -16, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -16, $noreg, killed renamable $eax :: (store (s32) into %ir.3)
  renamable $esi = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  renamable $rdi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.6)
  MOV32mr $rbp, 1, $noreg, -12, $noreg, killed renamable $eax :: (store (s32) into %ir.2)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -24, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  renamable $eax = MOV32rm $rbp, 1, $noreg, -32, $noreg :: (dereferenceable load (s32) from %ir.1)
  renamable $rcx = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  renamable $rdx = MOV64rm $rbp, 1, $noreg, -8, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr killed renamable $rcx, killed renamable $rdx, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit killed $eflags

bb.4.SP_return:
; predecessors: %bb.3
  liveins: $eax
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before X86 Speculative Execution Side Effect Suppression (x86-seses) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=8, align=8, at location [SP-16]
  fi#1: size=4, align=4, at location [SP-40]
  fi#2: size=4, align=4, at location [SP-20]
  fi#3: size=4, align=4, at location [SP-24]
  fi#4: size=4, align=4, at location [SP-32]
  fi#5: size=4, align=4, at location [SP-28]
  fi#6: size=4, align=4, at location [SP-36]

bb.0 (%ir-block.0):
  successors: %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  renamable $rax = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr $rbp, 1, $noreg, -8, $noreg, killed renamable $rax
  MOV32mi $rbp, 1, $noreg, -32, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi $rbp, 1, $noreg, -12, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi $rbp, 1, $noreg, -16, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi $rbp, 1, $noreg, -24, $noreg, 1 :: (store (s32) into %ir.4)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -20, $noreg
  renamable $rdx = LEA64r $rbp, 1, $noreg, -12, $noreg
  renamable $rcx = LEA64r $rbp, 1, $noreg, -16, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -20, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit killed $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -28, $noreg, killed renamable $eax :: (store (s32) into %ir.6)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $eax = ADD32rm killed renamable $eax(tied-def 0), $rbp, 1, $noreg, -16, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -16, $noreg, killed renamable $eax :: (store (s32) into %ir.3)
  renamable $esi = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  renamable $rdi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.6)
  MOV32mr $rbp, 1, $noreg, -12, $noreg, killed renamable $eax :: (store (s32) into %ir.2)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -24, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  renamable $eax = MOV32rm $rbp, 1, $noreg, -32, $noreg :: (dereferenceable load (s32) from %ir.1)
  renamable $rcx = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  renamable $rdx = MOV64rm $rbp, 1, $noreg, -8, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr killed renamable $rcx, killed renamable $rdx, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit killed $eflags

bb.4.SP_return:
; predecessors: %bb.3
  liveins: $eax
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After X86 Speculative Execution Side Effect Suppression (x86-seses) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=8, align=8, at location [SP-16]
  fi#1: size=4, align=4, at location [SP-40]
  fi#2: size=4, align=4, at location [SP-20]
  fi#3: size=4, align=4, at location [SP-24]
  fi#4: size=4, align=4, at location [SP-32]
  fi#5: size=4, align=4, at location [SP-28]
  fi#6: size=4, align=4, at location [SP-36]

bb.0 (%ir-block.0):
  successors: %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  renamable $rax = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr $rbp, 1, $noreg, -8, $noreg, killed renamable $rax
  MOV32mi $rbp, 1, $noreg, -32, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi $rbp, 1, $noreg, -12, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi $rbp, 1, $noreg, -16, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi $rbp, 1, $noreg, -24, $noreg, 1 :: (store (s32) into %ir.4)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -20, $noreg
  renamable $rdx = LEA64r $rbp, 1, $noreg, -12, $noreg
  renamable $rcx = LEA64r $rbp, 1, $noreg, -16, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -20, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit killed $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -28, $noreg, killed renamable $eax :: (store (s32) into %ir.6)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $eax = ADD32rm killed renamable $eax(tied-def 0), $rbp, 1, $noreg, -16, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -16, $noreg, killed renamable $eax :: (store (s32) into %ir.3)
  renamable $esi = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  renamable $rdi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.6)
  MOV32mr $rbp, 1, $noreg, -12, $noreg, killed renamable $eax :: (store (s32) into %ir.2)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -24, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  renamable $eax = MOV32rm $rbp, 1, $noreg, -32, $noreg :: (dereferenceable load (s32) from %ir.1)
  renamable $rcx = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  renamable $rdx = MOV64rm $rbp, 1, $noreg, -8, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr killed renamable $rcx, killed renamable $rdx, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit killed $eflags

bb.4.SP_return:
; predecessors: %bb.3
  liveins: $eax
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before Check CFA info and insert CFI instructions if needed (cfi-instr-inserter) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=8, align=8, at location [SP-16]
  fi#1: size=4, align=4, at location [SP-40]
  fi#2: size=4, align=4, at location [SP-20]
  fi#3: size=4, align=4, at location [SP-24]
  fi#4: size=4, align=4, at location [SP-32]
  fi#5: size=4, align=4, at location [SP-28]
  fi#6: size=4, align=4, at location [SP-36]

bb.0 (%ir-block.0):
  successors: %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  renamable $rax = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr $rbp, 1, $noreg, -8, $noreg, killed renamable $rax
  MOV32mi $rbp, 1, $noreg, -32, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi $rbp, 1, $noreg, -12, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi $rbp, 1, $noreg, -16, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi $rbp, 1, $noreg, -24, $noreg, 1 :: (store (s32) into %ir.4)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -20, $noreg
  renamable $rdx = LEA64r $rbp, 1, $noreg, -12, $noreg
  renamable $rcx = LEA64r $rbp, 1, $noreg, -16, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -20, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit killed $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -28, $noreg, killed renamable $eax :: (store (s32) into %ir.6)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $eax = ADD32rm killed renamable $eax(tied-def 0), $rbp, 1, $noreg, -16, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -16, $noreg, killed renamable $eax :: (store (s32) into %ir.3)
  renamable $esi = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  renamable $rdi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.6)
  MOV32mr $rbp, 1, $noreg, -12, $noreg, killed renamable $eax :: (store (s32) into %ir.2)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -24, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  renamable $eax = MOV32rm $rbp, 1, $noreg, -32, $noreg :: (dereferenceable load (s32) from %ir.1)
  renamable $rcx = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  renamable $rdx = MOV64rm $rbp, 1, $noreg, -8, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr killed renamable $rcx, killed renamable $rdx, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit killed $eflags

bb.4.SP_return:
; predecessors: %bb.3
  liveins: $eax
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After Check CFA info and insert CFI instructions if needed (cfi-instr-inserter) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=8, align=8, at location [SP-16]
  fi#1: size=4, align=4, at location [SP-40]
  fi#2: size=4, align=4, at location [SP-20]
  fi#3: size=4, align=4, at location [SP-24]
  fi#4: size=4, align=4, at location [SP-32]
  fi#5: size=4, align=4, at location [SP-28]
  fi#6: size=4, align=4, at location [SP-36]

bb.0 (%ir-block.0):
  successors: %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  renamable $rax = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr $rbp, 1, $noreg, -8, $noreg, killed renamable $rax
  MOV32mi $rbp, 1, $noreg, -32, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi $rbp, 1, $noreg, -12, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi $rbp, 1, $noreg, -16, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi $rbp, 1, $noreg, -24, $noreg, 1 :: (store (s32) into %ir.4)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -20, $noreg
  renamable $rdx = LEA64r $rbp, 1, $noreg, -12, $noreg
  renamable $rcx = LEA64r $rbp, 1, $noreg, -16, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -20, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit killed $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -28, $noreg, killed renamable $eax :: (store (s32) into %ir.6)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $eax = ADD32rm killed renamable $eax(tied-def 0), $rbp, 1, $noreg, -16, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -16, $noreg, killed renamable $eax :: (store (s32) into %ir.3)
  renamable $esi = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  renamable $rdi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.6)
  MOV32mr $rbp, 1, $noreg, -12, $noreg, killed renamable $eax :: (store (s32) into %ir.2)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -24, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  renamable $eax = MOV32rm $rbp, 1, $noreg, -32, $noreg :: (dereferenceable load (s32) from %ir.1)
  renamable $rcx = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  renamable $rdx = MOV64rm $rbp, 1, $noreg, -8, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr killed renamable $rcx, killed renamable $rdx, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit killed $eflags

bb.4.SP_return:
; predecessors: %bb.3
  liveins: $eax
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  CFI_INSTRUCTION def_cfa $rbp, 16
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before X86 Load Value Injection (LVI) Ret-Hardening (x86-lvi-ret) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=8, align=8, at location [SP-16]
  fi#1: size=4, align=4, at location [SP-40]
  fi#2: size=4, align=4, at location [SP-20]
  fi#3: size=4, align=4, at location [SP-24]
  fi#4: size=4, align=4, at location [SP-32]
  fi#5: size=4, align=4, at location [SP-28]
  fi#6: size=4, align=4, at location [SP-36]

bb.0 (%ir-block.0):
  successors: %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  renamable $rax = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr $rbp, 1, $noreg, -8, $noreg, killed renamable $rax
  MOV32mi $rbp, 1, $noreg, -32, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi $rbp, 1, $noreg, -12, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi $rbp, 1, $noreg, -16, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi $rbp, 1, $noreg, -24, $noreg, 1 :: (store (s32) into %ir.4)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -20, $noreg
  renamable $rdx = LEA64r $rbp, 1, $noreg, -12, $noreg
  renamable $rcx = LEA64r $rbp, 1, $noreg, -16, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -20, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit killed $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -28, $noreg, killed renamable $eax :: (store (s32) into %ir.6)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $eax = ADD32rm killed renamable $eax(tied-def 0), $rbp, 1, $noreg, -16, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -16, $noreg, killed renamable $eax :: (store (s32) into %ir.3)
  renamable $esi = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  renamable $rdi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.6)
  MOV32mr $rbp, 1, $noreg, -12, $noreg, killed renamable $eax :: (store (s32) into %ir.2)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -24, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  renamable $eax = MOV32rm $rbp, 1, $noreg, -32, $noreg :: (dereferenceable load (s32) from %ir.1)
  renamable $rcx = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  renamable $rdx = MOV64rm $rbp, 1, $noreg, -8, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr killed renamable $rcx, killed renamable $rdx, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit killed $eflags

bb.4.SP_return:
; predecessors: %bb.3
  liveins: $eax
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  CFI_INSTRUCTION def_cfa $rbp, 16
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After X86 Load Value Injection (LVI) Ret-Hardening (x86-lvi-ret) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=8, align=8, at location [SP-16]
  fi#1: size=4, align=4, at location [SP-40]
  fi#2: size=4, align=4, at location [SP-20]
  fi#3: size=4, align=4, at location [SP-24]
  fi#4: size=4, align=4, at location [SP-32]
  fi#5: size=4, align=4, at location [SP-28]
  fi#6: size=4, align=4, at location [SP-36]

bb.0 (%ir-block.0):
  successors: %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  renamable $rax = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr $rbp, 1, $noreg, -8, $noreg, killed renamable $rax
  MOV32mi $rbp, 1, $noreg, -32, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi $rbp, 1, $noreg, -12, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi $rbp, 1, $noreg, -16, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi $rbp, 1, $noreg, -24, $noreg, 1 :: (store (s32) into %ir.4)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -20, $noreg
  renamable $rdx = LEA64r $rbp, 1, $noreg, -12, $noreg
  renamable $rcx = LEA64r $rbp, 1, $noreg, -16, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -20, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit killed $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -28, $noreg, killed renamable $eax :: (store (s32) into %ir.6)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $eax = ADD32rm killed renamable $eax(tied-def 0), $rbp, 1, $noreg, -16, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -16, $noreg, killed renamable $eax :: (store (s32) into %ir.3)
  renamable $esi = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  renamable $rdi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.6)
  MOV32mr $rbp, 1, $noreg, -12, $noreg, killed renamable $eax :: (store (s32) into %ir.2)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -24, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  renamable $eax = MOV32rm $rbp, 1, $noreg, -32, $noreg :: (dereferenceable load (s32) from %ir.1)
  renamable $rcx = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  renamable $rdx = MOV64rm $rbp, 1, $noreg, -8, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr killed renamable $rcx, killed renamable $rdx, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit killed $eflags

bb.4.SP_return:
; predecessors: %bb.3
  liveins: $eax
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  CFI_INSTRUCTION def_cfa $rbp, 16
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump Before Pseudo Probe Inserter (pseudo-probe-inserter) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=8, align=8, at location [SP-16]
  fi#1: size=4, align=4, at location [SP-40]
  fi#2: size=4, align=4, at location [SP-20]
  fi#3: size=4, align=4, at location [SP-24]
  fi#4: size=4, align=4, at location [SP-32]
  fi#5: size=4, align=4, at location [SP-28]
  fi#6: size=4, align=4, at location [SP-36]

bb.0 (%ir-block.0):
  successors: %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  renamable $rax = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr $rbp, 1, $noreg, -8, $noreg, killed renamable $rax
  MOV32mi $rbp, 1, $noreg, -32, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi $rbp, 1, $noreg, -12, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi $rbp, 1, $noreg, -16, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi $rbp, 1, $noreg, -24, $noreg, 1 :: (store (s32) into %ir.4)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -20, $noreg
  renamable $rdx = LEA64r $rbp, 1, $noreg, -12, $noreg
  renamable $rcx = LEA64r $rbp, 1, $noreg, -16, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -20, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit killed $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -28, $noreg, killed renamable $eax :: (store (s32) into %ir.6)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $eax = ADD32rm killed renamable $eax(tied-def 0), $rbp, 1, $noreg, -16, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -16, $noreg, killed renamable $eax :: (store (s32) into %ir.3)
  renamable $esi = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  renamable $rdi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.6)
  MOV32mr $rbp, 1, $noreg, -12, $noreg, killed renamable $eax :: (store (s32) into %ir.2)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -24, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  renamable $eax = MOV32rm $rbp, 1, $noreg, -32, $noreg :: (dereferenceable load (s32) from %ir.1)
  renamable $rcx = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  renamable $rdx = MOV64rm $rbp, 1, $noreg, -8, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr killed renamable $rcx, killed renamable $rdx, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit killed $eflags

bb.4.SP_return:
; predecessors: %bb.3
  liveins: $eax
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  CFI_INSTRUCTION def_cfa $rbp, 16
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp

# End machine code for function main.

# *** IR Dump After Pseudo Probe Inserter (pseudo-probe-inserter) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=8, align=8, at location [SP-16]
  fi#1: size=4, align=4, at location [SP-40]
  fi#2: size=4, align=4, at location [SP-20]
  fi#3: size=4, align=4, at location [SP-24]
  fi#4: size=4, align=4, at location [SP-32]
  fi#5: size=4, align=4, at location [SP-28]
  fi#6: size=4, align=4, at location [SP-36]

bb.0 (%ir-block.0):
  successors: %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  renamable $rax = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  MOV64mr $rbp, 1, $noreg, -8, $noreg, killed renamable $rax
  MOV32mi $rbp, 1, $noreg, -32, $noreg, 0 :: (store (s32) into %ir.1)
  MOV32mi $rbp, 1, $noreg, -12, $noreg, 0 :: (store (s32) into %ir.2)
  MOV32mi $rbp, 1, $noreg, -16, $noreg, 1 :: (store (s32) into %ir.3)
  MOV32mi $rbp, 1, $noreg, -24, $noreg, 1 :: (store (s32) into %ir.4)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -20, $noreg
  renamable $rdx = LEA64r $rbp, 1, $noreg, -12, $noreg
  renamable $rcx = LEA64r $rbp, 1, $noreg, -16, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit $rdx, implicit $rcx, implicit-def $eax

bb.1 (%ir-block.8):
; predecessors: %bb.0, %bb.2
  successors: %bb.3, %bb.2

  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -20, $noreg, implicit-def $eflags :: (load (s32) from %ir.5)
  JCC_1 %bb.3, 13, implicit killed $eflags

bb.2 (%ir-block.12):
; predecessors: %bb.1
  successors: %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -28, $noreg, killed renamable $eax :: (store (s32) into %ir.6)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $eax = ADD32rm killed renamable $eax(tied-def 0), $rbp, 1, $noreg, -16, $noreg, implicit-def dead $eflags :: (load (s32) from %ir.3)
  MOV32mr $rbp, 1, $noreg, -16, $noreg, killed renamable $eax :: (store (s32) into %ir.3)
  renamable $esi = MOV32rm $rbp, 1, $noreg, -16, $noreg :: (load (s32) from %ir.3)
  renamable $rdi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $esi, implicit-def $eax
  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.6)
  MOV32mr $rbp, 1, $noreg, -12, $noreg, killed renamable $eax :: (store (s32) into %ir.2)
  renamable $eax = MOV32rm $rbp, 1, $noreg, -24, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -24, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.1

bb.3 (%ir-block.22):
; predecessors: %bb.1
  successors: %bb.5, %bb.4

  renamable $eax = MOV32rm $rbp, 1, $noreg, -32, $noreg :: (dereferenceable load (s32) from %ir.1)
  renamable $rcx = MOV64rm $noreg, 1, $noreg, 40, $fs :: (volatile load (s64) from `i8* addrspace(257)* inttoptr (i32 40 to i8* addrspace(257)*)`, addrspace 257)
  renamable $rdx = MOV64rm $rbp, 1, $noreg, -8, $noreg :: (volatile load (s64) from %ir.StackGuardSlot)
  CMP64rr killed renamable $rcx, killed renamable $rdx, implicit-def $eflags
  JCC_1 %bb.5, 5, implicit killed $eflags

bb.4.SP_return:
; predecessors: %bb.3
  liveins: $eax
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

bb.5.CallStackCheckFailBlk:
; predecessors: %bb.3

  CFI_INSTRUCTION def_cfa $rbp, 16
  CALL64pcrel32 target-flags(x86-plt) @__stack_chk_fail, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp

# End machine code for function main.

